2025-01-17 17:15:48,297:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 17:15:48,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 17:15:48,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 17:15:48,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 17:15:55,628:INFO:PyCaret ClassificationExperiment
2025-01-17 17:15:55,628:INFO:Logging name: clf-default-name
2025-01-17 17:15:55,628:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-01-17 17:15:55,628:INFO:version 3.3.1
2025-01-17 17:15:55,628:INFO:Initializing setup()
2025-01-17 17:15:55,628:INFO:self.USI: 691a
2025-01-17 17:15:55,628:INFO:self._variable_keys: {'is_multiclass', 'fold_shuffle_param', 'gpu_n_jobs_param', 'y_test', 'fold_generator', 'data', 'n_jobs_param', 'fold_groups_param', 'target_param', '_available_plots', 'X_test', 'gpu_param', 'html_param', 'USI', 'seed', 'fix_imbalance', '_ml_usecase', 'exp_id', 'pipeline', 'idx', 'logging_param', 'memory', 'X_train', 'y', 'exp_name_log', 'log_plots_param', 'X', 'y_train'}
2025-01-17 17:15:55,628:INFO:Checking environment
2025-01-17 17:15:55,628:INFO:python_version: 3.10.13
2025-01-17 17:15:55,628:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-17 17:15:55,628:INFO:machine: arm64
2025-01-17 17:15:55,628:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-17 17:15:55,629:INFO:Memory: svmem(total=8589934592, available=2111193088, percent=75.4, used=3503341568, free=93274112, active=2020311040, inactive=1995259904, wired=1483030528)
2025-01-17 17:15:55,629:INFO:Physical Core: 8
2025-01-17 17:15:55,629:INFO:Logical Core: 8
2025-01-17 17:15:55,629:INFO:Checking libraries
2025-01-17 17:15:55,629:INFO:System:
2025-01-17 17:15:55,629:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-17 17:15:55,629:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-17 17:15:55,629:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-17 17:15:55,629:INFO:PyCaret required dependencies:
2025-01-17 17:15:55,866:INFO:                 pip: 24.2
2025-01-17 17:15:55,866:INFO:          setuptools: 75.1.0
2025-01-17 17:15:55,866:INFO:             pycaret: 3.3.1
2025-01-17 17:15:55,866:INFO:             IPython: 8.27.0
2025-01-17 17:15:55,866:INFO:          ipywidgets: 8.1.2
2025-01-17 17:15:55,866:INFO:                tqdm: 4.66.5
2025-01-17 17:15:55,866:INFO:               numpy: 1.26.4
2025-01-17 17:15:55,866:INFO:              pandas: 2.1.4
2025-01-17 17:15:55,866:INFO:              jinja2: 3.1.4
2025-01-17 17:15:55,866:INFO:               scipy: 1.11.4
2025-01-17 17:15:55,866:INFO:              joblib: 1.3.2
2025-01-17 17:15:55,866:INFO:             sklearn: 1.4.2
2025-01-17 17:15:55,866:INFO:                pyod: 2.0.2
2025-01-17 17:15:55,866:INFO:            imblearn: 0.13.0
2025-01-17 17:15:55,866:INFO:   category_encoders: 2.7.0
2025-01-17 17:15:55,866:INFO:            lightgbm: 4.4.0
2025-01-17 17:15:55,867:INFO:               numba: 0.60.0
2025-01-17 17:15:55,867:INFO:            requests: 2.32.3
2025-01-17 17:15:55,867:INFO:          matplotlib: 3.9.2
2025-01-17 17:15:55,867:INFO:          scikitplot: 0.3.7
2025-01-17 17:15:55,867:INFO:         yellowbrick: 1.5
2025-01-17 17:15:55,867:INFO:              plotly: 5.24.1
2025-01-17 17:15:55,867:INFO:    plotly-resampler: Not installed
2025-01-17 17:15:55,867:INFO:             kaleido: 0.2.1
2025-01-17 17:15:55,867:INFO:           schemdraw: 0.15
2025-01-17 17:15:55,867:INFO:         statsmodels: 0.14.4
2025-01-17 17:15:55,867:INFO:              sktime: 0.26.0
2025-01-17 17:15:55,867:INFO:               tbats: 1.1.3
2025-01-17 17:15:55,867:INFO:            pmdarima: 2.0.4
2025-01-17 17:15:55,867:INFO:              psutil: 5.9.0
2025-01-17 17:15:55,867:INFO:          markupsafe: 2.1.3
2025-01-17 17:15:55,867:INFO:             pickle5: Not installed
2025-01-17 17:15:55,867:INFO:         cloudpickle: 3.1.0
2025-01-17 17:15:55,867:INFO:         deprecation: 2.1.0
2025-01-17 17:15:55,867:INFO:              xxhash: 3.5.0
2025-01-17 17:15:55,867:INFO:           wurlitzer: 3.1.1
2025-01-17 17:15:55,867:INFO:PyCaret optional dependencies:
2025-01-17 17:15:56,004:INFO:                shap: Not installed
2025-01-17 17:15:56,004:INFO:           interpret: Not installed
2025-01-17 17:15:56,004:INFO:                umap: 0.5.7
2025-01-17 17:15:56,004:INFO:     ydata_profiling: Not installed
2025-01-17 17:15:56,004:INFO:  explainerdashboard: Not installed
2025-01-17 17:15:56,004:INFO:             autoviz: Not installed
2025-01-17 17:15:56,004:INFO:           fairlearn: Not installed
2025-01-17 17:15:56,004:INFO:          deepchecks: Not installed
2025-01-17 17:15:56,004:INFO:             xgboost: 2.1.3
2025-01-17 17:15:56,004:INFO:            catboost: Not installed
2025-01-17 17:15:56,004:INFO:              kmodes: Not installed
2025-01-17 17:15:56,004:INFO:             mlxtend: Not installed
2025-01-17 17:15:56,004:INFO:       statsforecast: Not installed
2025-01-17 17:15:56,004:INFO:        tune_sklearn: Not installed
2025-01-17 17:15:56,004:INFO:                 ray: Not installed
2025-01-17 17:15:56,004:INFO:            hyperopt: Not installed
2025-01-17 17:15:56,004:INFO:              optuna: Not installed
2025-01-17 17:15:56,004:INFO:               skopt: Not installed
2025-01-17 17:15:56,004:INFO:              mlflow: Not installed
2025-01-17 17:15:56,004:INFO:              gradio: Not installed
2025-01-17 17:15:56,004:INFO:             fastapi: Not installed
2025-01-17 17:15:56,004:INFO:             uvicorn: Not installed
2025-01-17 17:15:56,004:INFO:              m2cgen: Not installed
2025-01-17 17:15:56,004:INFO:           evidently: Not installed
2025-01-17 17:15:56,004:INFO:               fugue: Not installed
2025-01-17 17:15:56,004:INFO:           streamlit: Not installed
2025-01-17 17:15:56,004:INFO:             prophet: Not installed
2025-01-17 17:15:56,004:INFO:None
2025-01-17 17:15:56,004:INFO:Set up data.
2025-01-17 17:15:56,009:INFO:Set up folding strategy.
2025-01-17 17:15:56,009:INFO:Set up train/test split.
2025-01-17 17:15:56,156:INFO:Set up index.
2025-01-17 17:15:56,156:INFO:Assigning column types.
2025-01-17 17:15:56,161:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-17 17:15:56,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 17:15:56,216:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 17:15:56,236:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:15:56,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:15:56,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 17:15:56,258:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 17:15:56,270:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:15:56,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:15:56,271:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-17 17:15:56,291:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 17:15:56,302:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:15:56,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:15:56,323:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 17:15:56,335:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:15:56,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:15:56,336:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-01-17 17:15:56,367:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:15:56,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:15:56,399:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:15:56,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:15:56,401:INFO:Preparing preprocessing pipeline...
2025-01-17 17:15:56,402:INFO:Set up label encoding.
2025-01-17 17:15:56,402:INFO:Set up simple imputation.
2025-01-17 17:15:56,412:INFO:Finished creating preprocessing pipeline.
2025-01-17 17:15:56,414:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-01-17 17:15:56,414:INFO:Creating final display dataframe.
2025-01-17 17:15:56,439:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                             species  
2                                          Multiclass  
3   Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...  
4                                            (150, 5)  
5                                            (150, 5)  
6                                            (105, 5)  
7                                             (45, 5)  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               691a  
2025-01-17 17:15:56,477:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:15:56,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:15:56,510:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:15:56,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:15:56,512:INFO:setup() successfully completed in 0.89s...............
2025-01-17 17:18:50,912:INFO:PyCaret ClassificationExperiment
2025-01-17 17:18:50,912:INFO:Logging name: clf-default-name
2025-01-17 17:18:50,913:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-01-17 17:18:50,913:INFO:version 3.3.1
2025-01-17 17:18:50,913:INFO:Initializing setup()
2025-01-17 17:18:50,913:INFO:self.USI: 805c
2025-01-17 17:18:50,913:INFO:self._variable_keys: {'is_multiclass', 'fold_shuffle_param', 'gpu_n_jobs_param', 'y_test', 'fold_generator', 'data', 'n_jobs_param', 'fold_groups_param', 'target_param', '_available_plots', 'X_test', 'gpu_param', 'html_param', 'USI', 'seed', 'fix_imbalance', '_ml_usecase', 'exp_id', 'pipeline', 'idx', 'logging_param', 'memory', 'X_train', 'y', 'exp_name_log', 'log_plots_param', 'X', 'y_train'}
2025-01-17 17:18:50,913:INFO:Checking environment
2025-01-17 17:18:50,913:INFO:python_version: 3.10.13
2025-01-17 17:18:50,913:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-17 17:18:50,913:INFO:machine: arm64
2025-01-17 17:18:50,913:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-17 17:18:50,914:INFO:Memory: svmem(total=8589934592, available=2156724224, percent=74.9, used=3514073088, free=109920256, active=2120990720, inactive=1997062144, wired=1393082368)
2025-01-17 17:18:50,914:INFO:Physical Core: 8
2025-01-17 17:18:50,914:INFO:Logical Core: 8
2025-01-17 17:18:50,914:INFO:Checking libraries
2025-01-17 17:18:50,914:INFO:System:
2025-01-17 17:18:50,914:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-17 17:18:50,914:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-17 17:18:50,914:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-17 17:18:50,914:INFO:PyCaret required dependencies:
2025-01-17 17:18:50,914:INFO:                 pip: 24.2
2025-01-17 17:18:50,914:INFO:          setuptools: 75.1.0
2025-01-17 17:18:50,914:INFO:             pycaret: 3.3.1
2025-01-17 17:18:50,914:INFO:             IPython: 8.27.0
2025-01-17 17:18:50,914:INFO:          ipywidgets: 8.1.2
2025-01-17 17:18:50,914:INFO:                tqdm: 4.66.5
2025-01-17 17:18:50,914:INFO:               numpy: 1.26.4
2025-01-17 17:18:50,914:INFO:              pandas: 2.1.4
2025-01-17 17:18:50,915:INFO:              jinja2: 3.1.4
2025-01-17 17:18:50,915:INFO:               scipy: 1.11.4
2025-01-17 17:18:50,915:INFO:              joblib: 1.3.2
2025-01-17 17:18:50,915:INFO:             sklearn: 1.4.2
2025-01-17 17:18:50,915:INFO:                pyod: 2.0.2
2025-01-17 17:18:50,915:INFO:            imblearn: 0.13.0
2025-01-17 17:18:50,915:INFO:   category_encoders: 2.7.0
2025-01-17 17:18:50,915:INFO:            lightgbm: 4.4.0
2025-01-17 17:18:50,915:INFO:               numba: 0.60.0
2025-01-17 17:18:50,915:INFO:            requests: 2.32.3
2025-01-17 17:18:50,915:INFO:          matplotlib: 3.9.2
2025-01-17 17:18:50,915:INFO:          scikitplot: 0.3.7
2025-01-17 17:18:50,915:INFO:         yellowbrick: 1.5
2025-01-17 17:18:50,915:INFO:              plotly: 5.24.1
2025-01-17 17:18:50,915:INFO:    plotly-resampler: Not installed
2025-01-17 17:18:50,915:INFO:             kaleido: 0.2.1
2025-01-17 17:18:50,915:INFO:           schemdraw: 0.15
2025-01-17 17:18:50,915:INFO:         statsmodels: 0.14.4
2025-01-17 17:18:50,915:INFO:              sktime: 0.26.0
2025-01-17 17:18:50,915:INFO:               tbats: 1.1.3
2025-01-17 17:18:50,915:INFO:            pmdarima: 2.0.4
2025-01-17 17:18:50,916:INFO:              psutil: 5.9.0
2025-01-17 17:18:50,916:INFO:          markupsafe: 2.1.3
2025-01-17 17:18:50,916:INFO:             pickle5: Not installed
2025-01-17 17:18:50,916:INFO:         cloudpickle: 3.1.0
2025-01-17 17:18:50,916:INFO:         deprecation: 2.1.0
2025-01-17 17:18:50,916:INFO:              xxhash: 3.5.0
2025-01-17 17:18:50,916:INFO:           wurlitzer: 3.1.1
2025-01-17 17:18:50,916:INFO:PyCaret optional dependencies:
2025-01-17 17:18:50,916:INFO:                shap: Not installed
2025-01-17 17:18:50,916:INFO:           interpret: Not installed
2025-01-17 17:18:50,916:INFO:                umap: 0.5.7
2025-01-17 17:18:50,916:INFO:     ydata_profiling: Not installed
2025-01-17 17:18:50,916:INFO:  explainerdashboard: Not installed
2025-01-17 17:18:50,916:INFO:             autoviz: Not installed
2025-01-17 17:18:50,916:INFO:           fairlearn: Not installed
2025-01-17 17:18:50,916:INFO:          deepchecks: Not installed
2025-01-17 17:18:50,916:INFO:             xgboost: 2.1.3
2025-01-17 17:18:50,916:INFO:            catboost: Not installed
2025-01-17 17:18:50,916:INFO:              kmodes: Not installed
2025-01-17 17:18:50,916:INFO:             mlxtend: Not installed
2025-01-17 17:18:50,916:INFO:       statsforecast: Not installed
2025-01-17 17:18:50,917:INFO:        tune_sklearn: Not installed
2025-01-17 17:18:50,917:INFO:                 ray: Not installed
2025-01-17 17:18:50,917:INFO:            hyperopt: Not installed
2025-01-17 17:18:50,917:INFO:              optuna: Not installed
2025-01-17 17:18:50,917:INFO:               skopt: Not installed
2025-01-17 17:18:50,917:INFO:              mlflow: Not installed
2025-01-17 17:18:50,917:INFO:              gradio: Not installed
2025-01-17 17:18:50,917:INFO:             fastapi: Not installed
2025-01-17 17:18:50,917:INFO:             uvicorn: Not installed
2025-01-17 17:18:50,917:INFO:              m2cgen: Not installed
2025-01-17 17:18:50,917:INFO:           evidently: Not installed
2025-01-17 17:18:50,917:INFO:               fugue: Not installed
2025-01-17 17:18:50,917:INFO:           streamlit: Not installed
2025-01-17 17:18:50,917:INFO:             prophet: Not installed
2025-01-17 17:18:50,918:INFO:None
2025-01-17 17:18:50,918:INFO:Set up data.
2025-01-17 17:18:50,924:INFO:Set up folding strategy.
2025-01-17 17:18:50,924:INFO:Set up train/test split.
2025-01-17 17:18:50,929:INFO:Set up index.
2025-01-17 17:18:50,929:INFO:Assigning column types.
2025-01-17 17:18:50,932:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-17 17:18:50,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 17:18:50,997:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 17:18:51,010:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:18:51,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:18:51,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 17:18:51,036:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 17:18:51,049:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:18:51,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:18:51,050:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-17 17:18:51,073:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 17:18:51,092:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:18:51,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:18:51,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 17:18:51,128:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:18:51,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:18:51,129:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-01-17 17:18:51,167:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:18:51,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:18:51,200:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:18:51,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:18:51,202:INFO:Preparing preprocessing pipeline...
2025-01-17 17:18:51,202:INFO:Set up label encoding.
2025-01-17 17:18:51,202:INFO:Set up simple imputation.
2025-01-17 17:18:51,210:INFO:Finished creating preprocessing pipeline.
2025-01-17 17:18:51,211:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-01-17 17:18:51,211:INFO:Creating final display dataframe.
2025-01-17 17:18:51,238:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                             species  
2                                          Multiclass  
3   Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...  
4                                            (150, 5)  
5                                            (150, 5)  
6                                            (105, 5)  
7                                             (45, 5)  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               805c  
2025-01-17 17:18:51,273:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:18:51,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:18:51,309:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 17:18:51,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 17:18:51,311:INFO:setup() successfully completed in 0.4s...............
2025-01-17 17:19:21,816:INFO:Initializing compare_models()
2025-01-17 17:19:21,816:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-01-17 17:19:21,816:INFO:Checking exceptions
2025-01-17 17:19:21,822:INFO:Preparing display monitor
2025-01-17 17:19:22,924:INFO:Initializing Logistic Regression
2025-01-17 17:19:22,925:INFO:Total runtime is 1.1086463928222656e-05 minutes
2025-01-17 17:19:22,959:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:22,960:INFO:Initializing create_model()
2025-01-17 17:19:22,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:22,960:INFO:Checking exceptions
2025-01-17 17:19:22,960:INFO:Importing libraries
2025-01-17 17:19:22,960:INFO:Copying training dataset
2025-01-17 17:19:22,965:INFO:Defining folds
2025-01-17 17:19:22,965:INFO:Declaring metric variables
2025-01-17 17:19:22,969:INFO:Importing untrained model
2025-01-17 17:19:22,971:INFO:Logistic Regression Imported successfully
2025-01-17 17:19:22,975:INFO:Starting cross validation
2025-01-17 17:19:22,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:25,095:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,097:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,098:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,099:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,115:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,116:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,117:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,119:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,121:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,122:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,124:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,125:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,163:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,165:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,167:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,168:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,180:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,181:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,181:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,182:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,183:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,183:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,184:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,184:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,189:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,190:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,192:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,194:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,201:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,202:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,204:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,206:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,216:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,217:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,219:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,220:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,237:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,239:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,240:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,242:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,253:INFO:Calculating mean and std
2025-01-17 17:19:25,259:INFO:Creating metrics dataframe
2025-01-17 17:19:25,261:INFO:Uploading results into container
2025-01-17 17:19:25,262:INFO:Uploading model into container now
2025-01-17 17:19:25,262:INFO:_master_model_container: 1
2025-01-17 17:19:25,262:INFO:_display_container: 2
2025-01-17 17:19:25,263:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 17:19:25,263:INFO:create_model() successfully completed......................................
2025-01-17 17:19:25,356:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:25,356:INFO:Creating metrics dataframe
2025-01-17 17:19:25,359:INFO:Initializing K Neighbors Classifier
2025-01-17 17:19:25,359:INFO:Total runtime is 0.040580550829569496 minutes
2025-01-17 17:19:25,360:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:25,360:INFO:Initializing create_model()
2025-01-17 17:19:25,361:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:25,361:INFO:Checking exceptions
2025-01-17 17:19:25,361:INFO:Importing libraries
2025-01-17 17:19:25,361:INFO:Copying training dataset
2025-01-17 17:19:25,362:INFO:Defining folds
2025-01-17 17:19:25,362:INFO:Declaring metric variables
2025-01-17 17:19:25,364:INFO:Importing untrained model
2025-01-17 17:19:25,365:INFO:K Neighbors Classifier Imported successfully
2025-01-17 17:19:25,370:INFO:Starting cross validation
2025-01-17 17:19:25,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:25,419:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,420:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,421:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,423:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,424:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,425:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,427:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,429:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,432:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,433:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,433:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,433:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,437:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,438:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,439:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,440:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,442:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,442:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,444:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,445:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,447:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,448:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,455:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,456:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,457:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,459:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,460:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,461:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,462:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,463:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,469:INFO:Calculating mean and std
2025-01-17 17:19:25,470:INFO:Creating metrics dataframe
2025-01-17 17:19:25,471:INFO:Uploading results into container
2025-01-17 17:19:25,471:INFO:Uploading model into container now
2025-01-17 17:19:25,471:INFO:_master_model_container: 2
2025-01-17 17:19:25,471:INFO:_display_container: 2
2025-01-17 17:19:25,472:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-01-17 17:19:25,472:INFO:create_model() successfully completed......................................
2025-01-17 17:19:25,521:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:25,521:INFO:Creating metrics dataframe
2025-01-17 17:19:25,524:INFO:Initializing Naive Bayes
2025-01-17 17:19:25,524:INFO:Total runtime is 0.043333534399668375 minutes
2025-01-17 17:19:25,526:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:25,526:INFO:Initializing create_model()
2025-01-17 17:19:25,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:25,526:INFO:Checking exceptions
2025-01-17 17:19:25,526:INFO:Importing libraries
2025-01-17 17:19:25,526:INFO:Copying training dataset
2025-01-17 17:19:25,528:INFO:Defining folds
2025-01-17 17:19:25,528:INFO:Declaring metric variables
2025-01-17 17:19:25,530:INFO:Importing untrained model
2025-01-17 17:19:25,532:INFO:Naive Bayes Imported successfully
2025-01-17 17:19:25,536:INFO:Starting cross validation
2025-01-17 17:19:25,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:25,555:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,556:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,557:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,558:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,558:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,559:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,560:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,563:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,563:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,563:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,564:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,564:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,565:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,571:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,571:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,572:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,573:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,573:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,574:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,574:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,575:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,575:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,575:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,576:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,578:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,578:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,579:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,579:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,579:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,581:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,581:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,582:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,582:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,585:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,586:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,587:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,588:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,591:INFO:Calculating mean and std
2025-01-17 17:19:25,591:INFO:Creating metrics dataframe
2025-01-17 17:19:25,592:INFO:Uploading results into container
2025-01-17 17:19:25,592:INFO:Uploading model into container now
2025-01-17 17:19:25,593:INFO:_master_model_container: 3
2025-01-17 17:19:25,593:INFO:_display_container: 2
2025-01-17 17:19:25,593:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-01-17 17:19:25,593:INFO:create_model() successfully completed......................................
2025-01-17 17:19:25,643:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:25,643:INFO:Creating metrics dataframe
2025-01-17 17:19:25,646:INFO:Initializing Decision Tree Classifier
2025-01-17 17:19:25,647:INFO:Total runtime is 0.04537415107091268 minutes
2025-01-17 17:19:25,648:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:25,648:INFO:Initializing create_model()
2025-01-17 17:19:25,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:25,648:INFO:Checking exceptions
2025-01-17 17:19:25,648:INFO:Importing libraries
2025-01-17 17:19:25,648:INFO:Copying training dataset
2025-01-17 17:19:25,650:INFO:Defining folds
2025-01-17 17:19:25,650:INFO:Declaring metric variables
2025-01-17 17:19:25,652:INFO:Importing untrained model
2025-01-17 17:19:25,653:INFO:Decision Tree Classifier Imported successfully
2025-01-17 17:19:25,656:INFO:Starting cross validation
2025-01-17 17:19:25,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:25,671:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,672:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,686:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,685:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,688:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,688:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,689:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,689:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,689:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,689:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,689:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,690:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,690:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,691:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,691:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,692:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,692:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,693:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,693:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,694:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,695:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,695:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,695:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,696:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:25,696:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,696:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,697:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,698:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,712:INFO:Calculating mean and std
2025-01-17 17:19:25,712:INFO:Creating metrics dataframe
2025-01-17 17:19:25,713:INFO:Uploading results into container
2025-01-17 17:19:25,713:INFO:Uploading model into container now
2025-01-17 17:19:25,714:INFO:_master_model_container: 4
2025-01-17 17:19:25,714:INFO:_display_container: 2
2025-01-17 17:19:25,714:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-01-17 17:19:25,714:INFO:create_model() successfully completed......................................
2025-01-17 17:19:25,762:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:25,762:INFO:Creating metrics dataframe
2025-01-17 17:19:25,765:INFO:Initializing SVM - Linear Kernel
2025-01-17 17:19:25,765:INFO:Total runtime is 0.04735668500264486 minutes
2025-01-17 17:19:25,767:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:25,767:INFO:Initializing create_model()
2025-01-17 17:19:25,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:25,768:INFO:Checking exceptions
2025-01-17 17:19:25,768:INFO:Importing libraries
2025-01-17 17:19:25,768:INFO:Copying training dataset
2025-01-17 17:19:25,769:INFO:Defining folds
2025-01-17 17:19:25,769:INFO:Declaring metric variables
2025-01-17 17:19:25,771:INFO:Importing untrained model
2025-01-17 17:19:25,772:INFO:SVM - Linear Kernel Imported successfully
2025-01-17 17:19:25,775:INFO:Starting cross validation
2025-01-17 17:19:25,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:25,804:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,804:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,805:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,806:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:25,807:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,808:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,808:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,809:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,809:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,810:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,810:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,811:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:25,812:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,813:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,814:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,815:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,816:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,816:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,816:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:25,817:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,818:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,818:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,819:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,819:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,820:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,820:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,820:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,821:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,822:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,822:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,823:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,825:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,825:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,827:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,827:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:25,828:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,832:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,832:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,834:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,834:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:25,835:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,835:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,835:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,837:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,837:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:25,838:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,844:INFO:Calculating mean and std
2025-01-17 17:19:25,844:INFO:Creating metrics dataframe
2025-01-17 17:19:25,845:INFO:Uploading results into container
2025-01-17 17:19:25,845:INFO:Uploading model into container now
2025-01-17 17:19:25,846:INFO:_master_model_container: 5
2025-01-17 17:19:25,846:INFO:_display_container: 2
2025-01-17 17:19:25,846:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-01-17 17:19:25,846:INFO:create_model() successfully completed......................................
2025-01-17 17:19:25,889:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:25,889:INFO:Creating metrics dataframe
2025-01-17 17:19:25,893:INFO:Initializing Ridge Classifier
2025-01-17 17:19:25,893:INFO:Total runtime is 0.04947636524836223 minutes
2025-01-17 17:19:25,894:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:25,894:INFO:Initializing create_model()
2025-01-17 17:19:25,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:25,894:INFO:Checking exceptions
2025-01-17 17:19:25,894:INFO:Importing libraries
2025-01-17 17:19:25,894:INFO:Copying training dataset
2025-01-17 17:19:25,896:INFO:Defining folds
2025-01-17 17:19:25,896:INFO:Declaring metric variables
2025-01-17 17:19:25,897:INFO:Importing untrained model
2025-01-17 17:19:25,898:INFO:Ridge Classifier Imported successfully
2025-01-17 17:19:25,901:INFO:Starting cross validation
2025-01-17 17:19:25,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:25,915:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,916:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,917:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,918:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,923:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,923:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,925:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,925:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,926:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,926:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,927:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,928:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,928:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,930:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,931:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,934:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,935:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,935:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,936:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,936:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,936:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,936:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,937:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,937:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,938:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,938:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,938:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,939:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,939:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,940:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:25,941:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,941:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,942:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,942:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,943:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:25,955:INFO:Calculating mean and std
2025-01-17 17:19:25,955:INFO:Creating metrics dataframe
2025-01-17 17:19:25,956:INFO:Uploading results into container
2025-01-17 17:19:25,956:INFO:Uploading model into container now
2025-01-17 17:19:25,956:INFO:_master_model_container: 6
2025-01-17 17:19:25,956:INFO:_display_container: 2
2025-01-17 17:19:25,957:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-01-17 17:19:25,957:INFO:create_model() successfully completed......................................
2025-01-17 17:19:26,001:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:26,002:INFO:Creating metrics dataframe
2025-01-17 17:19:26,005:INFO:Initializing Random Forest Classifier
2025-01-17 17:19:26,005:INFO:Total runtime is 0.05135401884714763 minutes
2025-01-17 17:19:26,007:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:26,007:INFO:Initializing create_model()
2025-01-17 17:19:26,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:26,007:INFO:Checking exceptions
2025-01-17 17:19:26,007:INFO:Importing libraries
2025-01-17 17:19:26,007:INFO:Copying training dataset
2025-01-17 17:19:26,009:INFO:Defining folds
2025-01-17 17:19:26,009:INFO:Declaring metric variables
2025-01-17 17:19:26,010:INFO:Importing untrained model
2025-01-17 17:19:26,012:INFO:Random Forest Classifier Imported successfully
2025-01-17 17:19:26,016:INFO:Starting cross validation
2025-01-17 17:19:26,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:26,168:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,169:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,170:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,172:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,177:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,177:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,178:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,178:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,178:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,179:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,180:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,180:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,181:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,181:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,182:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,183:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,185:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,186:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,187:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,187:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,188:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,188:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,189:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,190:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,193:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,194:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,195:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,196:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,201:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,202:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,204:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,267:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,267:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,274:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:26,275:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,276:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,277:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,289:INFO:Calculating mean and std
2025-01-17 17:19:26,290:INFO:Creating metrics dataframe
2025-01-17 17:19:26,291:INFO:Uploading results into container
2025-01-17 17:19:26,291:INFO:Uploading model into container now
2025-01-17 17:19:26,291:INFO:_master_model_container: 7
2025-01-17 17:19:26,291:INFO:_display_container: 2
2025-01-17 17:19:26,291:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-01-17 17:19:26,291:INFO:create_model() successfully completed......................................
2025-01-17 17:19:26,334:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:26,334:INFO:Creating metrics dataframe
2025-01-17 17:19:26,338:INFO:Initializing Quadratic Discriminant Analysis
2025-01-17 17:19:26,338:INFO:Total runtime is 0.05689818461736044 minutes
2025-01-17 17:19:26,339:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:26,339:INFO:Initializing create_model()
2025-01-17 17:19:26,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:26,340:INFO:Checking exceptions
2025-01-17 17:19:26,340:INFO:Importing libraries
2025-01-17 17:19:26,340:INFO:Copying training dataset
2025-01-17 17:19:26,341:INFO:Defining folds
2025-01-17 17:19:26,341:INFO:Declaring metric variables
2025-01-17 17:19:26,342:INFO:Importing untrained model
2025-01-17 17:19:26,344:INFO:Quadratic Discriminant Analysis Imported successfully
2025-01-17 17:19:26,382:INFO:Starting cross validation
2025-01-17 17:19:26,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:26,402:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,404:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,404:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,404:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,406:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,407:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,409:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,410:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,410:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,411:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,411:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,414:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,414:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,416:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,416:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,417:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,418:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,419:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,419:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,420:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,422:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,423:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,423:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,424:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,424:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,424:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,425:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,425:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,425:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,426:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,426:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,426:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,427:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,427:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,427:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,428:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,428:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,429:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,441:INFO:Calculating mean and std
2025-01-17 17:19:26,442:INFO:Creating metrics dataframe
2025-01-17 17:19:26,442:INFO:Uploading results into container
2025-01-17 17:19:26,443:INFO:Uploading model into container now
2025-01-17 17:19:26,443:INFO:_master_model_container: 8
2025-01-17 17:19:26,443:INFO:_display_container: 2
2025-01-17 17:19:26,443:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-01-17 17:19:26,443:INFO:create_model() successfully completed......................................
2025-01-17 17:19:26,489:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:26,489:INFO:Creating metrics dataframe
2025-01-17 17:19:26,493:INFO:Initializing Ada Boost Classifier
2025-01-17 17:19:26,493:INFO:Total runtime is 0.059484450022379565 minutes
2025-01-17 17:19:26,495:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:26,495:INFO:Initializing create_model()
2025-01-17 17:19:26,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:26,496:INFO:Checking exceptions
2025-01-17 17:19:26,496:INFO:Importing libraries
2025-01-17 17:19:26,496:INFO:Copying training dataset
2025-01-17 17:19:26,498:INFO:Defining folds
2025-01-17 17:19:26,498:INFO:Declaring metric variables
2025-01-17 17:19:26,499:INFO:Importing untrained model
2025-01-17 17:19:26,501:INFO:Ada Boost Classifier Imported successfully
2025-01-17 17:19:26,504:INFO:Starting cross validation
2025-01-17 17:19:26,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:26,516:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,517:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,523:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,525:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,533:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,535:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,545:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,585:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,586:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,586:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,587:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,587:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,589:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,594:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,594:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,596:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,597:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,597:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,598:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,601:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,604:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,606:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,606:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,607:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,608:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,608:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,610:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,612:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:26,612:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,612:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,613:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,613:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,613:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,614:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,615:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,638:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,638:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,640:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,652:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,664:INFO:Calculating mean and std
2025-01-17 17:19:26,665:INFO:Creating metrics dataframe
2025-01-17 17:19:26,665:INFO:Uploading results into container
2025-01-17 17:19:26,666:INFO:Uploading model into container now
2025-01-17 17:19:26,666:INFO:_master_model_container: 9
2025-01-17 17:19:26,666:INFO:_display_container: 2
2025-01-17 17:19:26,666:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-01-17 17:19:26,666:INFO:create_model() successfully completed......................................
2025-01-17 17:19:26,709:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:26,709:INFO:Creating metrics dataframe
2025-01-17 17:19:26,713:INFO:Initializing Gradient Boosting Classifier
2025-01-17 17:19:26,713:INFO:Total runtime is 0.06315263112386069 minutes
2025-01-17 17:19:26,715:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:26,715:INFO:Initializing create_model()
2025-01-17 17:19:26,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:26,715:INFO:Checking exceptions
2025-01-17 17:19:26,715:INFO:Importing libraries
2025-01-17 17:19:26,715:INFO:Copying training dataset
2025-01-17 17:19:26,716:INFO:Defining folds
2025-01-17 17:19:26,716:INFO:Declaring metric variables
2025-01-17 17:19:26,717:INFO:Importing untrained model
2025-01-17 17:19:26,719:INFO:Gradient Boosting Classifier Imported successfully
2025-01-17 17:19:26,722:INFO:Starting cross validation
2025-01-17 17:19:26,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:26,886:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,888:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,888:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,888:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,889:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,890:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,891:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,893:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,895:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,895:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,896:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,897:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,910:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,911:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,912:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,913:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,917:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,918:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,919:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,920:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,922:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,923:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,923:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,925:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,925:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,926:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,934:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,935:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,995:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:26,996:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,997:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:26,998:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,000:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,000:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,001:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,002:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,012:INFO:Calculating mean and std
2025-01-17 17:19:27,013:INFO:Creating metrics dataframe
2025-01-17 17:19:27,014:INFO:Uploading results into container
2025-01-17 17:19:27,014:INFO:Uploading model into container now
2025-01-17 17:19:27,014:INFO:_master_model_container: 10
2025-01-17 17:19:27,014:INFO:_display_container: 2
2025-01-17 17:19:27,014:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-01-17 17:19:27,014:INFO:create_model() successfully completed......................................
2025-01-17 17:19:27,057:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:27,057:INFO:Creating metrics dataframe
2025-01-17 17:19:27,061:INFO:Initializing Linear Discriminant Analysis
2025-01-17 17:19:27,061:INFO:Total runtime is 0.06894521713256836 minutes
2025-01-17 17:19:27,062:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:27,062:INFO:Initializing create_model()
2025-01-17 17:19:27,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:27,063:INFO:Checking exceptions
2025-01-17 17:19:27,063:INFO:Importing libraries
2025-01-17 17:19:27,063:INFO:Copying training dataset
2025-01-17 17:19:27,064:INFO:Defining folds
2025-01-17 17:19:27,064:INFO:Declaring metric variables
2025-01-17 17:19:27,065:INFO:Importing untrained model
2025-01-17 17:19:27,066:INFO:Linear Discriminant Analysis Imported successfully
2025-01-17 17:19:27,069:INFO:Starting cross validation
2025-01-17 17:19:27,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:27,083:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,083:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,084:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,084:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,085:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,085:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,086:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,087:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,088:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,088:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,089:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,091:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,094:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,094:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,094:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,095:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,097:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,098:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,098:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,099:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,099:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,100:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,100:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,101:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,101:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,101:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,102:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,103:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,104:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,104:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,105:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,106:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,107:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,108:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:27,108:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,108:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,109:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,109:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,110:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,110:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,124:INFO:Calculating mean and std
2025-01-17 17:19:27,124:INFO:Creating metrics dataframe
2025-01-17 17:19:27,125:INFO:Uploading results into container
2025-01-17 17:19:27,125:INFO:Uploading model into container now
2025-01-17 17:19:27,126:INFO:_master_model_container: 11
2025-01-17 17:19:27,126:INFO:_display_container: 2
2025-01-17 17:19:27,126:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-01-17 17:19:27,126:INFO:create_model() successfully completed......................................
2025-01-17 17:19:27,171:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:27,171:INFO:Creating metrics dataframe
2025-01-17 17:19:27,176:INFO:Initializing Extra Trees Classifier
2025-01-17 17:19:27,176:INFO:Total runtime is 0.07086031834284465 minutes
2025-01-17 17:19:27,177:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:27,177:INFO:Initializing create_model()
2025-01-17 17:19:27,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:27,177:INFO:Checking exceptions
2025-01-17 17:19:27,177:INFO:Importing libraries
2025-01-17 17:19:27,177:INFO:Copying training dataset
2025-01-17 17:19:27,178:INFO:Defining folds
2025-01-17 17:19:27,178:INFO:Declaring metric variables
2025-01-17 17:19:27,180:INFO:Importing untrained model
2025-01-17 17:19:27,181:INFO:Extra Trees Classifier Imported successfully
2025-01-17 17:19:27,183:INFO:Starting cross validation
2025-01-17 17:19:27,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:27,291:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,292:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,293:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,294:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,296:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,297:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,298:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,298:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,299:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,299:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,299:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,300:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,300:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,301:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,301:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,302:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,303:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,304:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,305:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,306:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,307:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,308:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,309:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,310:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,328:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,329:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,331:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,333:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,364:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,365:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,366:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,367:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,369:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,369:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,370:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,372:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,385:INFO:Calculating mean and std
2025-01-17 17:19:27,386:INFO:Creating metrics dataframe
2025-01-17 17:19:27,387:INFO:Uploading results into container
2025-01-17 17:19:27,387:INFO:Uploading model into container now
2025-01-17 17:19:27,387:INFO:_master_model_container: 12
2025-01-17 17:19:27,387:INFO:_display_container: 2
2025-01-17 17:19:27,387:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-01-17 17:19:27,387:INFO:create_model() successfully completed......................................
2025-01-17 17:19:27,430:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:27,430:INFO:Creating metrics dataframe
2025-01-17 17:19:27,435:INFO:Initializing Extreme Gradient Boosting
2025-01-17 17:19:27,435:INFO:Total runtime is 0.07517461776733399 minutes
2025-01-17 17:19:27,436:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:27,436:INFO:Initializing create_model()
2025-01-17 17:19:27,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:27,436:INFO:Checking exceptions
2025-01-17 17:19:27,436:INFO:Importing libraries
2025-01-17 17:19:27,436:INFO:Copying training dataset
2025-01-17 17:19:27,437:INFO:Defining folds
2025-01-17 17:19:27,437:INFO:Declaring metric variables
2025-01-17 17:19:27,439:INFO:Importing untrained model
2025-01-17 17:19:27,440:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 17:19:27,443:INFO:Starting cross validation
2025-01-17 17:19:27,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:27,499:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,499:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,501:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,501:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,503:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,504:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,505:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,508:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,508:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,509:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,509:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,509:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,510:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,512:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,512:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,513:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,514:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,515:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,516:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,518:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,522:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,523:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,529:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,529:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,529:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:27,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,531:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,531:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,532:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:27,544:INFO:Calculating mean and std
2025-01-17 17:19:27,545:INFO:Creating metrics dataframe
2025-01-17 17:19:27,546:INFO:Uploading results into container
2025-01-17 17:19:27,546:INFO:Uploading model into container now
2025-01-17 17:19:27,546:INFO:_master_model_container: 13
2025-01-17 17:19:27,546:INFO:_display_container: 2
2025-01-17 17:19:27,546:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 17:19:27,546:INFO:create_model() successfully completed......................................
2025-01-17 17:19:27,589:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:27,589:INFO:Creating metrics dataframe
2025-01-17 17:19:27,593:INFO:Initializing Light Gradient Boosting Machine
2025-01-17 17:19:27,593:INFO:Total runtime is 0.07782214879989624 minutes
2025-01-17 17:19:27,595:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:27,595:INFO:Initializing create_model()
2025-01-17 17:19:27,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:27,595:INFO:Checking exceptions
2025-01-17 17:19:27,595:INFO:Importing libraries
2025-01-17 17:19:27,595:INFO:Copying training dataset
2025-01-17 17:19:27,596:INFO:Defining folds
2025-01-17 17:19:27,596:INFO:Declaring metric variables
2025-01-17 17:19:27,598:INFO:Importing untrained model
2025-01-17 17:19:27,599:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-17 17:19:27,602:INFO:Starting cross validation
2025-01-17 17:19:27,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:28,237:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,240:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,243:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,247:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,295:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,297:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,299:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,302:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,303:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,304:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,305:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,306:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,308:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,326:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,328:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,329:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,329:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,330:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,331:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,331:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,372:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,375:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,375:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,376:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,377:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,378:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,381:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,382:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,383:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,531:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,532:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,532:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,533:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,533:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,534:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,534:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,538:INFO:Calculating mean and std
2025-01-17 17:19:28,539:INFO:Creating metrics dataframe
2025-01-17 17:19:28,540:INFO:Uploading results into container
2025-01-17 17:19:28,540:INFO:Uploading model into container now
2025-01-17 17:19:28,540:INFO:_master_model_container: 14
2025-01-17 17:19:28,540:INFO:_display_container: 2
2025-01-17 17:19:28,540:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-01-17 17:19:28,540:INFO:create_model() successfully completed......................................
2025-01-17 17:19:28,583:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:28,583:INFO:Creating metrics dataframe
2025-01-17 17:19:28,587:INFO:Initializing Dummy Classifier
2025-01-17 17:19:28,587:INFO:Total runtime is 0.09438873132069905 minutes
2025-01-17 17:19:28,589:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:28,589:INFO:Initializing create_model()
2025-01-17 17:19:28,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1095ab640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:28,589:INFO:Checking exceptions
2025-01-17 17:19:28,589:INFO:Importing libraries
2025-01-17 17:19:28,589:INFO:Copying training dataset
2025-01-17 17:19:28,590:INFO:Defining folds
2025-01-17 17:19:28,590:INFO:Declaring metric variables
2025-01-17 17:19:28,591:INFO:Importing untrained model
2025-01-17 17:19:28,593:INFO:Dummy Classifier Imported successfully
2025-01-17 17:19:28,595:INFO:Starting cross validation
2025-01-17 17:19:28,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:28,642:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,643:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,644:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,645:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,646:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,648:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,648:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,652:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,652:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,652:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,653:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,653:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,653:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,654:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,656:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,658:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,658:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:28,659:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,659:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,660:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,660:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,660:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,660:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:28,661:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,661:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:28,671:INFO:Calculating mean and std
2025-01-17 17:19:28,672:INFO:Creating metrics dataframe
2025-01-17 17:19:28,673:INFO:Uploading results into container
2025-01-17 17:19:28,673:INFO:Uploading model into container now
2025-01-17 17:19:28,673:INFO:_master_model_container: 15
2025-01-17 17:19:28,673:INFO:_display_container: 2
2025-01-17 17:19:28,673:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-01-17 17:19:28,673:INFO:create_model() successfully completed......................................
2025-01-17 17:19:28,716:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:28,716:INFO:Creating metrics dataframe
2025-01-17 17:19:28,723:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-17 17:19:28,727:INFO:Initializing create_model()
2025-01-17 17:19:28,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:28,727:INFO:Checking exceptions
2025-01-17 17:19:28,728:INFO:Importing libraries
2025-01-17 17:19:28,728:INFO:Copying training dataset
2025-01-17 17:19:28,729:INFO:Defining folds
2025-01-17 17:19:28,730:INFO:Declaring metric variables
2025-01-17 17:19:28,730:INFO:Importing untrained model
2025-01-17 17:19:28,730:INFO:Declaring custom model
2025-01-17 17:19:28,730:INFO:Logistic Regression Imported successfully
2025-01-17 17:19:28,731:INFO:Cross validation set to False
2025-01-17 17:19:28,731:INFO:Fitting Model
2025-01-17 17:19:28,739:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 17:19:28,739:INFO:create_model() successfully completed......................................
2025-01-17 17:19:28,799:INFO:_master_model_container: 15
2025-01-17 17:19:28,799:INFO:_display_container: 2
2025-01-17 17:19:28,799:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 17:19:28,799:INFO:compare_models() successfully completed......................................
2025-01-17 17:19:42,971:INFO:Initializing compare_models()
2025-01-17 17:19:42,972:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-01-17 17:19:42,972:INFO:Checking exceptions
2025-01-17 17:19:42,985:INFO:Preparing display monitor
2025-01-17 17:19:43,055:INFO:Initializing Logistic Regression
2025-01-17 17:19:43,091:INFO:Total runtime is 0.0006053487459818523 minutes
2025-01-17 17:19:43,094:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:43,094:INFO:Initializing create_model()
2025-01-17 17:19:43,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:43,095:INFO:Checking exceptions
2025-01-17 17:19:43,095:INFO:Importing libraries
2025-01-17 17:19:43,095:INFO:Copying training dataset
2025-01-17 17:19:43,100:INFO:Defining folds
2025-01-17 17:19:43,100:INFO:Declaring metric variables
2025-01-17 17:19:43,103:INFO:Importing untrained model
2025-01-17 17:19:43,105:INFO:Logistic Regression Imported successfully
2025-01-17 17:19:43,108:INFO:Starting cross validation
2025-01-17 17:19:43,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:43,200:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,202:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,202:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,202:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,204:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,204:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,205:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,205:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,207:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,209:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,210:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,210:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,212:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,212:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,213:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,213:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,214:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,214:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,214:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,215:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,215:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,227:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,228:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,229:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,229:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,229:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,230:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,231:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,231:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,231:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,232:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,232:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,232:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,232:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,233:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,234:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,235:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,243:INFO:Calculating mean and std
2025-01-17 17:19:43,243:INFO:Creating metrics dataframe
2025-01-17 17:19:43,244:INFO:Uploading results into container
2025-01-17 17:19:43,245:INFO:Uploading model into container now
2025-01-17 17:19:43,245:INFO:_master_model_container: 1
2025-01-17 17:19:43,245:INFO:_display_container: 2
2025-01-17 17:19:43,245:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 17:19:43,245:INFO:create_model() successfully completed......................................
2025-01-17 17:19:43,325:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:43,325:INFO:Creating metrics dataframe
2025-01-17 17:19:43,328:INFO:Initializing K Neighbors Classifier
2025-01-17 17:19:43,328:INFO:Total runtime is 0.004551517963409424 minutes
2025-01-17 17:19:43,330:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:43,330:INFO:Initializing create_model()
2025-01-17 17:19:43,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:43,330:INFO:Checking exceptions
2025-01-17 17:19:43,330:INFO:Importing libraries
2025-01-17 17:19:43,330:INFO:Copying training dataset
2025-01-17 17:19:43,332:INFO:Defining folds
2025-01-17 17:19:43,332:INFO:Declaring metric variables
2025-01-17 17:19:43,333:INFO:Importing untrained model
2025-01-17 17:19:43,335:INFO:K Neighbors Classifier Imported successfully
2025-01-17 17:19:43,338:INFO:Starting cross validation
2025-01-17 17:19:43,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:43,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,376:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,377:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,378:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,378:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,379:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,399:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,400:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,399:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,401:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,401:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,402:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,402:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,402:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,406:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,406:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,406:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,406:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,407:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,407:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,407:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,407:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,408:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,409:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,409:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,410:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,411:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,413:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,414:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,415:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,416:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,425:INFO:Calculating mean and std
2025-01-17 17:19:43,426:INFO:Creating metrics dataframe
2025-01-17 17:19:43,426:INFO:Uploading results into container
2025-01-17 17:19:43,426:INFO:Uploading model into container now
2025-01-17 17:19:43,427:INFO:_master_model_container: 2
2025-01-17 17:19:43,427:INFO:_display_container: 2
2025-01-17 17:19:43,427:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-01-17 17:19:43,427:INFO:create_model() successfully completed......................................
2025-01-17 17:19:43,477:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:43,477:INFO:Creating metrics dataframe
2025-01-17 17:19:43,481:INFO:Initializing Naive Bayes
2025-01-17 17:19:43,481:INFO:Total runtime is 0.007098400592803955 minutes
2025-01-17 17:19:43,482:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:43,483:INFO:Initializing create_model()
2025-01-17 17:19:43,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:43,483:INFO:Checking exceptions
2025-01-17 17:19:43,483:INFO:Importing libraries
2025-01-17 17:19:43,483:INFO:Copying training dataset
2025-01-17 17:19:43,484:INFO:Defining folds
2025-01-17 17:19:43,484:INFO:Declaring metric variables
2025-01-17 17:19:43,486:INFO:Importing untrained model
2025-01-17 17:19:43,488:INFO:Naive Bayes Imported successfully
2025-01-17 17:19:43,491:INFO:Starting cross validation
2025-01-17 17:19:43,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:43,505:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,505:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,506:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,507:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,518:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,518:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,519:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,520:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,520:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,520:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,522:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,522:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,523:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,523:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,524:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,525:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,525:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,525:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,526:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,526:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,526:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,529:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,529:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,534:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,535:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,537:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,538:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,538:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,539:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,540:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,542:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,546:INFO:Calculating mean and std
2025-01-17 17:19:43,546:INFO:Creating metrics dataframe
2025-01-17 17:19:43,547:INFO:Uploading results into container
2025-01-17 17:19:43,547:INFO:Uploading model into container now
2025-01-17 17:19:43,547:INFO:_master_model_container: 3
2025-01-17 17:19:43,547:INFO:_display_container: 2
2025-01-17 17:19:43,547:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-01-17 17:19:43,547:INFO:create_model() successfully completed......................................
2025-01-17 17:19:43,599:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:43,599:INFO:Creating metrics dataframe
2025-01-17 17:19:43,603:INFO:Initializing Decision Tree Classifier
2025-01-17 17:19:43,603:INFO:Total runtime is 0.009126802285512287 minutes
2025-01-17 17:19:43,604:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:43,605:INFO:Initializing create_model()
2025-01-17 17:19:43,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:43,605:INFO:Checking exceptions
2025-01-17 17:19:43,605:INFO:Importing libraries
2025-01-17 17:19:43,605:INFO:Copying training dataset
2025-01-17 17:19:43,607:INFO:Defining folds
2025-01-17 17:19:43,607:INFO:Declaring metric variables
2025-01-17 17:19:43,608:INFO:Importing untrained model
2025-01-17 17:19:43,610:INFO:Decision Tree Classifier Imported successfully
2025-01-17 17:19:43,614:INFO:Starting cross validation
2025-01-17 17:19:43,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:43,636:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,637:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,637:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,640:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,641:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,643:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,648:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,652:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,658:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,659:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,659:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,660:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,661:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,661:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,661:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,662:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,663:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,664:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,664:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,665:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,665:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,666:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,666:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:43,667:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,667:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,667:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,668:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,668:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,669:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,682:INFO:Calculating mean and std
2025-01-17 17:19:43,683:INFO:Creating metrics dataframe
2025-01-17 17:19:43,683:INFO:Uploading results into container
2025-01-17 17:19:43,684:INFO:Uploading model into container now
2025-01-17 17:19:43,684:INFO:_master_model_container: 4
2025-01-17 17:19:43,684:INFO:_display_container: 2
2025-01-17 17:19:43,684:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-01-17 17:19:43,684:INFO:create_model() successfully completed......................................
2025-01-17 17:19:43,733:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:43,733:INFO:Creating metrics dataframe
2025-01-17 17:19:43,736:INFO:Initializing SVM - Linear Kernel
2025-01-17 17:19:43,736:INFO:Total runtime is 0.011350568135579426 minutes
2025-01-17 17:19:43,738:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:43,738:INFO:Initializing create_model()
2025-01-17 17:19:43,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:43,738:INFO:Checking exceptions
2025-01-17 17:19:43,738:INFO:Importing libraries
2025-01-17 17:19:43,738:INFO:Copying training dataset
2025-01-17 17:19:43,739:INFO:Defining folds
2025-01-17 17:19:43,739:INFO:Declaring metric variables
2025-01-17 17:19:43,741:INFO:Importing untrained model
2025-01-17 17:19:43,743:INFO:SVM - Linear Kernel Imported successfully
2025-01-17 17:19:43,746:INFO:Starting cross validation
2025-01-17 17:19:43,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:43,775:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,776:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,778:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,779:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:43,779:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,783:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,785:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,786:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,787:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:43,787:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,789:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,790:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,790:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,790:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,790:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:43,791:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,791:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,792:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,792:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,793:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,793:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,795:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,796:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,797:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,798:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,799:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,800:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,803:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,804:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,805:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,806:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,810:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,812:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,812:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,813:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,813:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,813:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:43,814:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,814:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,814:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:43,815:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,815:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,816:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,817:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,817:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:43,818:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,821:INFO:Calculating mean and std
2025-01-17 17:19:43,821:INFO:Creating metrics dataframe
2025-01-17 17:19:43,822:INFO:Uploading results into container
2025-01-17 17:19:43,822:INFO:Uploading model into container now
2025-01-17 17:19:43,822:INFO:_master_model_container: 5
2025-01-17 17:19:43,822:INFO:_display_container: 2
2025-01-17 17:19:43,823:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-01-17 17:19:43,823:INFO:create_model() successfully completed......................................
2025-01-17 17:19:43,873:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:43,873:INFO:Creating metrics dataframe
2025-01-17 17:19:43,877:INFO:Initializing Ridge Classifier
2025-01-17 17:19:43,877:INFO:Total runtime is 0.013696646690368651 minutes
2025-01-17 17:19:43,878:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:43,879:INFO:Initializing create_model()
2025-01-17 17:19:43,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:43,879:INFO:Checking exceptions
2025-01-17 17:19:43,879:INFO:Importing libraries
2025-01-17 17:19:43,879:INFO:Copying training dataset
2025-01-17 17:19:43,880:INFO:Defining folds
2025-01-17 17:19:43,880:INFO:Declaring metric variables
2025-01-17 17:19:43,882:INFO:Importing untrained model
2025-01-17 17:19:43,883:INFO:Ridge Classifier Imported successfully
2025-01-17 17:19:43,886:INFO:Starting cross validation
2025-01-17 17:19:43,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:43,903:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,904:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,904:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,904:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,905:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,906:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,907:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,907:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,908:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,909:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,910:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,914:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,920:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,920:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,922:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,922:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,922:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,923:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,923:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,925:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,925:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,925:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,926:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,926:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,927:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,927:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,928:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,929:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,930:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,930:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,931:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:43,931:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,934:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:43,937:INFO:Calculating mean and std
2025-01-17 17:19:43,937:INFO:Creating metrics dataframe
2025-01-17 17:19:43,938:INFO:Uploading results into container
2025-01-17 17:19:43,938:INFO:Uploading model into container now
2025-01-17 17:19:43,938:INFO:_master_model_container: 6
2025-01-17 17:19:43,938:INFO:_display_container: 2
2025-01-17 17:19:43,939:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-01-17 17:19:43,939:INFO:create_model() successfully completed......................................
2025-01-17 17:19:43,990:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:43,990:INFO:Creating metrics dataframe
2025-01-17 17:19:43,994:INFO:Initializing Random Forest Classifier
2025-01-17 17:19:43,994:INFO:Total runtime is 0.01565413475036621 minutes
2025-01-17 17:19:43,996:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:43,996:INFO:Initializing create_model()
2025-01-17 17:19:43,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:43,996:INFO:Checking exceptions
2025-01-17 17:19:43,996:INFO:Importing libraries
2025-01-17 17:19:43,996:INFO:Copying training dataset
2025-01-17 17:19:43,998:INFO:Defining folds
2025-01-17 17:19:43,998:INFO:Declaring metric variables
2025-01-17 17:19:43,999:INFO:Importing untrained model
2025-01-17 17:19:44,001:INFO:Random Forest Classifier Imported successfully
2025-01-17 17:19:44,004:INFO:Starting cross validation
2025-01-17 17:19:44,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:44,146:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,147:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,149:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,150:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,155:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,157:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,158:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,158:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,159:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,160:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,160:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,161:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,162:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,162:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,163:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,164:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,164:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,165:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,166:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,167:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,174:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,175:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,175:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,176:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,176:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,177:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,178:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,179:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,190:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,191:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,192:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,193:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,250:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,251:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,252:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,253:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,261:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:44,262:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,263:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,264:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,267:INFO:Calculating mean and std
2025-01-17 17:19:44,268:INFO:Creating metrics dataframe
2025-01-17 17:19:44,269:INFO:Uploading results into container
2025-01-17 17:19:44,269:INFO:Uploading model into container now
2025-01-17 17:19:44,269:INFO:_master_model_container: 7
2025-01-17 17:19:44,269:INFO:_display_container: 2
2025-01-17 17:19:44,270:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-01-17 17:19:44,270:INFO:create_model() successfully completed......................................
2025-01-17 17:19:44,314:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:44,315:INFO:Creating metrics dataframe
2025-01-17 17:19:44,318:INFO:Initializing Quadratic Discriminant Analysis
2025-01-17 17:19:44,319:INFO:Total runtime is 0.021057180563608804 minutes
2025-01-17 17:19:44,320:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:44,320:INFO:Initializing create_model()
2025-01-17 17:19:44,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:44,320:INFO:Checking exceptions
2025-01-17 17:19:44,320:INFO:Importing libraries
2025-01-17 17:19:44,320:INFO:Copying training dataset
2025-01-17 17:19:44,322:INFO:Defining folds
2025-01-17 17:19:44,322:INFO:Declaring metric variables
2025-01-17 17:19:44,323:INFO:Importing untrained model
2025-01-17 17:19:44,324:INFO:Quadratic Discriminant Analysis Imported successfully
2025-01-17 17:19:44,328:INFO:Starting cross validation
2025-01-17 17:19:44,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:44,343:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,344:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,344:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,346:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,346:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,346:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,347:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,347:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,348:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,350:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,351:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,351:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,355:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,356:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,357:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,357:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,358:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,358:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,358:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,359:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,359:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,360:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,360:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,361:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,364:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,365:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,366:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,367:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,367:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,367:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,367:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,368:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,368:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,369:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,369:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,369:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,370:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,370:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,372:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,384:INFO:Calculating mean and std
2025-01-17 17:19:44,385:INFO:Creating metrics dataframe
2025-01-17 17:19:44,385:INFO:Uploading results into container
2025-01-17 17:19:44,386:INFO:Uploading model into container now
2025-01-17 17:19:44,386:INFO:_master_model_container: 8
2025-01-17 17:19:44,386:INFO:_display_container: 2
2025-01-17 17:19:44,386:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-01-17 17:19:44,386:INFO:create_model() successfully completed......................................
2025-01-17 17:19:44,430:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:44,430:INFO:Creating metrics dataframe
2025-01-17 17:19:44,433:INFO:Initializing Ada Boost Classifier
2025-01-17 17:19:44,433:INFO:Total runtime is 0.022972798347473143 minutes
2025-01-17 17:19:44,435:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:44,435:INFO:Initializing create_model()
2025-01-17 17:19:44,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:44,435:INFO:Checking exceptions
2025-01-17 17:19:44,435:INFO:Importing libraries
2025-01-17 17:19:44,435:INFO:Copying training dataset
2025-01-17 17:19:44,437:INFO:Defining folds
2025-01-17 17:19:44,437:INFO:Declaring metric variables
2025-01-17 17:19:44,438:INFO:Importing untrained model
2025-01-17 17:19:44,439:INFO:Ada Boost Classifier Imported successfully
2025-01-17 17:19:44,442:INFO:Starting cross validation
2025-01-17 17:19:44,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:44,452:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,481:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,491:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,492:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,496:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,498:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,500:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,501:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,610:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,618:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,618:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,619:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,619:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,620:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,622:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,630:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,632:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,632:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,633:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,633:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,633:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,634:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,634:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,635:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,635:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,636:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,637:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,638:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,640:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,640:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 17:19:44,640:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,641:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,642:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,642:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,643:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,648:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,676:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,678:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,678:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,679:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,680:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,681:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,684:INFO:Calculating mean and std
2025-01-17 17:19:44,684:INFO:Creating metrics dataframe
2025-01-17 17:19:44,685:INFO:Uploading results into container
2025-01-17 17:19:44,685:INFO:Uploading model into container now
2025-01-17 17:19:44,686:INFO:_master_model_container: 9
2025-01-17 17:19:44,686:INFO:_display_container: 2
2025-01-17 17:19:44,686:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-01-17 17:19:44,686:INFO:create_model() successfully completed......................................
2025-01-17 17:19:44,730:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:44,730:INFO:Creating metrics dataframe
2025-01-17 17:19:44,734:INFO:Initializing Gradient Boosting Classifier
2025-01-17 17:19:44,734:INFO:Total runtime is 0.027983049551645912 minutes
2025-01-17 17:19:44,735:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:44,736:INFO:Initializing create_model()
2025-01-17 17:19:44,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:44,736:INFO:Checking exceptions
2025-01-17 17:19:44,736:INFO:Importing libraries
2025-01-17 17:19:44,736:INFO:Copying training dataset
2025-01-17 17:19:44,737:INFO:Defining folds
2025-01-17 17:19:44,737:INFO:Declaring metric variables
2025-01-17 17:19:44,739:INFO:Importing untrained model
2025-01-17 17:19:44,740:INFO:Gradient Boosting Classifier Imported successfully
2025-01-17 17:19:44,743:INFO:Starting cross validation
2025-01-17 17:19:44,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:44,901:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,902:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,903:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,904:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,929:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,930:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,930:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,931:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,931:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,932:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,932:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,932:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,932:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,934:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,936:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,937:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,938:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,939:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,948:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,948:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,948:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,948:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,949:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,949:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,950:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,950:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,958:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:44,959:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,960:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:44,961:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,028:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,029:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,030:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,031:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,038:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,039:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,039:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,040:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,052:INFO:Calculating mean and std
2025-01-17 17:19:45,052:INFO:Creating metrics dataframe
2025-01-17 17:19:45,053:INFO:Uploading results into container
2025-01-17 17:19:45,053:INFO:Uploading model into container now
2025-01-17 17:19:45,054:INFO:_master_model_container: 10
2025-01-17 17:19:45,054:INFO:_display_container: 2
2025-01-17 17:19:45,054:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-01-17 17:19:45,054:INFO:create_model() successfully completed......................................
2025-01-17 17:19:45,097:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:45,097:INFO:Creating metrics dataframe
2025-01-17 17:19:45,101:INFO:Initializing Linear Discriminant Analysis
2025-01-17 17:19:45,101:INFO:Total runtime is 0.034099717934926346 minutes
2025-01-17 17:19:45,103:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:45,103:INFO:Initializing create_model()
2025-01-17 17:19:45,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:45,103:INFO:Checking exceptions
2025-01-17 17:19:45,103:INFO:Importing libraries
2025-01-17 17:19:45,103:INFO:Copying training dataset
2025-01-17 17:19:45,104:INFO:Defining folds
2025-01-17 17:19:45,104:INFO:Declaring metric variables
2025-01-17 17:19:45,106:INFO:Importing untrained model
2025-01-17 17:19:45,107:INFO:Linear Discriminant Analysis Imported successfully
2025-01-17 17:19:45,110:INFO:Starting cross validation
2025-01-17 17:19:45,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:45,123:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,124:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,125:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,126:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,131:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,131:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,132:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,132:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,133:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,133:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,135:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,135:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,140:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,140:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,141:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,142:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,142:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,142:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,142:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,143:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,143:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,144:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,144:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,144:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,145:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,145:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,146:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,147:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,147:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,147:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,148:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,149:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,152:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,152:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 17:19:45,152:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,152:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,153:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,153:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,154:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,154:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,165:INFO:Calculating mean and std
2025-01-17 17:19:45,166:INFO:Creating metrics dataframe
2025-01-17 17:19:45,166:INFO:Uploading results into container
2025-01-17 17:19:45,167:INFO:Uploading model into container now
2025-01-17 17:19:45,167:INFO:_master_model_container: 11
2025-01-17 17:19:45,167:INFO:_display_container: 2
2025-01-17 17:19:45,167:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-01-17 17:19:45,167:INFO:create_model() successfully completed......................................
2025-01-17 17:19:45,210:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:45,210:INFO:Creating metrics dataframe
2025-01-17 17:19:45,215:INFO:Initializing Extra Trees Classifier
2025-01-17 17:19:45,215:INFO:Total runtime is 0.035993635654449456 minutes
2025-01-17 17:19:45,216:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:45,216:INFO:Initializing create_model()
2025-01-17 17:19:45,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:45,216:INFO:Checking exceptions
2025-01-17 17:19:45,216:INFO:Importing libraries
2025-01-17 17:19:45,216:INFO:Copying training dataset
2025-01-17 17:19:45,218:INFO:Defining folds
2025-01-17 17:19:45,218:INFO:Declaring metric variables
2025-01-17 17:19:45,219:INFO:Importing untrained model
2025-01-17 17:19:45,220:INFO:Extra Trees Classifier Imported successfully
2025-01-17 17:19:45,223:INFO:Starting cross validation
2025-01-17 17:19:45,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:45,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,375:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,376:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,378:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,378:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,378:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,378:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,381:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,381:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,387:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,389:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,390:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,391:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,396:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,396:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,397:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,398:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,399:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,399:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,400:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,401:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,402:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,404:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,404:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,406:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,448:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,449:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,450:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,451:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,457:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,457:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,458:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,459:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,462:INFO:Calculating mean and std
2025-01-17 17:19:45,462:INFO:Creating metrics dataframe
2025-01-17 17:19:45,463:INFO:Uploading results into container
2025-01-17 17:19:45,463:INFO:Uploading model into container now
2025-01-17 17:19:45,463:INFO:_master_model_container: 12
2025-01-17 17:19:45,463:INFO:_display_container: 2
2025-01-17 17:19:45,464:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-01-17 17:19:45,464:INFO:create_model() successfully completed......................................
2025-01-17 17:19:45,509:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:45,509:INFO:Creating metrics dataframe
2025-01-17 17:19:45,514:INFO:Initializing Extreme Gradient Boosting
2025-01-17 17:19:45,514:INFO:Total runtime is 0.040975284576416006 minutes
2025-01-17 17:19:45,515:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:45,515:INFO:Initializing create_model()
2025-01-17 17:19:45,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:45,515:INFO:Checking exceptions
2025-01-17 17:19:45,515:INFO:Importing libraries
2025-01-17 17:19:45,515:INFO:Copying training dataset
2025-01-17 17:19:45,516:INFO:Defining folds
2025-01-17 17:19:45,516:INFO:Declaring metric variables
2025-01-17 17:19:45,518:INFO:Importing untrained model
2025-01-17 17:19:45,519:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 17:19:45,521:INFO:Starting cross validation
2025-01-17 17:19:45,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:45,554:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,555:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,556:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,557:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,557:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,557:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,558:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,559:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,560:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,561:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,562:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,563:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,565:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,569:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,570:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,570:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,572:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,576:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,578:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,579:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,581:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,584:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,584:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,585:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,585:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,586:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,587:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,588:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,589:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,589:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,590:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,590:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,591:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,591:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,591:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:45,592:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,592:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,593:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,594:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:45,606:INFO:Calculating mean and std
2025-01-17 17:19:45,607:INFO:Creating metrics dataframe
2025-01-17 17:19:45,608:INFO:Uploading results into container
2025-01-17 17:19:45,608:INFO:Uploading model into container now
2025-01-17 17:19:45,608:INFO:_master_model_container: 13
2025-01-17 17:19:45,608:INFO:_display_container: 2
2025-01-17 17:19:45,609:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 17:19:45,609:INFO:create_model() successfully completed......................................
2025-01-17 17:19:45,661:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:45,661:INFO:Creating metrics dataframe
2025-01-17 17:19:45,665:INFO:Initializing Light Gradient Boosting Machine
2025-01-17 17:19:45,665:INFO:Total runtime is 0.04350175062815347 minutes
2025-01-17 17:19:45,667:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:45,667:INFO:Initializing create_model()
2025-01-17 17:19:45,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:45,667:INFO:Checking exceptions
2025-01-17 17:19:45,667:INFO:Importing libraries
2025-01-17 17:19:45,667:INFO:Copying training dataset
2025-01-17 17:19:45,669:INFO:Defining folds
2025-01-17 17:19:45,669:INFO:Declaring metric variables
2025-01-17 17:19:45,670:INFO:Importing untrained model
2025-01-17 17:19:45,671:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-17 17:19:45,674:INFO:Starting cross validation
2025-01-17 17:19:45,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:46,334:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,335:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,336:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,337:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,344:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,345:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,346:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,347:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,355:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,356:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,357:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,357:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,358:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,359:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,360:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,362:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,370:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,370:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,372:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,372:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,372:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,381:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,383:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,568:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,569:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,593:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,593:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,594:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,595:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,597:INFO:Calculating mean and std
2025-01-17 17:19:46,598:INFO:Creating metrics dataframe
2025-01-17 17:19:46,598:INFO:Uploading results into container
2025-01-17 17:19:46,599:INFO:Uploading model into container now
2025-01-17 17:19:46,599:INFO:_master_model_container: 14
2025-01-17 17:19:46,599:INFO:_display_container: 2
2025-01-17 17:19:46,599:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-01-17 17:19:46,599:INFO:create_model() successfully completed......................................
2025-01-17 17:19:46,648:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:46,648:INFO:Creating metrics dataframe
2025-01-17 17:19:46,653:INFO:Initializing Dummy Classifier
2025-01-17 17:19:46,653:INFO:Total runtime is 0.05995783408482869 minutes
2025-01-17 17:19:46,654:INFO:SubProcess create_model() called ==================================
2025-01-17 17:19:46,654:INFO:Initializing create_model()
2025-01-17 17:19:46,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13ecd2ce0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:46,654:INFO:Checking exceptions
2025-01-17 17:19:46,654:INFO:Importing libraries
2025-01-17 17:19:46,654:INFO:Copying training dataset
2025-01-17 17:19:46,655:INFO:Defining folds
2025-01-17 17:19:46,655:INFO:Declaring metric variables
2025-01-17 17:19:46,657:INFO:Importing untrained model
2025-01-17 17:19:46,658:INFO:Dummy Classifier Imported successfully
2025-01-17 17:19:46,660:INFO:Starting cross validation
2025-01-17 17:19:46,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 17:19:46,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,676:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,676:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,679:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,680:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,682:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,685:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,686:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,688:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,688:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,688:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,688:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,689:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,689:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,690:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,690:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,690:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,691:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,691:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,691:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,691:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,693:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,693:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,693:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,695:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,697:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,697:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,698:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,698:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 17:19:46,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,700:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,700:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,700:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,700:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,701:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,701:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 17:19:46,702:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 17:19:46,714:INFO:Calculating mean and std
2025-01-17 17:19:46,715:INFO:Creating metrics dataframe
2025-01-17 17:19:46,716:INFO:Uploading results into container
2025-01-17 17:19:46,716:INFO:Uploading model into container now
2025-01-17 17:19:46,716:INFO:_master_model_container: 15
2025-01-17 17:19:46,716:INFO:_display_container: 2
2025-01-17 17:19:46,716:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-01-17 17:19:46,716:INFO:create_model() successfully completed......................................
2025-01-17 17:19:46,764:INFO:SubProcess create_model() end ==================================
2025-01-17 17:19:46,764:INFO:Creating metrics dataframe
2025-01-17 17:19:46,768:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-17 17:19:46,771:INFO:Initializing create_model()
2025-01-17 17:19:46,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x13f934a30>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 17:19:46,772:INFO:Checking exceptions
2025-01-17 17:19:46,772:INFO:Importing libraries
2025-01-17 17:19:46,772:INFO:Copying training dataset
2025-01-17 17:19:46,773:INFO:Defining folds
2025-01-17 17:19:46,774:INFO:Declaring metric variables
2025-01-17 17:19:46,774:INFO:Importing untrained model
2025-01-17 17:19:46,774:INFO:Declaring custom model
2025-01-17 17:19:46,774:INFO:Logistic Regression Imported successfully
2025-01-17 17:19:46,774:INFO:Cross validation set to False
2025-01-17 17:19:46,774:INFO:Fitting Model
2025-01-17 17:19:46,783:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 17:19:46,783:INFO:create_model() successfully completed......................................
2025-01-17 17:19:46,848:INFO:_master_model_container: 15
2025-01-17 17:19:46,848:INFO:_display_container: 2
2025-01-17 17:19:46,848:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 17:19:46,848:INFO:compare_models() successfully completed......................................
2025-01-17 17:20:23,880:INFO:Initializing plot_model()
2025-01-17 17:20:23,881:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, system=True)
2025-01-17 17:20:23,882:INFO:Checking exceptions
2025-01-17 17:20:23,901:INFO:Preloading libraries
2025-01-17 17:20:23,903:INFO:Copying training dataset
2025-01-17 17:20:23,903:INFO:Plot type: confusion_matrix
2025-01-17 17:20:23,972:INFO:Fitting Model
2025-01-17 17:20:23,975:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-01-17 17:20:23,975:INFO:Scoring test/hold-out set
2025-01-17 17:20:24,106:INFO:Visual Rendered Successfully
2025-01-17 17:20:24,195:INFO:plot_model() successfully completed......................................
2025-01-17 17:29:51,604:INFO:Initializing plot_model()
2025-01-17 17:29:51,605:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, system=True)
2025-01-17 17:29:51,606:INFO:Checking exceptions
2025-01-17 17:29:51,621:INFO:Preloading libraries
2025-01-17 17:29:51,621:INFO:Copying training dataset
2025-01-17 17:29:51,622:INFO:Plot type: auc
2025-01-17 17:29:51,680:INFO:Fitting Model
2025-01-17 17:29:51,680:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-01-17 17:29:51,680:INFO:Scoring test/hold-out set
2025-01-17 17:29:51,757:INFO:Visual Rendered Successfully
2025-01-17 17:29:51,842:INFO:plot_model() successfully completed......................................
2025-01-17 17:31:03,414:INFO:Initializing plot_model()
2025-01-17 17:31:03,415:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, system=True)
2025-01-17 17:31:03,416:INFO:Checking exceptions
2025-01-17 17:31:03,422:INFO:Preloading libraries
2025-01-17 17:31:03,422:INFO:Copying training dataset
2025-01-17 17:31:03,423:INFO:Plot type: feature
2025-01-17 17:31:03,526:INFO:Visual Rendered Successfully
2025-01-17 17:31:03,576:INFO:plot_model() successfully completed......................................
2025-01-17 17:31:32,319:INFO:Initializing evaluate_model()
2025-01-17 17:31:32,319:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-01-17 17:31:32,337:INFO:Initializing plot_model()
2025-01-17 17:31:32,337:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fe93d30>, system=True)
2025-01-17 17:31:32,337:INFO:Checking exceptions
2025-01-17 17:31:32,340:INFO:Preloading libraries
2025-01-17 17:31:32,340:INFO:Copying training dataset
2025-01-17 17:31:32,340:INFO:Plot type: pipeline
2025-01-17 17:31:32,430:INFO:Visual Rendered Successfully
2025-01-17 17:31:32,475:INFO:plot_model() successfully completed......................................
2025-01-17 19:48:05,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 19:48:05,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 19:48:05,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 19:48:05,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 19:48:05,508:INFO:PyCaret ClassificationExperiment
2025-01-17 19:48:05,508:INFO:Logging name: clf-default-name
2025-01-17 19:48:05,508:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-01-17 19:48:05,508:INFO:version 3.3.1
2025-01-17 19:48:05,508:INFO:Initializing setup()
2025-01-17 19:48:05,508:INFO:self.USI: d9cc
2025-01-17 19:48:05,508:INFO:self._variable_keys: {'memory', '_ml_usecase', 'data', 'log_plots_param', 'idx', 'fold_groups_param', '_available_plots', 'seed', 'X_train', 'pipeline', 'y_test', 'y', 'fold_generator', 'fix_imbalance', 'html_param', 'gpu_param', 'exp_id', 'fold_shuffle_param', 'target_param', 'exp_name_log', 'is_multiclass', 'y_train', 'gpu_n_jobs_param', 'n_jobs_param', 'X', 'USI', 'logging_param', 'X_test'}
2025-01-17 19:48:05,508:INFO:Checking environment
2025-01-17 19:48:05,508:INFO:python_version: 3.10.13
2025-01-17 19:48:05,508:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-17 19:48:05,508:INFO:machine: arm64
2025-01-17 19:48:05,508:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-17 19:48:05,508:INFO:Memory: svmem(total=8589934592, available=1403633664, percent=83.7, used=2950201344, free=64028672, active=1387134976, inactive=1264959488, wired=1563066368)
2025-01-17 19:48:05,508:INFO:Physical Core: 8
2025-01-17 19:48:05,508:INFO:Logical Core: 8
2025-01-17 19:48:05,508:INFO:Checking libraries
2025-01-17 19:48:05,508:INFO:System:
2025-01-17 19:48:05,508:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-17 19:48:05,509:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-17 19:48:05,509:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-17 19:48:05,509:INFO:PyCaret required dependencies:
2025-01-17 19:48:05,532:INFO:                 pip: 24.2
2025-01-17 19:48:05,532:INFO:          setuptools: 75.1.0
2025-01-17 19:48:05,532:INFO:             pycaret: 3.3.1
2025-01-17 19:48:05,532:INFO:             IPython: 8.27.0
2025-01-17 19:48:05,532:INFO:          ipywidgets: 8.1.2
2025-01-17 19:48:05,532:INFO:                tqdm: 4.66.5
2025-01-17 19:48:05,532:INFO:               numpy: 1.26.4
2025-01-17 19:48:05,532:INFO:              pandas: 2.1.4
2025-01-17 19:48:05,532:INFO:              jinja2: 3.1.4
2025-01-17 19:48:05,532:INFO:               scipy: 1.11.4
2025-01-17 19:48:05,532:INFO:              joblib: 1.3.2
2025-01-17 19:48:05,532:INFO:             sklearn: 1.4.2
2025-01-17 19:48:05,532:INFO:                pyod: 2.0.2
2025-01-17 19:48:05,532:INFO:            imblearn: 0.13.0
2025-01-17 19:48:05,532:INFO:   category_encoders: 2.7.0
2025-01-17 19:48:05,532:INFO:            lightgbm: 4.4.0
2025-01-17 19:48:05,532:INFO:               numba: 0.60.0
2025-01-17 19:48:05,532:INFO:            requests: 2.32.3
2025-01-17 19:48:05,532:INFO:          matplotlib: 3.9.2
2025-01-17 19:48:05,532:INFO:          scikitplot: 0.3.7
2025-01-17 19:48:05,532:INFO:         yellowbrick: 1.5
2025-01-17 19:48:05,533:INFO:              plotly: 5.24.1
2025-01-17 19:48:05,533:INFO:    plotly-resampler: Not installed
2025-01-17 19:48:05,533:INFO:             kaleido: 0.2.1
2025-01-17 19:48:05,533:INFO:           schemdraw: 0.15
2025-01-17 19:48:05,533:INFO:         statsmodels: 0.14.4
2025-01-17 19:48:05,533:INFO:              sktime: 0.26.0
2025-01-17 19:48:05,533:INFO:               tbats: 1.1.3
2025-01-17 19:48:05,533:INFO:            pmdarima: 2.0.4
2025-01-17 19:48:05,533:INFO:              psutil: 5.9.0
2025-01-17 19:48:05,533:INFO:          markupsafe: 2.1.3
2025-01-17 19:48:05,533:INFO:             pickle5: Not installed
2025-01-17 19:48:05,533:INFO:         cloudpickle: 3.1.0
2025-01-17 19:48:05,533:INFO:         deprecation: 2.1.0
2025-01-17 19:48:05,533:INFO:              xxhash: 3.5.0
2025-01-17 19:48:05,533:INFO:           wurlitzer: 3.1.1
2025-01-17 19:48:05,533:INFO:PyCaret optional dependencies:
2025-01-17 19:48:05,570:INFO:                shap: Not installed
2025-01-17 19:48:05,570:INFO:           interpret: Not installed
2025-01-17 19:48:05,570:INFO:                umap: 0.5.7
2025-01-17 19:48:05,570:INFO:     ydata_profiling: Not installed
2025-01-17 19:48:05,570:INFO:  explainerdashboard: Not installed
2025-01-17 19:48:05,570:INFO:             autoviz: Not installed
2025-01-17 19:48:05,570:INFO:           fairlearn: Not installed
2025-01-17 19:48:05,570:INFO:          deepchecks: Not installed
2025-01-17 19:48:05,570:INFO:             xgboost: 2.1.3
2025-01-17 19:48:05,570:INFO:            catboost: Not installed
2025-01-17 19:48:05,570:INFO:              kmodes: Not installed
2025-01-17 19:48:05,570:INFO:             mlxtend: Not installed
2025-01-17 19:48:05,570:INFO:       statsforecast: Not installed
2025-01-17 19:48:05,570:INFO:        tune_sklearn: Not installed
2025-01-17 19:48:05,570:INFO:                 ray: Not installed
2025-01-17 19:48:05,570:INFO:            hyperopt: Not installed
2025-01-17 19:48:05,570:INFO:              optuna: Not installed
2025-01-17 19:48:05,570:INFO:               skopt: Not installed
2025-01-17 19:48:05,570:INFO:              mlflow: Not installed
2025-01-17 19:48:05,570:INFO:              gradio: Not installed
2025-01-17 19:48:05,570:INFO:             fastapi: Not installed
2025-01-17 19:48:05,570:INFO:             uvicorn: Not installed
2025-01-17 19:48:05,570:INFO:              m2cgen: Not installed
2025-01-17 19:48:05,570:INFO:           evidently: Not installed
2025-01-17 19:48:05,570:INFO:               fugue: Not installed
2025-01-17 19:48:05,570:INFO:           streamlit: Not installed
2025-01-17 19:48:05,570:INFO:             prophet: Not installed
2025-01-17 19:48:05,570:INFO:None
2025-01-17 19:48:05,570:INFO:Set up data.
2025-01-17 19:48:05,575:INFO:Set up folding strategy.
2025-01-17 19:48:05,575:INFO:Set up train/test split.
2025-01-17 19:48:05,583:INFO:Set up index.
2025-01-17 19:48:05,584:INFO:Assigning column types.
2025-01-17 19:48:05,586:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-17 19:48:05,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 19:48:05,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 19:48:05,643:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:05,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:05,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 19:48:05,677:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 19:48:05,697:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:05,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:05,699:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-17 19:48:05,730:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 19:48:05,750:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:05,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:05,786:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 19:48:05,806:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:05,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:05,808:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-01-17 19:48:05,860:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:05,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:05,913:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:05,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:05,916:INFO:Preparing preprocessing pipeline...
2025-01-17 19:48:05,918:INFO:Set up label encoding.
2025-01-17 19:48:05,918:INFO:Set up simple imputation.
2025-01-17 19:48:05,934:INFO:Finished creating preprocessing pipeline.
2025-01-17 19:48:05,937:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-01-17 19:48:05,938:INFO:Creating final display dataframe.
2025-01-17 19:48:05,979:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                             species  
2                                          Multiclass  
3   Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...  
4                                            (150, 5)  
5                                            (150, 5)  
6                                            (105, 5)  
7                                             (45, 5)  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               d9cc  
2025-01-17 19:48:06,037:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,091:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,094:INFO:setup() successfully completed in 0.59s...............
2025-01-17 19:48:06,108:INFO:PyCaret ClassificationExperiment
2025-01-17 19:48:06,108:INFO:Logging name: clf-default-name
2025-01-17 19:48:06,108:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-01-17 19:48:06,108:INFO:version 3.3.1
2025-01-17 19:48:06,108:INFO:Initializing setup()
2025-01-17 19:48:06,108:INFO:self.USI: 6143
2025-01-17 19:48:06,108:INFO:self._variable_keys: {'memory', '_ml_usecase', 'data', 'log_plots_param', 'idx', 'fold_groups_param', '_available_plots', 'seed', 'X_train', 'pipeline', 'y_test', 'y', 'fold_generator', 'fix_imbalance', 'html_param', 'gpu_param', 'exp_id', 'fold_shuffle_param', 'target_param', 'exp_name_log', 'is_multiclass', 'y_train', 'gpu_n_jobs_param', 'n_jobs_param', 'X', 'USI', 'logging_param', 'X_test'}
2025-01-17 19:48:06,108:INFO:Checking environment
2025-01-17 19:48:06,108:INFO:python_version: 3.10.13
2025-01-17 19:48:06,108:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-17 19:48:06,108:INFO:machine: arm64
2025-01-17 19:48:06,108:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-17 19:48:06,108:INFO:Memory: svmem(total=8589934592, available=1403846656, percent=83.7, used=2951053312, free=63176704, active=1357479936, inactive=1266450432, wired=1593573376)
2025-01-17 19:48:06,108:INFO:Physical Core: 8
2025-01-17 19:48:06,108:INFO:Logical Core: 8
2025-01-17 19:48:06,109:INFO:Checking libraries
2025-01-17 19:48:06,109:INFO:System:
2025-01-17 19:48:06,109:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-17 19:48:06,109:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-17 19:48:06,109:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-17 19:48:06,109:INFO:PyCaret required dependencies:
2025-01-17 19:48:06,109:INFO:                 pip: 24.2
2025-01-17 19:48:06,109:INFO:          setuptools: 75.1.0
2025-01-17 19:48:06,109:INFO:             pycaret: 3.3.1
2025-01-17 19:48:06,109:INFO:             IPython: 8.27.0
2025-01-17 19:48:06,109:INFO:          ipywidgets: 8.1.2
2025-01-17 19:48:06,109:INFO:                tqdm: 4.66.5
2025-01-17 19:48:06,109:INFO:               numpy: 1.26.4
2025-01-17 19:48:06,109:INFO:              pandas: 2.1.4
2025-01-17 19:48:06,109:INFO:              jinja2: 3.1.4
2025-01-17 19:48:06,109:INFO:               scipy: 1.11.4
2025-01-17 19:48:06,109:INFO:              joblib: 1.3.2
2025-01-17 19:48:06,109:INFO:             sklearn: 1.4.2
2025-01-17 19:48:06,109:INFO:                pyod: 2.0.2
2025-01-17 19:48:06,109:INFO:            imblearn: 0.13.0
2025-01-17 19:48:06,109:INFO:   category_encoders: 2.7.0
2025-01-17 19:48:06,109:INFO:            lightgbm: 4.4.0
2025-01-17 19:48:06,109:INFO:               numba: 0.60.0
2025-01-17 19:48:06,109:INFO:            requests: 2.32.3
2025-01-17 19:48:06,109:INFO:          matplotlib: 3.9.2
2025-01-17 19:48:06,109:INFO:          scikitplot: 0.3.7
2025-01-17 19:48:06,109:INFO:         yellowbrick: 1.5
2025-01-17 19:48:06,109:INFO:              plotly: 5.24.1
2025-01-17 19:48:06,109:INFO:    plotly-resampler: Not installed
2025-01-17 19:48:06,109:INFO:             kaleido: 0.2.1
2025-01-17 19:48:06,109:INFO:           schemdraw: 0.15
2025-01-17 19:48:06,109:INFO:         statsmodels: 0.14.4
2025-01-17 19:48:06,109:INFO:              sktime: 0.26.0
2025-01-17 19:48:06,109:INFO:               tbats: 1.1.3
2025-01-17 19:48:06,109:INFO:            pmdarima: 2.0.4
2025-01-17 19:48:06,109:INFO:              psutil: 5.9.0
2025-01-17 19:48:06,109:INFO:          markupsafe: 2.1.3
2025-01-17 19:48:06,109:INFO:             pickle5: Not installed
2025-01-17 19:48:06,109:INFO:         cloudpickle: 3.1.0
2025-01-17 19:48:06,109:INFO:         deprecation: 2.1.0
2025-01-17 19:48:06,109:INFO:              xxhash: 3.5.0
2025-01-17 19:48:06,109:INFO:           wurlitzer: 3.1.1
2025-01-17 19:48:06,109:INFO:PyCaret optional dependencies:
2025-01-17 19:48:06,110:INFO:                shap: Not installed
2025-01-17 19:48:06,110:INFO:           interpret: Not installed
2025-01-17 19:48:06,110:INFO:                umap: 0.5.7
2025-01-17 19:48:06,110:INFO:     ydata_profiling: Not installed
2025-01-17 19:48:06,110:INFO:  explainerdashboard: Not installed
2025-01-17 19:48:06,110:INFO:             autoviz: Not installed
2025-01-17 19:48:06,110:INFO:           fairlearn: Not installed
2025-01-17 19:48:06,110:INFO:          deepchecks: Not installed
2025-01-17 19:48:06,110:INFO:             xgboost: 2.1.3
2025-01-17 19:48:06,110:INFO:            catboost: Not installed
2025-01-17 19:48:06,110:INFO:              kmodes: Not installed
2025-01-17 19:48:06,110:INFO:             mlxtend: Not installed
2025-01-17 19:48:06,110:INFO:       statsforecast: Not installed
2025-01-17 19:48:06,110:INFO:        tune_sklearn: Not installed
2025-01-17 19:48:06,110:INFO:                 ray: Not installed
2025-01-17 19:48:06,110:INFO:            hyperopt: Not installed
2025-01-17 19:48:06,110:INFO:              optuna: Not installed
2025-01-17 19:48:06,110:INFO:               skopt: Not installed
2025-01-17 19:48:06,110:INFO:              mlflow: Not installed
2025-01-17 19:48:06,110:INFO:              gradio: Not installed
2025-01-17 19:48:06,110:INFO:             fastapi: Not installed
2025-01-17 19:48:06,110:INFO:             uvicorn: Not installed
2025-01-17 19:48:06,110:INFO:              m2cgen: Not installed
2025-01-17 19:48:06,110:INFO:           evidently: Not installed
2025-01-17 19:48:06,110:INFO:               fugue: Not installed
2025-01-17 19:48:06,110:INFO:           streamlit: Not installed
2025-01-17 19:48:06,110:INFO:             prophet: Not installed
2025-01-17 19:48:06,110:INFO:None
2025-01-17 19:48:06,110:INFO:Set up data.
2025-01-17 19:48:06,118:INFO:Set up folding strategy.
2025-01-17 19:48:06,118:INFO:Set up train/test split.
2025-01-17 19:48:06,120:INFO:Set up index.
2025-01-17 19:48:06,120:INFO:Assigning column types.
2025-01-17 19:48:06,122:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-17 19:48:06,153:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 19:48:06,154:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 19:48:06,174:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,207:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 19:48:06,207:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 19:48:06,227:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,229:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-17 19:48:06,261:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 19:48:06,280:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,314:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 19:48:06,334:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,335:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-01-17 19:48:06,387:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,440:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,442:INFO:Preparing preprocessing pipeline...
2025-01-17 19:48:06,443:INFO:Set up label encoding.
2025-01-17 19:48:06,443:INFO:Set up simple imputation.
2025-01-17 19:48:06,456:INFO:Finished creating preprocessing pipeline.
2025-01-17 19:48:06,459:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-01-17 19:48:06,459:INFO:Creating final display dataframe.
2025-01-17 19:48:06,501:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                             species  
2                                          Multiclass  
3   Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...  
4                                            (150, 5)  
5                                            (150, 5)  
6                                            (105, 5)  
7                                             (45, 5)  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               6143  
2025-01-17 19:48:06,557:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,610:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 19:48:06,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 19:48:06,613:INFO:setup() successfully completed in 0.51s...............
2025-01-17 19:48:06,616:INFO:Initializing compare_models()
2025-01-17 19:48:06,617:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-01-17 19:48:06,617:INFO:Checking exceptions
2025-01-17 19:48:06,619:INFO:Preparing display monitor
2025-01-17 19:48:06,660:INFO:Initializing Logistic Regression
2025-01-17 19:48:06,660:INFO:Total runtime is 5.352497100830078e-06 minutes
2025-01-17 19:48:06,663:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:06,663:INFO:Initializing create_model()
2025-01-17 19:48:06,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:06,663:INFO:Checking exceptions
2025-01-17 19:48:06,663:INFO:Importing libraries
2025-01-17 19:48:06,664:INFO:Copying training dataset
2025-01-17 19:48:06,667:INFO:Defining folds
2025-01-17 19:48:06,667:INFO:Declaring metric variables
2025-01-17 19:48:06,669:INFO:Importing untrained model
2025-01-17 19:48:06,672:INFO:Logistic Regression Imported successfully
2025-01-17 19:48:06,677:INFO:Starting cross validation
2025-01-17 19:48:06,678:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:10,264:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,267:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,270:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,270:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,271:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,273:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,273:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,274:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,274:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,275:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,276:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,277:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,277:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,277:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,277:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,279:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,279:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,279:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,280:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,280:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,283:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,283:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,287:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,287:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,290:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,294:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,298:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,301:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,304:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,308:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,314:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,319:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,394:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,395:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,396:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:10,397:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,398:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,400:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,400:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,402:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,409:INFO:Calculating mean and std
2025-01-17 19:48:10,412:INFO:Creating metrics dataframe
2025-01-17 19:48:10,422:INFO:Uploading results into container
2025-01-17 19:48:10,423:INFO:Uploading model into container now
2025-01-17 19:48:10,424:INFO:_master_model_container: 1
2025-01-17 19:48:10,424:INFO:_display_container: 2
2025-01-17 19:48:10,424:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 19:48:10,425:INFO:create_model() successfully completed......................................
2025-01-17 19:48:10,537:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:10,537:INFO:Creating metrics dataframe
2025-01-17 19:48:10,542:INFO:Initializing K Neighbors Classifier
2025-01-17 19:48:10,543:INFO:Total runtime is 0.06471267143885295 minutes
2025-01-17 19:48:10,545:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:10,545:INFO:Initializing create_model()
2025-01-17 19:48:10,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:10,545:INFO:Checking exceptions
2025-01-17 19:48:10,545:INFO:Importing libraries
2025-01-17 19:48:10,545:INFO:Copying training dataset
2025-01-17 19:48:10,547:INFO:Defining folds
2025-01-17 19:48:10,547:INFO:Declaring metric variables
2025-01-17 19:48:10,550:INFO:Importing untrained model
2025-01-17 19:48:10,552:INFO:K Neighbors Classifier Imported successfully
2025-01-17 19:48:10,556:INFO:Starting cross validation
2025-01-17 19:48:10,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:10,604:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,604:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,604:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,605:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,605:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,605:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,605:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,607:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,607:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,607:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,607:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,608:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,608:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,610:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,610:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,613:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,614:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,615:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,616:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,618:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,620:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,622:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,623:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,625:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,626:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,627:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,629:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,637:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,637:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,638:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,638:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,641:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,641:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,648:INFO:Calculating mean and std
2025-01-17 19:48:10,649:INFO:Creating metrics dataframe
2025-01-17 19:48:10,650:INFO:Uploading results into container
2025-01-17 19:48:10,651:INFO:Uploading model into container now
2025-01-17 19:48:10,651:INFO:_master_model_container: 2
2025-01-17 19:48:10,651:INFO:_display_container: 2
2025-01-17 19:48:10,651:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-01-17 19:48:10,651:INFO:create_model() successfully completed......................................
2025-01-17 19:48:10,699:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:10,699:INFO:Creating metrics dataframe
2025-01-17 19:48:10,704:INFO:Initializing Naive Bayes
2025-01-17 19:48:10,704:INFO:Total runtime is 0.06740085681279501 minutes
2025-01-17 19:48:10,706:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:10,706:INFO:Initializing create_model()
2025-01-17 19:48:10,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:10,706:INFO:Checking exceptions
2025-01-17 19:48:10,706:INFO:Importing libraries
2025-01-17 19:48:10,706:INFO:Copying training dataset
2025-01-17 19:48:10,708:INFO:Defining folds
2025-01-17 19:48:10,708:INFO:Declaring metric variables
2025-01-17 19:48:10,710:INFO:Importing untrained model
2025-01-17 19:48:10,712:INFO:Naive Bayes Imported successfully
2025-01-17 19:48:10,716:INFO:Starting cross validation
2025-01-17 19:48:10,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:10,738:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,738:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,739:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,740:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,740:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,741:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,742:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,742:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,742:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,743:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,743:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,745:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,746:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,748:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,750:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,751:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,752:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,753:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,754:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,754:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,755:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,756:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,756:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,756:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,756:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,757:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,757:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,758:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,758:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,758:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,759:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,760:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,760:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,760:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,761:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,762:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,763:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,763:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,765:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,765:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,771:INFO:Calculating mean and std
2025-01-17 19:48:10,772:INFO:Creating metrics dataframe
2025-01-17 19:48:10,773:INFO:Uploading results into container
2025-01-17 19:48:10,773:INFO:Uploading model into container now
2025-01-17 19:48:10,774:INFO:_master_model_container: 3
2025-01-17 19:48:10,774:INFO:_display_container: 2
2025-01-17 19:48:10,774:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-01-17 19:48:10,774:INFO:create_model() successfully completed......................................
2025-01-17 19:48:10,822:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:10,822:INFO:Creating metrics dataframe
2025-01-17 19:48:10,827:INFO:Initializing Decision Tree Classifier
2025-01-17 19:48:10,827:INFO:Total runtime is 0.06945552031199138 minutes
2025-01-17 19:48:10,829:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:10,829:INFO:Initializing create_model()
2025-01-17 19:48:10,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:10,829:INFO:Checking exceptions
2025-01-17 19:48:10,829:INFO:Importing libraries
2025-01-17 19:48:10,829:INFO:Copying training dataset
2025-01-17 19:48:10,831:INFO:Defining folds
2025-01-17 19:48:10,831:INFO:Declaring metric variables
2025-01-17 19:48:10,833:INFO:Importing untrained model
2025-01-17 19:48:10,835:INFO:Decision Tree Classifier Imported successfully
2025-01-17 19:48:10,839:INFO:Starting cross validation
2025-01-17 19:48:10,840:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:10,862:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,862:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,863:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,863:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,864:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,864:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,865:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,865:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,865:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,865:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,865:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,866:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,866:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,866:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,866:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,867:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,868:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,868:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,869:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,871:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,875:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,875:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,876:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,876:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,877:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,878:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,878:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,879:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,879:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,879:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,880:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,881:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,882:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,882:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,883:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:10,884:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,884:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,884:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,885:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,887:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:10,898:INFO:Calculating mean and std
2025-01-17 19:48:10,898:INFO:Creating metrics dataframe
2025-01-17 19:48:10,900:INFO:Uploading results into container
2025-01-17 19:48:10,900:INFO:Uploading model into container now
2025-01-17 19:48:10,900:INFO:_master_model_container: 4
2025-01-17 19:48:10,900:INFO:_display_container: 2
2025-01-17 19:48:10,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-01-17 19:48:10,901:INFO:create_model() successfully completed......................................
2025-01-17 19:48:10,948:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:10,948:INFO:Creating metrics dataframe
2025-01-17 19:48:10,953:INFO:Initializing SVM - Linear Kernel
2025-01-17 19:48:10,953:INFO:Total runtime is 0.07156033913294475 minutes
2025-01-17 19:48:10,955:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:10,956:INFO:Initializing create_model()
2025-01-17 19:48:10,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:10,956:INFO:Checking exceptions
2025-01-17 19:48:10,956:INFO:Importing libraries
2025-01-17 19:48:10,956:INFO:Copying training dataset
2025-01-17 19:48:10,958:INFO:Defining folds
2025-01-17 19:48:10,958:INFO:Declaring metric variables
2025-01-17 19:48:10,960:INFO:Importing untrained model
2025-01-17 19:48:10,962:INFO:SVM - Linear Kernel Imported successfully
2025-01-17 19:48:10,966:INFO:Starting cross validation
2025-01-17 19:48:10,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:11,001:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,001:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,003:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,004:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:11,005:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,006:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,007:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,007:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,008:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,008:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,009:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:11,009:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,009:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,010:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,011:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,012:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,012:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,013:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,013:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,015:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,015:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,015:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,016:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,016:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:11,017:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,017:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,018:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,020:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,021:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,022:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,023:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,023:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,024:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,025:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,025:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:11,026:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,033:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,034:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,035:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,036:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:11,037:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,037:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,038:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,040:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,040:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:11,041:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,046:INFO:Calculating mean and std
2025-01-17 19:48:11,047:INFO:Creating metrics dataframe
2025-01-17 19:48:11,048:INFO:Uploading results into container
2025-01-17 19:48:11,049:INFO:Uploading model into container now
2025-01-17 19:48:11,049:INFO:_master_model_container: 5
2025-01-17 19:48:11,049:INFO:_display_container: 2
2025-01-17 19:48:11,050:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-01-17 19:48:11,050:INFO:create_model() successfully completed......................................
2025-01-17 19:48:11,097:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:11,097:INFO:Creating metrics dataframe
2025-01-17 19:48:11,102:INFO:Initializing Ridge Classifier
2025-01-17 19:48:11,102:INFO:Total runtime is 0.07404290437698366 minutes
2025-01-17 19:48:11,104:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:11,105:INFO:Initializing create_model()
2025-01-17 19:48:11,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:11,105:INFO:Checking exceptions
2025-01-17 19:48:11,105:INFO:Importing libraries
2025-01-17 19:48:11,105:INFO:Copying training dataset
2025-01-17 19:48:11,107:INFO:Defining folds
2025-01-17 19:48:11,107:INFO:Declaring metric variables
2025-01-17 19:48:11,109:INFO:Importing untrained model
2025-01-17 19:48:11,111:INFO:Ridge Classifier Imported successfully
2025-01-17 19:48:11,115:INFO:Starting cross validation
2025-01-17 19:48:11,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:11,139:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,139:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,139:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,140:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,140:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,140:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,141:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,141:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,141:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,142:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,142:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,143:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,143:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,143:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,144:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,145:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,151:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,152:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,152:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,153:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,153:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,154:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,155:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,155:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,155:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,156:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,156:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,156:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,156:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,158:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,158:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,159:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,161:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,161:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,162:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,162:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,163:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,163:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,165:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,165:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,169:INFO:Calculating mean and std
2025-01-17 19:48:11,170:INFO:Creating metrics dataframe
2025-01-17 19:48:11,171:INFO:Uploading results into container
2025-01-17 19:48:11,171:INFO:Uploading model into container now
2025-01-17 19:48:11,171:INFO:_master_model_container: 6
2025-01-17 19:48:11,172:INFO:_display_container: 2
2025-01-17 19:48:11,172:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-01-17 19:48:11,172:INFO:create_model() successfully completed......................................
2025-01-17 19:48:11,219:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:11,219:INFO:Creating metrics dataframe
2025-01-17 19:48:11,225:INFO:Initializing Random Forest Classifier
2025-01-17 19:48:11,225:INFO:Total runtime is 0.07608927090962729 minutes
2025-01-17 19:48:11,227:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:11,227:INFO:Initializing create_model()
2025-01-17 19:48:11,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:11,227:INFO:Checking exceptions
2025-01-17 19:48:11,227:INFO:Importing libraries
2025-01-17 19:48:11,228:INFO:Copying training dataset
2025-01-17 19:48:11,230:INFO:Defining folds
2025-01-17 19:48:11,230:INFO:Declaring metric variables
2025-01-17 19:48:11,232:INFO:Importing untrained model
2025-01-17 19:48:11,234:INFO:Random Forest Classifier Imported successfully
2025-01-17 19:48:11,237:INFO:Starting cross validation
2025-01-17 19:48:11,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:11,411:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,412:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,414:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,414:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,415:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,416:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,417:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,418:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,424:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,424:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,425:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,426:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,427:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,428:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,429:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,430:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,439:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,440:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,441:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,442:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,442:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,444:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,444:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,445:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,448:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,450:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,451:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,452:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,453:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,453:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,455:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,457:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,568:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,568:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:11,569:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,570:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,571:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,572:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,573:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,574:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,577:INFO:Calculating mean and std
2025-01-17 19:48:11,578:INFO:Creating metrics dataframe
2025-01-17 19:48:11,580:INFO:Uploading results into container
2025-01-17 19:48:11,580:INFO:Uploading model into container now
2025-01-17 19:48:11,581:INFO:_master_model_container: 7
2025-01-17 19:48:11,581:INFO:_display_container: 2
2025-01-17 19:48:11,581:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-01-17 19:48:11,581:INFO:create_model() successfully completed......................................
2025-01-17 19:48:11,636:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:11,636:INFO:Creating metrics dataframe
2025-01-17 19:48:11,642:INFO:Initializing Quadratic Discriminant Analysis
2025-01-17 19:48:11,642:INFO:Total runtime is 0.08304471969604493 minutes
2025-01-17 19:48:11,645:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:11,645:INFO:Initializing create_model()
2025-01-17 19:48:11,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:11,645:INFO:Checking exceptions
2025-01-17 19:48:11,645:INFO:Importing libraries
2025-01-17 19:48:11,645:INFO:Copying training dataset
2025-01-17 19:48:11,648:INFO:Defining folds
2025-01-17 19:48:11,648:INFO:Declaring metric variables
2025-01-17 19:48:11,650:INFO:Importing untrained model
2025-01-17 19:48:11,652:INFO:Quadratic Discriminant Analysis Imported successfully
2025-01-17 19:48:11,657:INFO:Starting cross validation
2025-01-17 19:48:11,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:11,681:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,681:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,682:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,682:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,683:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,683:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,684:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,685:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,685:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,685:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,686:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,689:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,690:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,693:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,694:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,694:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,694:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,693:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,695:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,695:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,696:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,697:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,697:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,698:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,700:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,703:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,705:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,706:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,707:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,708:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,709:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,709:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,710:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,711:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,713:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,726:INFO:Calculating mean and std
2025-01-17 19:48:11,727:INFO:Creating metrics dataframe
2025-01-17 19:48:11,729:INFO:Uploading results into container
2025-01-17 19:48:11,729:INFO:Uploading model into container now
2025-01-17 19:48:11,729:INFO:_master_model_container: 8
2025-01-17 19:48:11,729:INFO:_display_container: 2
2025-01-17 19:48:11,729:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-01-17 19:48:11,729:INFO:create_model() successfully completed......................................
2025-01-17 19:48:11,781:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:11,781:INFO:Creating metrics dataframe
2025-01-17 19:48:11,788:INFO:Initializing Ada Boost Classifier
2025-01-17 19:48:11,788:INFO:Total runtime is 0.08547300497690838 minutes
2025-01-17 19:48:11,791:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:11,791:INFO:Initializing create_model()
2025-01-17 19:48:11,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:11,791:INFO:Checking exceptions
2025-01-17 19:48:11,791:INFO:Importing libraries
2025-01-17 19:48:11,791:INFO:Copying training dataset
2025-01-17 19:48:11,793:INFO:Defining folds
2025-01-17 19:48:11,793:INFO:Declaring metric variables
2025-01-17 19:48:11,795:INFO:Importing untrained model
2025-01-17 19:48:11,798:INFO:Ada Boost Classifier Imported successfully
2025-01-17 19:48:11,802:INFO:Starting cross validation
2025-01-17 19:48:11,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:11,817:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,821:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,828:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,830:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,835:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,838:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,851:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,855:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,886:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,887:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,889:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,891:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,891:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,892:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,896:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,899:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,905:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,907:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:11,910:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,911:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,912:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,913:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,913:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,913:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,914:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,915:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,915:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,917:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,917:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,917:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,918:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,922:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,926:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,930:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,931:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,935:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,936:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,937:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,939:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,941:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,979:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,980:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:11,980:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,981:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,982:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,983:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,984:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,985:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:11,995:INFO:Calculating mean and std
2025-01-17 19:48:11,996:INFO:Creating metrics dataframe
2025-01-17 19:48:11,998:INFO:Uploading results into container
2025-01-17 19:48:11,998:INFO:Uploading model into container now
2025-01-17 19:48:11,999:INFO:_master_model_container: 9
2025-01-17 19:48:11,999:INFO:_display_container: 2
2025-01-17 19:48:11,999:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-01-17 19:48:11,999:INFO:create_model() successfully completed......................................
2025-01-17 19:48:12,051:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:12,051:INFO:Creating metrics dataframe
2025-01-17 19:48:12,058:INFO:Initializing Gradient Boosting Classifier
2025-01-17 19:48:12,058:INFO:Total runtime is 0.0899739185969035 minutes
2025-01-17 19:48:12,061:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:12,061:INFO:Initializing create_model()
2025-01-17 19:48:12,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:12,061:INFO:Checking exceptions
2025-01-17 19:48:12,061:INFO:Importing libraries
2025-01-17 19:48:12,061:INFO:Copying training dataset
2025-01-17 19:48:12,064:INFO:Defining folds
2025-01-17 19:48:12,064:INFO:Declaring metric variables
2025-01-17 19:48:12,066:INFO:Importing untrained model
2025-01-17 19:48:12,068:INFO:Gradient Boosting Classifier Imported successfully
2025-01-17 19:48:12,072:INFO:Starting cross validation
2025-01-17 19:48:12,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:12,399:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,401:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,407:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,408:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,410:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,413:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,415:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,418:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,422:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,426:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,437:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,437:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,439:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,441:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,442:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,443:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,444:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,445:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,446:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,448:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,449:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,451:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,453:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,458:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,462:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,464:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,466:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,469:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,473:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,635:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,636:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,636:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,637:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,638:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,641:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,652:INFO:Calculating mean and std
2025-01-17 19:48:12,653:INFO:Creating metrics dataframe
2025-01-17 19:48:12,654:INFO:Uploading results into container
2025-01-17 19:48:12,654:INFO:Uploading model into container now
2025-01-17 19:48:12,655:INFO:_master_model_container: 10
2025-01-17 19:48:12,655:INFO:_display_container: 2
2025-01-17 19:48:12,655:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-01-17 19:48:12,655:INFO:create_model() successfully completed......................................
2025-01-17 19:48:12,702:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:12,703:INFO:Creating metrics dataframe
2025-01-17 19:48:12,709:INFO:Initializing Linear Discriminant Analysis
2025-01-17 19:48:12,709:INFO:Total runtime is 0.10082738399505617 minutes
2025-01-17 19:48:12,712:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:12,712:INFO:Initializing create_model()
2025-01-17 19:48:12,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:12,712:INFO:Checking exceptions
2025-01-17 19:48:12,712:INFO:Importing libraries
2025-01-17 19:48:12,712:INFO:Copying training dataset
2025-01-17 19:48:12,714:INFO:Defining folds
2025-01-17 19:48:12,714:INFO:Declaring metric variables
2025-01-17 19:48:12,716:INFO:Importing untrained model
2025-01-17 19:48:12,718:INFO:Linear Discriminant Analysis Imported successfully
2025-01-17 19:48:12,722:INFO:Starting cross validation
2025-01-17 19:48:12,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:12,744:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,745:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,745:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,748:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,749:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,753:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,753:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,754:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,755:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,756:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,757:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,759:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,763:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,764:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,766:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,767:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,767:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,767:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,768:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,768:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,769:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,769:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,769:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,771:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,771:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,771:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,771:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,771:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,772:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,772:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,773:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,774:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,774:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,775:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,775:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,777:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,782:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:12,782:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,784:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,785:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:12,791:INFO:Calculating mean and std
2025-01-17 19:48:12,792:INFO:Creating metrics dataframe
2025-01-17 19:48:12,794:INFO:Uploading results into container
2025-01-17 19:48:12,794:INFO:Uploading model into container now
2025-01-17 19:48:12,794:INFO:_master_model_container: 11
2025-01-17 19:48:12,794:INFO:_display_container: 2
2025-01-17 19:48:12,794:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-01-17 19:48:12,794:INFO:create_model() successfully completed......................................
2025-01-17 19:48:12,843:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:12,843:INFO:Creating metrics dataframe
2025-01-17 19:48:12,850:INFO:Initializing Extra Trees Classifier
2025-01-17 19:48:12,850:INFO:Total runtime is 0.10317018826802574 minutes
2025-01-17 19:48:12,852:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:12,852:INFO:Initializing create_model()
2025-01-17 19:48:12,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:12,852:INFO:Checking exceptions
2025-01-17 19:48:12,852:INFO:Importing libraries
2025-01-17 19:48:12,852:INFO:Copying training dataset
2025-01-17 19:48:12,854:INFO:Defining folds
2025-01-17 19:48:12,854:INFO:Declaring metric variables
2025-01-17 19:48:12,856:INFO:Importing untrained model
2025-01-17 19:48:12,858:INFO:Extra Trees Classifier Imported successfully
2025-01-17 19:48:12,862:INFO:Starting cross validation
2025-01-17 19:48:12,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:13,015:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,017:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,018:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,020:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,020:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,020:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,021:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,021:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,023:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,023:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,025:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,025:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,036:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,037:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,038:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,039:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,040:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,041:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,041:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,044:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,045:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,045:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,047:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,048:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,055:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,056:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,058:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,060:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,063:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,065:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,066:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,068:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,127:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,128:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,130:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,132:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,133:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,134:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,136:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,137:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,150:INFO:Calculating mean and std
2025-01-17 19:48:13,151:INFO:Creating metrics dataframe
2025-01-17 19:48:13,153:INFO:Uploading results into container
2025-01-17 19:48:13,153:INFO:Uploading model into container now
2025-01-17 19:48:13,153:INFO:_master_model_container: 12
2025-01-17 19:48:13,153:INFO:_display_container: 2
2025-01-17 19:48:13,153:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-01-17 19:48:13,153:INFO:create_model() successfully completed......................................
2025-01-17 19:48:13,201:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:13,201:INFO:Creating metrics dataframe
2025-01-17 19:48:13,208:INFO:Initializing Extreme Gradient Boosting
2025-01-17 19:48:13,208:INFO:Total runtime is 0.10913833379745486 minutes
2025-01-17 19:48:13,210:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:13,210:INFO:Initializing create_model()
2025-01-17 19:48:13,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:13,211:INFO:Checking exceptions
2025-01-17 19:48:13,211:INFO:Importing libraries
2025-01-17 19:48:13,211:INFO:Copying training dataset
2025-01-17 19:48:13,213:INFO:Defining folds
2025-01-17 19:48:13,213:INFO:Declaring metric variables
2025-01-17 19:48:13,215:INFO:Importing untrained model
2025-01-17 19:48:13,217:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 19:48:13,221:INFO:Starting cross validation
2025-01-17 19:48:13,221:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:13,291:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,292:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,294:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,295:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,299:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,301:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,305:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,305:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,305:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,305:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,306:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,306:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,308:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,308:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,308:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,309:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,309:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,309:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,311:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,313:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,314:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,315:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,317:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,319:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,323:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,324:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,325:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,327:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,328:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,329:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,330:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,332:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,337:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,337:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:13,338:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,338:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,339:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,339:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,341:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,341:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:13,347:INFO:Calculating mean and std
2025-01-17 19:48:13,348:INFO:Creating metrics dataframe
2025-01-17 19:48:13,349:INFO:Uploading results into container
2025-01-17 19:48:13,349:INFO:Uploading model into container now
2025-01-17 19:48:13,350:INFO:_master_model_container: 13
2025-01-17 19:48:13,350:INFO:_display_container: 2
2025-01-17 19:48:13,350:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 19:48:13,350:INFO:create_model() successfully completed......................................
2025-01-17 19:48:13,398:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:13,398:INFO:Creating metrics dataframe
2025-01-17 19:48:13,405:INFO:Initializing Light Gradient Boosting Machine
2025-01-17 19:48:13,405:INFO:Total runtime is 0.11242488622665407 minutes
2025-01-17 19:48:13,407:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:13,408:INFO:Initializing create_model()
2025-01-17 19:48:13,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:13,408:INFO:Checking exceptions
2025-01-17 19:48:13,408:INFO:Importing libraries
2025-01-17 19:48:13,408:INFO:Copying training dataset
2025-01-17 19:48:13,410:INFO:Defining folds
2025-01-17 19:48:13,410:INFO:Declaring metric variables
2025-01-17 19:48:13,412:INFO:Importing untrained model
2025-01-17 19:48:13,414:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-17 19:48:13,417:INFO:Starting cross validation
2025-01-17 19:48:13,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:14,138:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,141:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,146:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,150:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,239:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,241:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,241:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,242:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,244:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,246:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,247:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,249:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,289:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,291:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,295:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,300:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,328:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,330:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,332:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,335:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,340:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,341:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,343:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,345:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,356:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,357:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,359:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,361:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,402:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,403:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,404:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,406:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,544:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,545:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,547:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,548:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,557:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,557:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,559:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,560:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,567:INFO:Calculating mean and std
2025-01-17 19:48:14,568:INFO:Creating metrics dataframe
2025-01-17 19:48:14,569:INFO:Uploading results into container
2025-01-17 19:48:14,569:INFO:Uploading model into container now
2025-01-17 19:48:14,570:INFO:_master_model_container: 14
2025-01-17 19:48:14,570:INFO:_display_container: 2
2025-01-17 19:48:14,570:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-01-17 19:48:14,570:INFO:create_model() successfully completed......................................
2025-01-17 19:48:14,618:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:14,618:INFO:Creating metrics dataframe
2025-01-17 19:48:14,625:INFO:Initializing Dummy Classifier
2025-01-17 19:48:14,625:INFO:Total runtime is 0.13276133537292484 minutes
2025-01-17 19:48:14,627:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:14,628:INFO:Initializing create_model()
2025-01-17 19:48:14,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163dfa830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:14,628:INFO:Checking exceptions
2025-01-17 19:48:14,628:INFO:Importing libraries
2025-01-17 19:48:14,628:INFO:Copying training dataset
2025-01-17 19:48:14,630:INFO:Defining folds
2025-01-17 19:48:14,630:INFO:Declaring metric variables
2025-01-17 19:48:14,632:INFO:Importing untrained model
2025-01-17 19:48:14,634:INFO:Dummy Classifier Imported successfully
2025-01-17 19:48:14,637:INFO:Starting cross validation
2025-01-17 19:48:14,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:14,654:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,656:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,657:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,657:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,657:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,658:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,658:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,659:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,660:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,661:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,663:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,663:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,664:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,666:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,667:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,668:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,668:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,669:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,669:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,669:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,670:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,670:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,671:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,671:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,672:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:14,676:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,676:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,678:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,678:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,678:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,679:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:14,679:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,694:INFO:Calculating mean and std
2025-01-17 19:48:14,695:INFO:Creating metrics dataframe
2025-01-17 19:48:14,696:INFO:Uploading results into container
2025-01-17 19:48:14,696:INFO:Uploading model into container now
2025-01-17 19:48:14,696:INFO:_master_model_container: 15
2025-01-17 19:48:14,696:INFO:_display_container: 2
2025-01-17 19:48:14,696:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-01-17 19:48:14,697:INFO:create_model() successfully completed......................................
2025-01-17 19:48:14,744:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:14,744:INFO:Creating metrics dataframe
2025-01-17 19:48:14,754:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-17 19:48:14,759:INFO:Initializing create_model()
2025-01-17 19:48:14,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:14,759:INFO:Checking exceptions
2025-01-17 19:48:14,760:INFO:Importing libraries
2025-01-17 19:48:14,760:INFO:Copying training dataset
2025-01-17 19:48:14,762:INFO:Defining folds
2025-01-17 19:48:14,762:INFO:Declaring metric variables
2025-01-17 19:48:14,762:INFO:Importing untrained model
2025-01-17 19:48:14,762:INFO:Declaring custom model
2025-01-17 19:48:14,763:INFO:Logistic Regression Imported successfully
2025-01-17 19:48:14,763:INFO:Cross validation set to False
2025-01-17 19:48:14,763:INFO:Fitting Model
2025-01-17 19:48:14,775:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 19:48:14,776:INFO:create_model() successfully completed......................................
2025-01-17 19:48:14,841:INFO:_master_model_container: 15
2025-01-17 19:48:14,841:INFO:_display_container: 2
2025-01-17 19:48:14,842:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 19:48:14,842:INFO:compare_models() successfully completed......................................
2025-01-17 19:48:14,845:INFO:Initializing compare_models()
2025-01-17 19:48:14,846:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-01-17 19:48:14,846:INFO:Checking exceptions
2025-01-17 19:48:14,849:INFO:Preparing display monitor
2025-01-17 19:48:14,881:INFO:Initializing Logistic Regression
2025-01-17 19:48:14,881:INFO:Total runtime is 3.830591837565104e-06 minutes
2025-01-17 19:48:14,883:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:14,883:INFO:Initializing create_model()
2025-01-17 19:48:14,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:14,884:INFO:Checking exceptions
2025-01-17 19:48:14,884:INFO:Importing libraries
2025-01-17 19:48:14,884:INFO:Copying training dataset
2025-01-17 19:48:14,886:INFO:Defining folds
2025-01-17 19:48:14,886:INFO:Declaring metric variables
2025-01-17 19:48:14,888:INFO:Importing untrained model
2025-01-17 19:48:14,891:INFO:Logistic Regression Imported successfully
2025-01-17 19:48:14,899:INFO:Starting cross validation
2025-01-17 19:48:14,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:14,943:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,946:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,950:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,954:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,959:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,961:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,962:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,962:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,963:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,963:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,964:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,965:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,965:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,966:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,966:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,967:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,967:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,969:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,969:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,970:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,973:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,973:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,973:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,974:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,975:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,975:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,975:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,978:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,978:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,979:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,980:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,981:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,982:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,982:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,983:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,985:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,986:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:14,987:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,988:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,990:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:14,997:INFO:Calculating mean and std
2025-01-17 19:48:14,997:INFO:Creating metrics dataframe
2025-01-17 19:48:14,998:INFO:Uploading results into container
2025-01-17 19:48:14,999:INFO:Uploading model into container now
2025-01-17 19:48:14,999:INFO:_master_model_container: 1
2025-01-17 19:48:14,999:INFO:_display_container: 2
2025-01-17 19:48:14,999:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 19:48:14,999:INFO:create_model() successfully completed......................................
2025-01-17 19:48:15,047:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:15,047:INFO:Creating metrics dataframe
2025-01-17 19:48:15,051:INFO:Initializing K Neighbors Classifier
2025-01-17 19:48:15,051:INFO:Total runtime is 0.002841464678446452 minutes
2025-01-17 19:48:15,053:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:15,053:INFO:Initializing create_model()
2025-01-17 19:48:15,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:15,053:INFO:Checking exceptions
2025-01-17 19:48:15,053:INFO:Importing libraries
2025-01-17 19:48:15,053:INFO:Copying training dataset
2025-01-17 19:48:15,056:INFO:Defining folds
2025-01-17 19:48:15,056:INFO:Declaring metric variables
2025-01-17 19:48:15,058:INFO:Importing untrained model
2025-01-17 19:48:15,060:INFO:K Neighbors Classifier Imported successfully
2025-01-17 19:48:15,064:INFO:Starting cross validation
2025-01-17 19:48:15,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:15,111:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,112:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,117:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,118:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,118:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,119:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,119:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,120:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,120:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,121:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,122:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,123:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,123:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,125:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,125:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,126:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,127:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,127:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,128:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,128:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,128:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,129:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,130:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,130:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,130:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,131:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,131:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,132:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,138:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,139:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,140:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,142:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,150:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,150:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,151:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,151:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,153:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,153:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,154:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,154:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,158:INFO:Calculating mean and std
2025-01-17 19:48:15,159:INFO:Creating metrics dataframe
2025-01-17 19:48:15,160:INFO:Uploading results into container
2025-01-17 19:48:15,161:INFO:Uploading model into container now
2025-01-17 19:48:15,161:INFO:_master_model_container: 2
2025-01-17 19:48:15,161:INFO:_display_container: 2
2025-01-17 19:48:15,161:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-01-17 19:48:15,161:INFO:create_model() successfully completed......................................
2025-01-17 19:48:15,210:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:15,210:INFO:Creating metrics dataframe
2025-01-17 19:48:15,215:INFO:Initializing Naive Bayes
2025-01-17 19:48:15,215:INFO:Total runtime is 0.005575450261433919 minutes
2025-01-17 19:48:15,217:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:15,217:INFO:Initializing create_model()
2025-01-17 19:48:15,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:15,217:INFO:Checking exceptions
2025-01-17 19:48:15,217:INFO:Importing libraries
2025-01-17 19:48:15,217:INFO:Copying training dataset
2025-01-17 19:48:15,219:INFO:Defining folds
2025-01-17 19:48:15,219:INFO:Declaring metric variables
2025-01-17 19:48:15,222:INFO:Importing untrained model
2025-01-17 19:48:15,223:INFO:Naive Bayes Imported successfully
2025-01-17 19:48:15,227:INFO:Starting cross validation
2025-01-17 19:48:15,228:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:15,245:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,246:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,247:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,248:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,249:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,249:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,251:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,252:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,252:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,253:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,255:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,256:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,256:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,257:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,259:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,260:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,261:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,261:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,262:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,262:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,263:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,264:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,264:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,267:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,267:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,268:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,268:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,269:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,270:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,271:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,272:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,272:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,273:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,275:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,277:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,281:INFO:Calculating mean and std
2025-01-17 19:48:15,281:INFO:Creating metrics dataframe
2025-01-17 19:48:15,282:INFO:Uploading results into container
2025-01-17 19:48:15,283:INFO:Uploading model into container now
2025-01-17 19:48:15,283:INFO:_master_model_container: 3
2025-01-17 19:48:15,283:INFO:_display_container: 2
2025-01-17 19:48:15,283:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-01-17 19:48:15,283:INFO:create_model() successfully completed......................................
2025-01-17 19:48:15,331:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:15,331:INFO:Creating metrics dataframe
2025-01-17 19:48:15,336:INFO:Initializing Decision Tree Classifier
2025-01-17 19:48:15,336:INFO:Total runtime is 0.0075836817423502595 minutes
2025-01-17 19:48:15,338:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:15,338:INFO:Initializing create_model()
2025-01-17 19:48:15,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:15,338:INFO:Checking exceptions
2025-01-17 19:48:15,338:INFO:Importing libraries
2025-01-17 19:48:15,338:INFO:Copying training dataset
2025-01-17 19:48:15,340:INFO:Defining folds
2025-01-17 19:48:15,340:INFO:Declaring metric variables
2025-01-17 19:48:15,342:INFO:Importing untrained model
2025-01-17 19:48:15,344:INFO:Decision Tree Classifier Imported successfully
2025-01-17 19:48:15,348:INFO:Starting cross validation
2025-01-17 19:48:15,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:15,367:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,368:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,369:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,370:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,372:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,373:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,374:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,376:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,377:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,384:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,385:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,385:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,385:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,386:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,386:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,386:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,387:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,387:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,387:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,387:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,389:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,389:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,389:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,390:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,391:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,391:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,392:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,392:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,393:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,394:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,394:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,395:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,396:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,404:INFO:Calculating mean and std
2025-01-17 19:48:15,405:INFO:Creating metrics dataframe
2025-01-17 19:48:15,406:INFO:Uploading results into container
2025-01-17 19:48:15,406:INFO:Uploading model into container now
2025-01-17 19:48:15,406:INFO:_master_model_container: 4
2025-01-17 19:48:15,406:INFO:_display_container: 2
2025-01-17 19:48:15,407:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-01-17 19:48:15,407:INFO:create_model() successfully completed......................................
2025-01-17 19:48:15,455:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:15,455:INFO:Creating metrics dataframe
2025-01-17 19:48:15,460:INFO:Initializing SVM - Linear Kernel
2025-01-17 19:48:15,460:INFO:Total runtime is 0.009660414854685464 minutes
2025-01-17 19:48:15,462:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:15,462:INFO:Initializing create_model()
2025-01-17 19:48:15,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:15,462:INFO:Checking exceptions
2025-01-17 19:48:15,462:INFO:Importing libraries
2025-01-17 19:48:15,462:INFO:Copying training dataset
2025-01-17 19:48:15,464:INFO:Defining folds
2025-01-17 19:48:15,464:INFO:Declaring metric variables
2025-01-17 19:48:15,466:INFO:Importing untrained model
2025-01-17 19:48:15,468:INFO:SVM - Linear Kernel Imported successfully
2025-01-17 19:48:15,472:INFO:Starting cross validation
2025-01-17 19:48:15,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:15,508:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,509:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,510:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,511:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:15,511:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,512:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,512:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,512:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,513:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,513:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,514:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,514:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,515:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,515:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:15,515:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:15,516:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,516:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,516:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,518:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,518:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,520:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,520:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,522:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,523:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,525:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,525:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,529:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,531:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,532:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:15,533:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,544:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,544:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,545:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,545:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,546:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,546:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,547:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:15,547:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:15,548:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,548:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,563:INFO:Calculating mean and std
2025-01-17 19:48:15,563:INFO:Creating metrics dataframe
2025-01-17 19:48:15,564:INFO:Uploading results into container
2025-01-17 19:48:15,565:INFO:Uploading model into container now
2025-01-17 19:48:15,565:INFO:_master_model_container: 5
2025-01-17 19:48:15,565:INFO:_display_container: 2
2025-01-17 19:48:15,565:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-01-17 19:48:15,565:INFO:create_model() successfully completed......................................
2025-01-17 19:48:15,613:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:15,613:INFO:Creating metrics dataframe
2025-01-17 19:48:15,618:INFO:Initializing Ridge Classifier
2025-01-17 19:48:15,618:INFO:Total runtime is 0.01229496399561564 minutes
2025-01-17 19:48:15,620:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:15,620:INFO:Initializing create_model()
2025-01-17 19:48:15,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:15,621:INFO:Checking exceptions
2025-01-17 19:48:15,621:INFO:Importing libraries
2025-01-17 19:48:15,621:INFO:Copying training dataset
2025-01-17 19:48:15,623:INFO:Defining folds
2025-01-17 19:48:15,623:INFO:Declaring metric variables
2025-01-17 19:48:15,625:INFO:Importing untrained model
2025-01-17 19:48:15,627:INFO:Ridge Classifier Imported successfully
2025-01-17 19:48:15,631:INFO:Starting cross validation
2025-01-17 19:48:15,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:15,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,651:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,653:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,653:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,654:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,654:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,654:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,656:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,656:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,657:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,657:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,658:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,658:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,663:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,664:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,664:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,665:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,665:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,666:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,667:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,668:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,669:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,670:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,672:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,672:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:15,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,676:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,676:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,678:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,689:INFO:Calculating mean and std
2025-01-17 19:48:15,689:INFO:Creating metrics dataframe
2025-01-17 19:48:15,690:INFO:Uploading results into container
2025-01-17 19:48:15,691:INFO:Uploading model into container now
2025-01-17 19:48:15,691:INFO:_master_model_container: 6
2025-01-17 19:48:15,691:INFO:_display_container: 2
2025-01-17 19:48:15,691:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-01-17 19:48:15,691:INFO:create_model() successfully completed......................................
2025-01-17 19:48:15,739:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:15,739:INFO:Creating metrics dataframe
2025-01-17 19:48:15,744:INFO:Initializing Random Forest Classifier
2025-01-17 19:48:15,744:INFO:Total runtime is 0.014394851525624591 minutes
2025-01-17 19:48:15,746:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:15,746:INFO:Initializing create_model()
2025-01-17 19:48:15,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:15,747:INFO:Checking exceptions
2025-01-17 19:48:15,747:INFO:Importing libraries
2025-01-17 19:48:15,747:INFO:Copying training dataset
2025-01-17 19:48:15,748:INFO:Defining folds
2025-01-17 19:48:15,748:INFO:Declaring metric variables
2025-01-17 19:48:15,750:INFO:Importing untrained model
2025-01-17 19:48:15,752:INFO:Random Forest Classifier Imported successfully
2025-01-17 19:48:15,756:INFO:Starting cross validation
2025-01-17 19:48:15,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:15,971:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,973:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,975:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,976:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,978:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,980:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,982:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,984:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,985:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,985:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,986:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,987:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,988:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,989:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,990:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,990:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,996:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,997:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:15,997:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,998:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,999:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:15,999:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,001:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,001:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,007:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:16,008:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,010:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,011:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:16,012:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,012:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,014:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,016:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,124:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:16,125:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,127:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,128:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,135:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:16,136:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,138:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,140:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,144:INFO:Calculating mean and std
2025-01-17 19:48:16,145:INFO:Creating metrics dataframe
2025-01-17 19:48:16,147:INFO:Uploading results into container
2025-01-17 19:48:16,147:INFO:Uploading model into container now
2025-01-17 19:48:16,148:INFO:_master_model_container: 7
2025-01-17 19:48:16,148:INFO:_display_container: 2
2025-01-17 19:48:16,148:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-01-17 19:48:16,148:INFO:create_model() successfully completed......................................
2025-01-17 19:48:16,202:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:16,202:INFO:Creating metrics dataframe
2025-01-17 19:48:16,209:INFO:Initializing Quadratic Discriminant Analysis
2025-01-17 19:48:16,209:INFO:Total runtime is 0.022134812672932942 minutes
2025-01-17 19:48:16,211:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:16,211:INFO:Initializing create_model()
2025-01-17 19:48:16,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:16,211:INFO:Checking exceptions
2025-01-17 19:48:16,211:INFO:Importing libraries
2025-01-17 19:48:16,211:INFO:Copying training dataset
2025-01-17 19:48:16,214:INFO:Defining folds
2025-01-17 19:48:16,214:INFO:Declaring metric variables
2025-01-17 19:48:16,216:INFO:Importing untrained model
2025-01-17 19:48:16,218:INFO:Quadratic Discriminant Analysis Imported successfully
2025-01-17 19:48:16,223:INFO:Starting cross validation
2025-01-17 19:48:16,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:16,241:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,242:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,244:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,245:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,247:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,247:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,248:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,248:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,250:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,250:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,250:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,251:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,251:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,251:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,252:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,256:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,258:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,259:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,259:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,260:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,260:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,260:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,261:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,261:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,262:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,262:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,262:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,263:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,263:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,264:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,264:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,268:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,268:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,269:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,271:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,272:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,281:INFO:Calculating mean and std
2025-01-17 19:48:16,281:INFO:Creating metrics dataframe
2025-01-17 19:48:16,283:INFO:Uploading results into container
2025-01-17 19:48:16,283:INFO:Uploading model into container now
2025-01-17 19:48:16,283:INFO:_master_model_container: 8
2025-01-17 19:48:16,283:INFO:_display_container: 2
2025-01-17 19:48:16,284:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-01-17 19:48:16,284:INFO:create_model() successfully completed......................................
2025-01-17 19:48:16,331:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:16,331:INFO:Creating metrics dataframe
2025-01-17 19:48:16,338:INFO:Initializing Ada Boost Classifier
2025-01-17 19:48:16,338:INFO:Total runtime is 0.02428606351216634 minutes
2025-01-17 19:48:16,340:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:16,340:INFO:Initializing create_model()
2025-01-17 19:48:16,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:16,340:INFO:Checking exceptions
2025-01-17 19:48:16,340:INFO:Importing libraries
2025-01-17 19:48:16,340:INFO:Copying training dataset
2025-01-17 19:48:16,342:INFO:Defining folds
2025-01-17 19:48:16,342:INFO:Declaring metric variables
2025-01-17 19:48:16,344:INFO:Importing untrained model
2025-01-17 19:48:16,346:INFO:Ada Boost Classifier Imported successfully
2025-01-17 19:48:16,350:INFO:Starting cross validation
2025-01-17 19:48:16,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:16,364:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,365:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,368:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,371:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,377:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,385:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,430:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,431:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,432:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,437:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,438:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,438:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,440:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,441:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,442:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,444:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,447:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,447:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,452:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 19:48:16,452:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,453:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,453:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,454:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,454:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,455:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,455:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,457:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,457:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,458:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,460:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,461:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,481:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,482:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,483:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,485:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,506:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,507:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,509:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,510:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,512:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,513:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,515:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,517:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,529:INFO:Calculating mean and std
2025-01-17 19:48:16,530:INFO:Creating metrics dataframe
2025-01-17 19:48:16,531:INFO:Uploading results into container
2025-01-17 19:48:16,531:INFO:Uploading model into container now
2025-01-17 19:48:16,532:INFO:_master_model_container: 9
2025-01-17 19:48:16,532:INFO:_display_container: 2
2025-01-17 19:48:16,532:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-01-17 19:48:16,532:INFO:create_model() successfully completed......................................
2025-01-17 19:48:16,583:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:16,583:INFO:Creating metrics dataframe
2025-01-17 19:48:16,590:INFO:Initializing Gradient Boosting Classifier
2025-01-17 19:48:16,590:INFO:Total runtime is 0.028487833340962727 minutes
2025-01-17 19:48:16,592:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:16,592:INFO:Initializing create_model()
2025-01-17 19:48:16,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:16,592:INFO:Checking exceptions
2025-01-17 19:48:16,592:INFO:Importing libraries
2025-01-17 19:48:16,593:INFO:Copying training dataset
2025-01-17 19:48:16,595:INFO:Defining folds
2025-01-17 19:48:16,595:INFO:Declaring metric variables
2025-01-17 19:48:16,597:INFO:Importing untrained model
2025-01-17 19:48:16,599:INFO:Gradient Boosting Classifier Imported successfully
2025-01-17 19:48:16,603:INFO:Starting cross validation
2025-01-17 19:48:16,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:16,901:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,903:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,906:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,916:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,928:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,929:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,938:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,947:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,949:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,953:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,957:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,960:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,961:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,964:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,964:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,966:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,968:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,969:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,973:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,973:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,975:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,978:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,980:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,981:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,982:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,986:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,989:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:16,995:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:16,997:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,000:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,004:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,163:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,164:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,165:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,165:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,166:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,167:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,167:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,169:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,175:INFO:Calculating mean and std
2025-01-17 19:48:17,176:INFO:Creating metrics dataframe
2025-01-17 19:48:17,177:INFO:Uploading results into container
2025-01-17 19:48:17,177:INFO:Uploading model into container now
2025-01-17 19:48:17,177:INFO:_master_model_container: 10
2025-01-17 19:48:17,178:INFO:_display_container: 2
2025-01-17 19:48:17,178:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-01-17 19:48:17,178:INFO:create_model() successfully completed......................................
2025-01-17 19:48:17,226:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:17,226:INFO:Creating metrics dataframe
2025-01-17 19:48:17,232:INFO:Initializing Linear Discriminant Analysis
2025-01-17 19:48:17,233:INFO:Total runtime is 0.039200500647226966 minutes
2025-01-17 19:48:17,235:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:17,235:INFO:Initializing create_model()
2025-01-17 19:48:17,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:17,235:INFO:Checking exceptions
2025-01-17 19:48:17,235:INFO:Importing libraries
2025-01-17 19:48:17,235:INFO:Copying training dataset
2025-01-17 19:48:17,237:INFO:Defining folds
2025-01-17 19:48:17,237:INFO:Declaring metric variables
2025-01-17 19:48:17,239:INFO:Importing untrained model
2025-01-17 19:48:17,241:INFO:Linear Discriminant Analysis Imported successfully
2025-01-17 19:48:17,245:INFO:Starting cross validation
2025-01-17 19:48:17,245:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:17,264:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,264:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,268:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,269:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,270:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,271:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,273:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,273:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,274:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,275:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,276:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,276:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,277:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,277:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,279:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,281:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,282:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,283:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,283:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,284:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,284:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,285:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,285:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,287:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,287:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,289:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,289:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,290:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,291:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,291:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,291:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,292:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-01-17 19:48:17,292:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,293:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,293:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,294:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,294:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,295:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,296:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,303:INFO:Calculating mean and std
2025-01-17 19:48:17,304:INFO:Creating metrics dataframe
2025-01-17 19:48:17,305:INFO:Uploading results into container
2025-01-17 19:48:17,305:INFO:Uploading model into container now
2025-01-17 19:48:17,306:INFO:_master_model_container: 11
2025-01-17 19:48:17,306:INFO:_display_container: 2
2025-01-17 19:48:17,306:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-01-17 19:48:17,306:INFO:create_model() successfully completed......................................
2025-01-17 19:48:17,354:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:17,354:INFO:Creating metrics dataframe
2025-01-17 19:48:17,361:INFO:Initializing Extra Trees Classifier
2025-01-17 19:48:17,361:INFO:Total runtime is 0.04133568207422892 minutes
2025-01-17 19:48:17,363:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:17,363:INFO:Initializing create_model()
2025-01-17 19:48:17,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:17,363:INFO:Checking exceptions
2025-01-17 19:48:17,363:INFO:Importing libraries
2025-01-17 19:48:17,363:INFO:Copying training dataset
2025-01-17 19:48:17,365:INFO:Defining folds
2025-01-17 19:48:17,365:INFO:Declaring metric variables
2025-01-17 19:48:17,367:INFO:Importing untrained model
2025-01-17 19:48:17,369:INFO:Extra Trees Classifier Imported successfully
2025-01-17 19:48:17,373:INFO:Starting cross validation
2025-01-17 19:48:17,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:17,619:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,620:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,622:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,624:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,624:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,626:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,628:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,628:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,630:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,630:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,631:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,632:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,633:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,634:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,634:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,636:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,637:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,641:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,641:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,645:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,652:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,653:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,654:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,656:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,657:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,659:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,659:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,661:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,663:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,666:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,668:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,764:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,766:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,768:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,770:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,771:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,772:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,774:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,776:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,786:INFO:Calculating mean and std
2025-01-17 19:48:17,787:INFO:Creating metrics dataframe
2025-01-17 19:48:17,789:INFO:Uploading results into container
2025-01-17 19:48:17,789:INFO:Uploading model into container now
2025-01-17 19:48:17,789:INFO:_master_model_container: 12
2025-01-17 19:48:17,790:INFO:_display_container: 2
2025-01-17 19:48:17,790:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-01-17 19:48:17,790:INFO:create_model() successfully completed......................................
2025-01-17 19:48:17,845:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:17,845:INFO:Creating metrics dataframe
2025-01-17 19:48:17,853:INFO:Initializing Extreme Gradient Boosting
2025-01-17 19:48:17,853:INFO:Total runtime is 0.04954071442286173 minutes
2025-01-17 19:48:17,855:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:17,856:INFO:Initializing create_model()
2025-01-17 19:48:17,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:17,856:INFO:Checking exceptions
2025-01-17 19:48:17,856:INFO:Importing libraries
2025-01-17 19:48:17,856:INFO:Copying training dataset
2025-01-17 19:48:17,858:INFO:Defining folds
2025-01-17 19:48:17,858:INFO:Declaring metric variables
2025-01-17 19:48:17,860:INFO:Importing untrained model
2025-01-17 19:48:17,863:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 19:48:17,867:INFO:Starting cross validation
2025-01-17 19:48:17,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:17,901:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,902:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,904:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,905:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,908:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,909:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,911:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,913:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,919:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,920:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,923:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,925:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,926:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,926:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,927:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,929:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,930:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,931:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,932:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,933:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,934:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,935:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,935:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,936:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,937:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,939:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,941:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,941:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,942:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,944:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,945:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,954:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:17,955:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,957:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,959:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:17,972:INFO:Calculating mean and std
2025-01-17 19:48:17,973:INFO:Creating metrics dataframe
2025-01-17 19:48:17,974:INFO:Uploading results into container
2025-01-17 19:48:17,975:INFO:Uploading model into container now
2025-01-17 19:48:17,975:INFO:_master_model_container: 13
2025-01-17 19:48:17,975:INFO:_display_container: 2
2025-01-17 19:48:17,976:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 19:48:17,976:INFO:create_model() successfully completed......................................
2025-01-17 19:48:18,023:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:18,023:INFO:Creating metrics dataframe
2025-01-17 19:48:18,031:INFO:Initializing Light Gradient Boosting Machine
2025-01-17 19:48:18,031:INFO:Total runtime is 0.05250213146209717 minutes
2025-01-17 19:48:18,033:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:18,033:INFO:Initializing create_model()
2025-01-17 19:48:18,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:18,033:INFO:Checking exceptions
2025-01-17 19:48:18,033:INFO:Importing libraries
2025-01-17 19:48:18,033:INFO:Copying training dataset
2025-01-17 19:48:18,035:INFO:Defining folds
2025-01-17 19:48:18,035:INFO:Declaring metric variables
2025-01-17 19:48:18,037:INFO:Importing untrained model
2025-01-17 19:48:18,039:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-17 19:48:18,043:INFO:Starting cross validation
2025-01-17 19:48:18,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:18,732:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:18,734:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,736:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,737:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,795:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:18,803:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,812:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,813:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:18,814:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,816:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,817:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,819:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,848:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:18,849:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,850:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:18,851:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,851:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,852:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,853:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,855:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,860:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:18,860:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,862:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,863:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,876:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:18,877:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,878:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,880:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,902:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:18,903:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,906:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:18,909:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,081:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,082:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,083:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,085:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,089:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,090:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,092:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,093:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,102:INFO:Calculating mean and std
2025-01-17 19:48:19,102:INFO:Creating metrics dataframe
2025-01-17 19:48:19,104:INFO:Uploading results into container
2025-01-17 19:48:19,104:INFO:Uploading model into container now
2025-01-17 19:48:19,104:INFO:_master_model_container: 14
2025-01-17 19:48:19,104:INFO:_display_container: 2
2025-01-17 19:48:19,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-01-17 19:48:19,104:INFO:create_model() successfully completed......................................
2025-01-17 19:48:19,152:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:19,153:INFO:Creating metrics dataframe
2025-01-17 19:48:19,160:INFO:Initializing Dummy Classifier
2025-01-17 19:48:19,160:INFO:Total runtime is 0.0713267962137858 minutes
2025-01-17 19:48:19,162:INFO:SubProcess create_model() called ==================================
2025-01-17 19:48:19,162:INFO:Initializing create_model()
2025-01-17 19:48:19,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x163e9e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:19,162:INFO:Checking exceptions
2025-01-17 19:48:19,163:INFO:Importing libraries
2025-01-17 19:48:19,163:INFO:Copying training dataset
2025-01-17 19:48:19,165:INFO:Defining folds
2025-01-17 19:48:19,165:INFO:Declaring metric variables
2025-01-17 19:48:19,167:INFO:Importing untrained model
2025-01-17 19:48:19,169:INFO:Dummy Classifier Imported successfully
2025-01-17 19:48:19,172:INFO:Starting cross validation
2025-01-17 19:48:19,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 19:48:19,189:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,190:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,191:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,191:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,192:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,192:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,193:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,194:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,194:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,195:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,196:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,197:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,199:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,199:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,200:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,200:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,201:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,204:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,205:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,206:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,206:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,206:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,207:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,208:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,208:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,208:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,209:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,209:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,209:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,210:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,210:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,210:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,211:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,212:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,213:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,214:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,214:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,215:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,216:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,217:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,217:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/utils/generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2025-01-17 19:48:19,218:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,218:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,219:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,220:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 19:48:19,221:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:48:19,230:INFO:Calculating mean and std
2025-01-17 19:48:19,231:INFO:Creating metrics dataframe
2025-01-17 19:48:19,232:INFO:Uploading results into container
2025-01-17 19:48:19,232:INFO:Uploading model into container now
2025-01-17 19:48:19,233:INFO:_master_model_container: 15
2025-01-17 19:48:19,233:INFO:_display_container: 2
2025-01-17 19:48:19,233:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-01-17 19:48:19,233:INFO:create_model() successfully completed......................................
2025-01-17 19:48:19,281:INFO:SubProcess create_model() end ==================================
2025-01-17 19:48:19,281:INFO:Creating metrics dataframe
2025-01-17 19:48:19,289:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-17 19:48:19,294:INFO:Initializing create_model()
2025-01-17 19:48:19,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163dfa800>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 19:48:19,294:INFO:Checking exceptions
2025-01-17 19:48:19,295:INFO:Importing libraries
2025-01-17 19:48:19,295:INFO:Copying training dataset
2025-01-17 19:48:19,297:INFO:Defining folds
2025-01-17 19:48:19,297:INFO:Declaring metric variables
2025-01-17 19:48:19,297:INFO:Importing untrained model
2025-01-17 19:48:19,297:INFO:Declaring custom model
2025-01-17 19:48:19,297:INFO:Logistic Regression Imported successfully
2025-01-17 19:48:19,298:INFO:Cross validation set to False
2025-01-17 19:48:19,298:INFO:Fitting Model
2025-01-17 19:48:19,309:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 19:48:19,310:INFO:create_model() successfully completed......................................
2025-01-17 19:48:19,373:INFO:_master_model_container: 15
2025-01-17 19:48:19,373:INFO:_display_container: 2
2025-01-17 19:48:19,374:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 19:48:19,374:INFO:compare_models() successfully completed......................................
2025-01-17 19:48:19,379:INFO:Initializing plot_model()
2025-01-17 19:48:19,379:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, system=True)
2025-01-17 19:48:19,379:INFO:Checking exceptions
2025-01-17 19:48:19,381:INFO:Preloading libraries
2025-01-17 19:48:19,381:INFO:Copying training dataset
2025-01-17 19:48:19,381:INFO:Plot type: confusion_matrix
2025-01-17 19:48:19,436:INFO:Fitting Model
2025-01-17 19:48:19,437:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-01-17 19:48:19,437:INFO:Scoring test/hold-out set
2025-01-17 19:48:19,529:INFO:Visual Rendered Successfully
2025-01-17 19:48:19,578:INFO:plot_model() successfully completed......................................
2025-01-17 19:48:19,581:INFO:Initializing plot_model()
2025-01-17 19:48:19,582:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, system=True)
2025-01-17 19:48:19,582:INFO:Checking exceptions
2025-01-17 19:48:19,584:INFO:Preloading libraries
2025-01-17 19:48:19,584:INFO:Copying training dataset
2025-01-17 19:48:19,584:INFO:Plot type: auc
2025-01-17 19:48:19,636:INFO:Fitting Model
2025-01-17 19:48:19,636:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-01-17 19:48:19,636:INFO:Scoring test/hold-out set
2025-01-17 19:48:19,746:INFO:Visual Rendered Successfully
2025-01-17 19:48:19,795:INFO:plot_model() successfully completed......................................
2025-01-17 19:48:19,800:INFO:Initializing plot_model()
2025-01-17 19:48:19,801:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, system=True)
2025-01-17 19:48:19,801:INFO:Checking exceptions
2025-01-17 19:48:19,808:INFO:Preloading libraries
2025-01-17 19:48:19,809:INFO:Copying training dataset
2025-01-17 19:48:19,810:INFO:Plot type: feature
2025-01-17 19:48:19,914:INFO:Visual Rendered Successfully
2025-01-17 19:48:19,963:INFO:plot_model() successfully completed......................................
2025-01-17 19:48:19,966:INFO:Initializing evaluate_model()
2025-01-17 19:48:19,967:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-01-17 19:48:19,976:INFO:Initializing plot_model()
2025-01-17 19:48:19,977:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, system=True)
2025-01-17 19:48:19,977:INFO:Checking exceptions
2025-01-17 19:48:19,978:INFO:Preloading libraries
2025-01-17 19:48:19,979:INFO:Copying training dataset
2025-01-17 19:48:19,979:INFO:Plot type: pipeline
2025-01-17 19:48:20,069:INFO:Visual Rendered Successfully
2025-01-17 19:48:20,118:INFO:plot_model() successfully completed......................................
2025-01-17 19:49:21,094:INFO:Initializing predict_model()
2025-01-17 19:49:21,095:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16102bb80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x163d528c0>)
2025-01-17 19:49:21,095:INFO:Checking exceptions
2025-01-17 19:49:21,096:INFO:Preloading libraries
2025-01-17 19:49:21,210:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:49:21,212:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 19:49:21,214:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-01-17 21:13:23,219:INFO:PyCaret ClassificationExperiment
2025-01-17 21:13:23,219:INFO:Logging name: clf-default-name
2025-01-17 21:13:23,219:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-01-17 21:13:23,219:INFO:version 3.3.1
2025-01-17 21:13:23,220:INFO:Initializing setup()
2025-01-17 21:13:23,220:INFO:self.USI: dab4
2025-01-17 21:13:23,220:INFO:self._variable_keys: {'memory', '_ml_usecase', 'data', 'log_plots_param', 'idx', 'fold_groups_param', '_available_plots', 'seed', 'X_train', 'pipeline', 'y_test', 'y', 'fold_generator', 'fix_imbalance', 'html_param', 'gpu_param', 'exp_id', 'fold_shuffle_param', 'target_param', 'exp_name_log', 'is_multiclass', 'y_train', 'gpu_n_jobs_param', 'n_jobs_param', 'X', 'USI', 'logging_param', 'X_test'}
2025-01-17 21:13:23,220:INFO:Checking environment
2025-01-17 21:13:23,220:INFO:python_version: 3.10.13
2025-01-17 21:13:23,220:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-17 21:13:23,220:INFO:machine: arm64
2025-01-17 21:13:23,220:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-17 21:13:23,221:INFO:Memory: svmem(total=8589934592, available=2720940032, percent=68.3, used=4010606592, free=89964544, active=2649227264, inactive=2629812224, wired=1361379328)
2025-01-17 21:13:23,221:INFO:Physical Core: 8
2025-01-17 21:13:23,221:INFO:Logical Core: 8
2025-01-17 21:13:23,221:INFO:Checking libraries
2025-01-17 21:13:23,221:INFO:System:
2025-01-17 21:13:23,221:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-17 21:13:23,222:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-17 21:13:23,222:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-17 21:13:23,222:INFO:PyCaret required dependencies:
2025-01-17 21:13:23,222:INFO:                 pip: 24.2
2025-01-17 21:13:23,222:INFO:          setuptools: 75.1.0
2025-01-17 21:13:23,222:INFO:             pycaret: 3.3.1
2025-01-17 21:13:23,222:INFO:             IPython: 8.27.0
2025-01-17 21:13:23,222:INFO:          ipywidgets: 8.1.2
2025-01-17 21:13:23,222:INFO:                tqdm: 4.66.5
2025-01-17 21:13:23,222:INFO:               numpy: 1.26.4
2025-01-17 21:13:23,222:INFO:              pandas: 2.1.4
2025-01-17 21:13:23,222:INFO:              jinja2: 3.1.4
2025-01-17 21:13:23,222:INFO:               scipy: 1.11.4
2025-01-17 21:13:23,222:INFO:              joblib: 1.3.2
2025-01-17 21:13:23,222:INFO:             sklearn: 1.4.2
2025-01-17 21:13:23,222:INFO:                pyod: 2.0.2
2025-01-17 21:13:23,222:INFO:            imblearn: 0.13.0
2025-01-17 21:13:23,222:INFO:   category_encoders: 2.7.0
2025-01-17 21:13:23,223:INFO:            lightgbm: 4.4.0
2025-01-17 21:13:23,223:INFO:               numba: 0.60.0
2025-01-17 21:13:23,223:INFO:            requests: 2.32.3
2025-01-17 21:13:23,223:INFO:          matplotlib: 3.9.2
2025-01-17 21:13:23,223:INFO:          scikitplot: 0.3.7
2025-01-17 21:13:23,223:INFO:         yellowbrick: 1.5
2025-01-17 21:13:23,223:INFO:              plotly: 5.24.1
2025-01-17 21:13:23,223:INFO:    plotly-resampler: Not installed
2025-01-17 21:13:23,223:INFO:             kaleido: 0.2.1
2025-01-17 21:13:23,223:INFO:           schemdraw: 0.15
2025-01-17 21:13:23,223:INFO:         statsmodels: 0.14.4
2025-01-17 21:13:23,223:INFO:              sktime: 0.26.0
2025-01-17 21:13:23,223:INFO:               tbats: 1.1.3
2025-01-17 21:13:23,223:INFO:            pmdarima: 2.0.4
2025-01-17 21:13:23,223:INFO:              psutil: 5.9.0
2025-01-17 21:13:23,223:INFO:          markupsafe: 2.1.3
2025-01-17 21:13:23,223:INFO:             pickle5: Not installed
2025-01-17 21:13:23,223:INFO:         cloudpickle: 3.1.0
2025-01-17 21:13:23,223:INFO:         deprecation: 2.1.0
2025-01-17 21:13:23,223:INFO:              xxhash: 3.5.0
2025-01-17 21:13:23,223:INFO:           wurlitzer: 3.1.1
2025-01-17 21:13:23,224:INFO:PyCaret optional dependencies:
2025-01-17 21:13:23,224:INFO:                shap: Not installed
2025-01-17 21:13:23,224:INFO:           interpret: Not installed
2025-01-17 21:13:23,224:INFO:                umap: 0.5.7
2025-01-17 21:13:23,224:INFO:     ydata_profiling: Not installed
2025-01-17 21:13:23,224:INFO:  explainerdashboard: Not installed
2025-01-17 21:13:23,224:INFO:             autoviz: Not installed
2025-01-17 21:13:23,224:INFO:           fairlearn: Not installed
2025-01-17 21:13:23,224:INFO:          deepchecks: Not installed
2025-01-17 21:13:23,224:INFO:             xgboost: 2.1.3
2025-01-17 21:13:23,224:INFO:            catboost: Not installed
2025-01-17 21:13:23,224:INFO:              kmodes: Not installed
2025-01-17 21:13:23,224:INFO:             mlxtend: Not installed
2025-01-17 21:13:23,224:INFO:       statsforecast: Not installed
2025-01-17 21:13:23,224:INFO:        tune_sklearn: Not installed
2025-01-17 21:13:23,224:INFO:                 ray: Not installed
2025-01-17 21:13:23,224:INFO:            hyperopt: Not installed
2025-01-17 21:13:23,224:INFO:              optuna: Not installed
2025-01-17 21:13:23,224:INFO:               skopt: Not installed
2025-01-17 21:13:23,224:INFO:              mlflow: Not installed
2025-01-17 21:13:23,225:INFO:              gradio: Not installed
2025-01-17 21:13:23,225:INFO:             fastapi: Not installed
2025-01-17 21:13:23,225:INFO:             uvicorn: Not installed
2025-01-17 21:13:23,225:INFO:              m2cgen: Not installed
2025-01-17 21:13:23,225:INFO:           evidently: Not installed
2025-01-17 21:13:23,225:INFO:               fugue: Not installed
2025-01-17 21:13:23,225:INFO:           streamlit: Not installed
2025-01-17 21:13:23,225:INFO:             prophet: Not installed
2025-01-17 21:13:23,225:INFO:None
2025-01-17 21:13:23,225:INFO:Set up data.
2025-01-17 21:13:23,272:INFO:Set up folding strategy.
2025-01-17 21:13:23,272:INFO:Set up train/test split.
2025-01-17 21:13:23,313:INFO:Set up index.
2025-01-17 21:13:23,314:INFO:Assigning column types.
2025-01-17 21:13:23,323:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-17 21:13:23,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 21:13:23,356:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:13:23,377:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:13:23,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:13:23,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 21:13:23,411:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:13:23,431:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:13:23,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:13:23,433:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-17 21:13:23,464:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:13:23,484:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:13:23,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:13:23,518:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:13:23,537:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:13:23,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:13:23,539:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-01-17 21:13:23,590:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:13:23,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:13:23,643:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:13:23,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:13:23,647:INFO:Preparing preprocessing pipeline...
2025-01-17 21:13:23,649:INFO:Set up simple imputation.
2025-01-17 21:13:23,656:INFO:Set up encoding of ordinal features.
2025-01-17 21:13:23,661:INFO:Set up encoding of categorical features.
2025-01-17 21:13:23,870:INFO:Finished creating preprocessing pipeline.
2025-01-17 21:13:23,885:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-01-17 21:13:23,885:INFO:Creating final display dataframe.
2025-01-17 21:13:24,269:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       loan_status
2                   Target type            Binary
3           Original data shape       (45000, 14)
4        Transformed data shape       (45000, 26)
5   Transformed train set shape       (31499, 26)
6    Transformed test set shape       (13501, 26)
7              Numeric features                 8
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              dab4
2025-01-17 21:13:24,329:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:13:24,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:13:24,385:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:13:24,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:13:24,388:INFO:setup() successfully completed in 1.17s...............
2025-01-17 21:13:56,820:INFO:Initializing compare_models()
2025-01-17 21:13:56,820:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-01-17 21:13:56,821:INFO:Checking exceptions
2025-01-17 21:13:56,865:INFO:Preparing display monitor
2025-01-17 21:13:56,888:INFO:Initializing Logistic Regression
2025-01-17 21:13:56,889:INFO:Total runtime is 9.0638796488444e-06 minutes
2025-01-17 21:13:56,892:INFO:SubProcess create_model() called ==================================
2025-01-17 21:13:56,892:INFO:Initializing create_model()
2025-01-17 21:13:56,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:13:56,893:INFO:Checking exceptions
2025-01-17 21:13:56,893:INFO:Importing libraries
2025-01-17 21:13:56,893:INFO:Copying training dataset
2025-01-17 21:13:56,913:INFO:Defining folds
2025-01-17 21:13:56,913:INFO:Declaring metric variables
2025-01-17 21:13:56,916:INFO:Importing untrained model
2025-01-17 21:13:56,919:INFO:Logistic Regression Imported successfully
2025-01-17 21:13:56,925:INFO:Starting cross validation
2025-01-17 21:13:56,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:06,341:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:06,343:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:06,360:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:06,429:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:06,445:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:06,519:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:06,529:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:06,668:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:08,861:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:08,895:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:14:08,942:INFO:Calculating mean and std
2025-01-17 21:14:08,944:INFO:Creating metrics dataframe
2025-01-17 21:14:08,947:INFO:Uploading results into container
2025-01-17 21:14:08,948:INFO:Uploading model into container now
2025-01-17 21:14:08,949:INFO:_master_model_container: 1
2025-01-17 21:14:08,949:INFO:_display_container: 2
2025-01-17 21:14:08,949:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 21:14:08,949:INFO:create_model() successfully completed......................................
2025-01-17 21:14:09,061:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:09,061:INFO:Creating metrics dataframe
2025-01-17 21:14:09,065:INFO:Initializing K Neighbors Classifier
2025-01-17 21:14:09,066:INFO:Total runtime is 0.2029518485069275 minutes
2025-01-17 21:14:09,068:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:09,068:INFO:Initializing create_model()
2025-01-17 21:14:09,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:09,068:INFO:Checking exceptions
2025-01-17 21:14:09,068:INFO:Importing libraries
2025-01-17 21:14:09,068:INFO:Copying training dataset
2025-01-17 21:14:09,084:INFO:Defining folds
2025-01-17 21:14:09,085:INFO:Declaring metric variables
2025-01-17 21:14:09,088:INFO:Importing untrained model
2025-01-17 21:14:09,093:INFO:K Neighbors Classifier Imported successfully
2025-01-17 21:14:09,098:INFO:Starting cross validation
2025-01-17 21:14:09,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:10,690:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:10,703:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:10,703:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:10,717:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:10,729:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:10,744:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:10,752:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:10,781:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:11,461:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:11,463:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:11,483:INFO:Calculating mean and std
2025-01-17 21:14:11,484:INFO:Creating metrics dataframe
2025-01-17 21:14:11,485:INFO:Uploading results into container
2025-01-17 21:14:11,486:INFO:Uploading model into container now
2025-01-17 21:14:11,486:INFO:_master_model_container: 2
2025-01-17 21:14:11,486:INFO:_display_container: 2
2025-01-17 21:14:11,487:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-01-17 21:14:11,487:INFO:create_model() successfully completed......................................
2025-01-17 21:14:11,545:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:11,545:INFO:Creating metrics dataframe
2025-01-17 21:14:11,550:INFO:Initializing Naive Bayes
2025-01-17 21:14:11,550:INFO:Total runtime is 0.24436488151550292 minutes
2025-01-17 21:14:11,552:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:11,553:INFO:Initializing create_model()
2025-01-17 21:14:11,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:11,553:INFO:Checking exceptions
2025-01-17 21:14:11,553:INFO:Importing libraries
2025-01-17 21:14:11,553:INFO:Copying training dataset
2025-01-17 21:14:11,569:INFO:Defining folds
2025-01-17 21:14:11,569:INFO:Declaring metric variables
2025-01-17 21:14:11,571:INFO:Importing untrained model
2025-01-17 21:14:11,573:INFO:Naive Bayes Imported successfully
2025-01-17 21:14:11,578:INFO:Starting cross validation
2025-01-17 21:14:11,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:11,968:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:11,972:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,041:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,088:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,096:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,119:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,139:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,153:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,381:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,387:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:12,405:INFO:Calculating mean and std
2025-01-17 21:14:12,406:INFO:Creating metrics dataframe
2025-01-17 21:14:12,407:INFO:Uploading results into container
2025-01-17 21:14:12,408:INFO:Uploading model into container now
2025-01-17 21:14:12,408:INFO:_master_model_container: 3
2025-01-17 21:14:12,408:INFO:_display_container: 2
2025-01-17 21:14:12,408:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-01-17 21:14:12,408:INFO:create_model() successfully completed......................................
2025-01-17 21:14:12,465:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:12,465:INFO:Creating metrics dataframe
2025-01-17 21:14:12,470:INFO:Initializing Decision Tree Classifier
2025-01-17 21:14:12,470:INFO:Total runtime is 0.25969956715901693 minutes
2025-01-17 21:14:12,472:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:12,473:INFO:Initializing create_model()
2025-01-17 21:14:12,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:12,473:INFO:Checking exceptions
2025-01-17 21:14:12,473:INFO:Importing libraries
2025-01-17 21:14:12,473:INFO:Copying training dataset
2025-01-17 21:14:12,488:INFO:Defining folds
2025-01-17 21:14:12,488:INFO:Declaring metric variables
2025-01-17 21:14:12,490:INFO:Importing untrained model
2025-01-17 21:14:12,492:INFO:Decision Tree Classifier Imported successfully
2025-01-17 21:14:12,497:INFO:Starting cross validation
2025-01-17 21:14:12,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:13,112:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,129:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,132:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,148:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,190:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,193:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,196:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,204:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,543:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,553:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:13,565:INFO:Calculating mean and std
2025-01-17 21:14:13,566:INFO:Creating metrics dataframe
2025-01-17 21:14:13,567:INFO:Uploading results into container
2025-01-17 21:14:13,567:INFO:Uploading model into container now
2025-01-17 21:14:13,568:INFO:_master_model_container: 4
2025-01-17 21:14:13,568:INFO:_display_container: 2
2025-01-17 21:14:13,568:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-01-17 21:14:13,568:INFO:create_model() successfully completed......................................
2025-01-17 21:14:13,624:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:13,624:INFO:Creating metrics dataframe
2025-01-17 21:14:13,630:INFO:Initializing SVM - Linear Kernel
2025-01-17 21:14:13,630:INFO:Total runtime is 0.2790226976076762 minutes
2025-01-17 21:14:13,632:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:13,632:INFO:Initializing create_model()
2025-01-17 21:14:13,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:13,632:INFO:Checking exceptions
2025-01-17 21:14:13,632:INFO:Importing libraries
2025-01-17 21:14:13,632:INFO:Copying training dataset
2025-01-17 21:14:13,646:INFO:Defining folds
2025-01-17 21:14:13,646:INFO:Declaring metric variables
2025-01-17 21:14:13,649:INFO:Importing untrained model
2025-01-17 21:14:13,652:INFO:SVM - Linear Kernel Imported successfully
2025-01-17 21:14:13,657:INFO:Starting cross validation
2025-01-17 21:14:13,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:15,565:INFO:Calculating mean and std
2025-01-17 21:14:15,565:INFO:Creating metrics dataframe
2025-01-17 21:14:15,567:INFO:Uploading results into container
2025-01-17 21:14:15,567:INFO:Uploading model into container now
2025-01-17 21:14:15,567:INFO:_master_model_container: 5
2025-01-17 21:14:15,567:INFO:_display_container: 2
2025-01-17 21:14:15,568:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-01-17 21:14:15,568:INFO:create_model() successfully completed......................................
2025-01-17 21:14:15,625:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:15,625:INFO:Creating metrics dataframe
2025-01-17 21:14:15,631:INFO:Initializing Ridge Classifier
2025-01-17 21:14:15,631:INFO:Total runtime is 0.3123700976371765 minutes
2025-01-17 21:14:15,633:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:15,633:INFO:Initializing create_model()
2025-01-17 21:14:15,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:15,633:INFO:Checking exceptions
2025-01-17 21:14:15,633:INFO:Importing libraries
2025-01-17 21:14:15,633:INFO:Copying training dataset
2025-01-17 21:14:15,648:INFO:Defining folds
2025-01-17 21:14:15,648:INFO:Declaring metric variables
2025-01-17 21:14:15,650:INFO:Importing untrained model
2025-01-17 21:14:15,653:INFO:Ridge Classifier Imported successfully
2025-01-17 21:14:15,659:INFO:Starting cross validation
2025-01-17 21:14:15,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:16,414:INFO:Calculating mean and std
2025-01-17 21:14:16,415:INFO:Creating metrics dataframe
2025-01-17 21:14:16,416:INFO:Uploading results into container
2025-01-17 21:14:16,416:INFO:Uploading model into container now
2025-01-17 21:14:16,417:INFO:_master_model_container: 6
2025-01-17 21:14:16,417:INFO:_display_container: 2
2025-01-17 21:14:16,417:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-01-17 21:14:16,417:INFO:create_model() successfully completed......................................
2025-01-17 21:14:16,477:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:16,477:INFO:Creating metrics dataframe
2025-01-17 21:14:16,483:INFO:Initializing Random Forest Classifier
2025-01-17 21:14:16,483:INFO:Total runtime is 0.32657391627629595 minutes
2025-01-17 21:14:16,485:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:16,485:INFO:Initializing create_model()
2025-01-17 21:14:16,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:16,485:INFO:Checking exceptions
2025-01-17 21:14:16,485:INFO:Importing libraries
2025-01-17 21:14:16,486:INFO:Copying training dataset
2025-01-17 21:14:16,499:INFO:Defining folds
2025-01-17 21:14:16,499:INFO:Declaring metric variables
2025-01-17 21:14:16,502:INFO:Importing untrained model
2025-01-17 21:14:16,504:INFO:Random Forest Classifier Imported successfully
2025-01-17 21:14:16,509:INFO:Starting cross validation
2025-01-17 21:14:16,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:21,300:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:21,454:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:21,511:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:21,513:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:21,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:21,525:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:21,664:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:21,664:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:22,918:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:22,936:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:22,958:INFO:Calculating mean and std
2025-01-17 21:14:22,959:INFO:Creating metrics dataframe
2025-01-17 21:14:22,961:INFO:Uploading results into container
2025-01-17 21:14:22,962:INFO:Uploading model into container now
2025-01-17 21:14:22,962:INFO:_master_model_container: 7
2025-01-17 21:14:22,962:INFO:_display_container: 2
2025-01-17 21:14:22,963:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-01-17 21:14:22,963:INFO:create_model() successfully completed......................................
2025-01-17 21:14:23,038:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:23,038:INFO:Creating metrics dataframe
2025-01-17 21:14:23,044:INFO:Initializing Quadratic Discriminant Analysis
2025-01-17 21:14:23,044:INFO:Total runtime is 0.43593246539433794 minutes
2025-01-17 21:14:23,047:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:23,047:INFO:Initializing create_model()
2025-01-17 21:14:23,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:23,047:INFO:Checking exceptions
2025-01-17 21:14:23,047:INFO:Importing libraries
2025-01-17 21:14:23,047:INFO:Copying training dataset
2025-01-17 21:14:23,065:INFO:Defining folds
2025-01-17 21:14:23,065:INFO:Declaring metric variables
2025-01-17 21:14:23,068:INFO:Importing untrained model
2025-01-17 21:14:23,072:INFO:Quadratic Discriminant Analysis Imported successfully
2025-01-17 21:14:23,078:INFO:Starting cross validation
2025-01-17 21:14:23,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:23,432:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,481:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,559:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,580:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,614:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,618:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,618:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,619:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,626:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,626:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,627:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,634:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,635:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,639:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,643:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,644:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,645:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,655:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,665:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,665:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,666:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,667:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,673:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,674:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,675:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,676:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,679:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,682:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,682:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,683:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,687:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,698:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,698:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,706:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,706:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,707:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,711:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,712:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,712:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,713:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,717:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,717:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,718:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,719:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,719:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,720:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,721:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,724:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,724:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,725:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,728:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,737:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,737:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,738:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,742:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,742:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,743:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,746:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,940:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,947:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:14:23,972:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,972:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,972:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,974:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,974:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,975:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,975:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,978:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,978:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,979:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,981:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,981:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:14:23,981:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:14:23,982:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:14:23,999:INFO:Calculating mean and std
2025-01-17 21:14:24,001:INFO:Creating metrics dataframe
2025-01-17 21:14:24,003:INFO:Uploading results into container
2025-01-17 21:14:24,003:INFO:Uploading model into container now
2025-01-17 21:14:24,003:INFO:_master_model_container: 8
2025-01-17 21:14:24,003:INFO:_display_container: 2
2025-01-17 21:14:24,004:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-01-17 21:14:24,004:INFO:create_model() successfully completed......................................
2025-01-17 21:14:24,073:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:24,073:INFO:Creating metrics dataframe
2025-01-17 21:14:24,080:INFO:Initializing Ada Boost Classifier
2025-01-17 21:14:24,080:INFO:Total runtime is 0.45319010019302364 minutes
2025-01-17 21:14:24,082:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:24,082:INFO:Initializing create_model()
2025-01-17 21:14:24,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:24,082:INFO:Checking exceptions
2025-01-17 21:14:24,082:INFO:Importing libraries
2025-01-17 21:14:24,083:INFO:Copying training dataset
2025-01-17 21:14:24,101:INFO:Defining folds
2025-01-17 21:14:24,101:INFO:Declaring metric variables
2025-01-17 21:14:24,104:INFO:Importing untrained model
2025-01-17 21:14:24,106:INFO:Ada Boost Classifier Imported successfully
2025-01-17 21:14:24,111:INFO:Starting cross validation
2025-01-17 21:14:24,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:24,391:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:24,423:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:24,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:24,440:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:24,446:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:24,452:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:24,496:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:24,533:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:27,205:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:27,225:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:14:28,636:INFO:Calculating mean and std
2025-01-17 21:14:28,637:INFO:Creating metrics dataframe
2025-01-17 21:14:28,638:INFO:Uploading results into container
2025-01-17 21:14:28,639:INFO:Uploading model into container now
2025-01-17 21:14:28,639:INFO:_master_model_container: 9
2025-01-17 21:14:28,639:INFO:_display_container: 2
2025-01-17 21:14:28,640:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-01-17 21:14:28,640:INFO:create_model() successfully completed......................................
2025-01-17 21:14:28,704:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:28,705:INFO:Creating metrics dataframe
2025-01-17 21:14:28,711:INFO:Initializing Gradient Boosting Classifier
2025-01-17 21:14:28,712:INFO:Total runtime is 0.5303844650586446 minutes
2025-01-17 21:14:28,714:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:28,714:INFO:Initializing create_model()
2025-01-17 21:14:28,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:28,715:INFO:Checking exceptions
2025-01-17 21:14:28,715:INFO:Importing libraries
2025-01-17 21:14:28,715:INFO:Copying training dataset
2025-01-17 21:14:28,731:INFO:Defining folds
2025-01-17 21:14:28,731:INFO:Declaring metric variables
2025-01-17 21:14:28,734:INFO:Importing untrained model
2025-01-17 21:14:28,737:INFO:Gradient Boosting Classifier Imported successfully
2025-01-17 21:14:28,743:INFO:Starting cross validation
2025-01-17 21:14:28,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:43,864:INFO:Calculating mean and std
2025-01-17 21:14:43,866:INFO:Creating metrics dataframe
2025-01-17 21:14:43,868:INFO:Uploading results into container
2025-01-17 21:14:43,869:INFO:Uploading model into container now
2025-01-17 21:14:43,869:INFO:_master_model_container: 10
2025-01-17 21:14:43,869:INFO:_display_container: 2
2025-01-17 21:14:43,870:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-01-17 21:14:43,870:INFO:create_model() successfully completed......................................
2025-01-17 21:14:43,939:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:43,940:INFO:Creating metrics dataframe
2025-01-17 21:14:43,946:INFO:Initializing Linear Discriminant Analysis
2025-01-17 21:14:43,946:INFO:Total runtime is 0.7842954834302266 minutes
2025-01-17 21:14:43,948:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:43,949:INFO:Initializing create_model()
2025-01-17 21:14:43,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:43,949:INFO:Checking exceptions
2025-01-17 21:14:43,949:INFO:Importing libraries
2025-01-17 21:14:43,949:INFO:Copying training dataset
2025-01-17 21:14:43,991:INFO:Defining folds
2025-01-17 21:14:43,991:INFO:Declaring metric variables
2025-01-17 21:14:44,001:INFO:Importing untrained model
2025-01-17 21:14:44,003:INFO:Linear Discriminant Analysis Imported successfully
2025-01-17 21:14:44,007:INFO:Starting cross validation
2025-01-17 21:14:44,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:44,912:INFO:Calculating mean and std
2025-01-17 21:14:44,914:INFO:Creating metrics dataframe
2025-01-17 21:14:44,915:INFO:Uploading results into container
2025-01-17 21:14:44,916:INFO:Uploading model into container now
2025-01-17 21:14:44,916:INFO:_master_model_container: 11
2025-01-17 21:14:44,917:INFO:_display_container: 2
2025-01-17 21:14:44,917:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-01-17 21:14:44,917:INFO:create_model() successfully completed......................................
2025-01-17 21:14:44,985:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:44,986:INFO:Creating metrics dataframe
2025-01-17 21:14:44,992:INFO:Initializing Extra Trees Classifier
2025-01-17 21:14:44,993:INFO:Total runtime is 0.8017356475194295 minutes
2025-01-17 21:14:44,995:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:44,995:INFO:Initializing create_model()
2025-01-17 21:14:44,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:44,995:INFO:Checking exceptions
2025-01-17 21:14:44,995:INFO:Importing libraries
2025-01-17 21:14:44,995:INFO:Copying training dataset
2025-01-17 21:14:45,011:INFO:Defining folds
2025-01-17 21:14:45,011:INFO:Declaring metric variables
2025-01-17 21:14:45,013:INFO:Importing untrained model
2025-01-17 21:14:45,016:INFO:Extra Trees Classifier Imported successfully
2025-01-17 21:14:45,021:INFO:Starting cross validation
2025-01-17 21:14:45,022:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:49,179:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:49,214:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:49,227:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:49,237:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:49,241:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:49,322:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:49,354:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:49,424:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:50,394:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:50,426:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:50,445:INFO:Calculating mean and std
2025-01-17 21:14:50,446:INFO:Creating metrics dataframe
2025-01-17 21:14:50,456:INFO:Uploading results into container
2025-01-17 21:14:50,457:INFO:Uploading model into container now
2025-01-17 21:14:50,458:INFO:_master_model_container: 12
2025-01-17 21:14:50,458:INFO:_display_container: 2
2025-01-17 21:14:50,459:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-01-17 21:14:50,459:INFO:create_model() successfully completed......................................
2025-01-17 21:14:50,577:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:50,577:INFO:Creating metrics dataframe
2025-01-17 21:14:50,585:INFO:Initializing Extreme Gradient Boosting
2025-01-17 21:14:50,585:INFO:Total runtime is 0.8949367483456929 minutes
2025-01-17 21:14:50,587:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:50,587:INFO:Initializing create_model()
2025-01-17 21:14:50,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:50,587:INFO:Checking exceptions
2025-01-17 21:14:50,587:INFO:Importing libraries
2025-01-17 21:14:50,588:INFO:Copying training dataset
2025-01-17 21:14:50,604:INFO:Defining folds
2025-01-17 21:14:50,604:INFO:Declaring metric variables
2025-01-17 21:14:50,607:INFO:Importing untrained model
2025-01-17 21:14:50,611:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:14:50,618:INFO:Starting cross validation
2025-01-17 21:14:50,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:51,850:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:51,852:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:51,862:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:51,869:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:51,873:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:51,905:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:51,910:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:51,957:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:52,418:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:52,419:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:52,439:INFO:Calculating mean and std
2025-01-17 21:14:52,439:INFO:Creating metrics dataframe
2025-01-17 21:14:52,441:INFO:Uploading results into container
2025-01-17 21:14:52,441:INFO:Uploading model into container now
2025-01-17 21:14:52,442:INFO:_master_model_container: 13
2025-01-17 21:14:52,442:INFO:_display_container: 2
2025-01-17 21:14:52,442:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:14:52,442:INFO:create_model() successfully completed......................................
2025-01-17 21:14:52,501:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:52,501:INFO:Creating metrics dataframe
2025-01-17 21:14:52,509:INFO:Initializing Light Gradient Boosting Machine
2025-01-17 21:14:52,509:INFO:Total runtime is 0.9270025491714478 minutes
2025-01-17 21:14:52,511:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:52,511:INFO:Initializing create_model()
2025-01-17 21:14:52,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:52,511:INFO:Checking exceptions
2025-01-17 21:14:52,511:INFO:Importing libraries
2025-01-17 21:14:52,511:INFO:Copying training dataset
2025-01-17 21:14:52,525:INFO:Defining folds
2025-01-17 21:14:52,525:INFO:Declaring metric variables
2025-01-17 21:14:52,528:INFO:Importing untrained model
2025-01-17 21:14:52,530:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-17 21:14:52,535:INFO:Starting cross validation
2025-01-17 21:14:52,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:55,915:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:55,924:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:55,937:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:55,948:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:55,954:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:56,020:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:56,193:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:56,253:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,215:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,224:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,245:INFO:Calculating mean and std
2025-01-17 21:14:57,246:INFO:Creating metrics dataframe
2025-01-17 21:14:57,248:INFO:Uploading results into container
2025-01-17 21:14:57,248:INFO:Uploading model into container now
2025-01-17 21:14:57,248:INFO:_master_model_container: 14
2025-01-17 21:14:57,248:INFO:_display_container: 2
2025-01-17 21:14:57,249:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-01-17 21:14:57,249:INFO:create_model() successfully completed......................................
2025-01-17 21:14:57,316:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:57,316:INFO:Creating metrics dataframe
2025-01-17 21:14:57,324:INFO:Initializing Dummy Classifier
2025-01-17 21:14:57,324:INFO:Total runtime is 1.0072628458340962 minutes
2025-01-17 21:14:57,326:INFO:SubProcess create_model() called ==================================
2025-01-17 21:14:57,327:INFO:Initializing create_model()
2025-01-17 21:14:57,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x164c551e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:57,327:INFO:Checking exceptions
2025-01-17 21:14:57,328:INFO:Importing libraries
2025-01-17 21:14:57,328:INFO:Copying training dataset
2025-01-17 21:14:57,342:INFO:Defining folds
2025-01-17 21:14:57,342:INFO:Declaring metric variables
2025-01-17 21:14:57,345:INFO:Importing untrained model
2025-01-17 21:14:57,351:INFO:Dummy Classifier Imported successfully
2025-01-17 21:14:57,361:INFO:Starting cross validation
2025-01-17 21:14:57,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:14:57,868:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,881:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:57,888:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,899:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:57,899:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,910:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:57,918:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,921:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,928:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:57,930:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:57,955:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,959:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,960:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:57,964:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:57,967:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:57,968:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:58,180:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:58,184:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:58,188:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:14:58,192:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:14:58,201:INFO:Calculating mean and std
2025-01-17 21:14:58,201:INFO:Creating metrics dataframe
2025-01-17 21:14:58,203:INFO:Uploading results into container
2025-01-17 21:14:58,203:INFO:Uploading model into container now
2025-01-17 21:14:58,203:INFO:_master_model_container: 15
2025-01-17 21:14:58,204:INFO:_display_container: 2
2025-01-17 21:14:58,204:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-01-17 21:14:58,204:INFO:create_model() successfully completed......................................
2025-01-17 21:14:58,260:INFO:SubProcess create_model() end ==================================
2025-01-17 21:14:58,260:INFO:Creating metrics dataframe
2025-01-17 21:14:58,268:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-17 21:14:58,274:INFO:Initializing create_model()
2025-01-17 21:14:58,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:14:58,274:INFO:Checking exceptions
2025-01-17 21:14:58,275:INFO:Importing libraries
2025-01-17 21:14:58,275:INFO:Copying training dataset
2025-01-17 21:14:58,320:INFO:Defining folds
2025-01-17 21:14:58,320:INFO:Declaring metric variables
2025-01-17 21:14:58,321:INFO:Importing untrained model
2025-01-17 21:14:58,321:INFO:Declaring custom model
2025-01-17 21:14:58,322:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:14:58,323:INFO:Cross validation set to False
2025-01-17 21:14:58,323:INFO:Fitting Model
2025-01-17 21:14:58,732:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:14:58,732:INFO:create_model() successfully completed......................................
2025-01-17 21:14:58,808:INFO:_master_model_container: 15
2025-01-17 21:14:58,808:INFO:_display_container: 2
2025-01-17 21:14:58,808:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:14:58,809:INFO:compare_models() successfully completed......................................
2025-01-17 21:15:29,086:INFO:Initializing finalize_model()
2025-01-17 21:15:29,087:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-01-17 21:15:29,088:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:15:29,144:INFO:Initializing create_model()
2025-01-17 21:15:29,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:15:29,144:INFO:Checking exceptions
2025-01-17 21:15:29,148:INFO:Importing libraries
2025-01-17 21:15:29,148:INFO:Copying training dataset
2025-01-17 21:15:29,149:INFO:Defining folds
2025-01-17 21:15:29,149:INFO:Declaring metric variables
2025-01-17 21:15:29,149:INFO:Importing untrained model
2025-01-17 21:15:29,149:INFO:Declaring custom model
2025-01-17 21:15:29,150:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:15:29,152:INFO:Cross validation set to False
2025-01-17 21:15:29,152:INFO:Fitting Model
2025-01-17 21:15:29,682:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:15:29,682:INFO:create_model() successfully completed......................................
2025-01-17 21:15:29,785:INFO:_master_model_container: 15
2025-01-17 21:15:29,785:INFO:_display_container: 2
2025-01-17 21:15:29,801:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:15:29,801:INFO:finalize_model() successfully completed......................................
2025-01-17 21:16:13,283:INFO:Initializing save_model()
2025-01-17 21:16:13,284:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=pycaret_best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-01-17 21:16:13,284:INFO:Adding model into prep_pipe
2025-01-17 21:16:13,284:WARNING:Only Model saved as it was a pipeline.
2025-01-17 21:16:13,297:INFO:pycaret_best_model.pkl saved in current working directory
2025-01-17 21:16:13,314:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:16:13,314:INFO:save_model() successfully completed......................................
2025-01-17 21:19:50,000:INFO:Initializing plot_model()
2025-01-17 21:19:50,002:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, system=True)
2025-01-17 21:19:50,003:INFO:Checking exceptions
2025-01-17 21:19:50,029:INFO:Preloading libraries
2025-01-17 21:19:50,032:INFO:Copying training dataset
2025-01-17 21:19:50,032:INFO:Plot type: auc
2025-01-17 21:19:50,286:INFO:Fitting Model
2025-01-17 21:19:50,288:INFO:Scoring test/hold-out set
2025-01-17 21:19:50,431:INFO:Visual Rendered Successfully
2025-01-17 21:19:50,527:INFO:plot_model() successfully completed......................................
2025-01-17 21:19:50,527:INFO:Initializing plot_model()
2025-01-17 21:19:50,527:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, system=True)
2025-01-17 21:19:50,528:INFO:Checking exceptions
2025-01-17 21:19:50,536:INFO:Preloading libraries
2025-01-17 21:19:50,538:INFO:Copying training dataset
2025-01-17 21:19:50,538:INFO:Plot type: confusion_matrix
2025-01-17 21:19:50,769:INFO:Fitting Model
2025-01-17 21:19:50,769:INFO:Scoring test/hold-out set
2025-01-17 21:19:50,851:INFO:Visual Rendered Successfully
2025-01-17 21:19:50,919:INFO:plot_model() successfully completed......................................
2025-01-17 21:19:50,920:INFO:Initializing plot_model()
2025-01-17 21:19:50,920:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, system=True)
2025-01-17 21:19:50,920:INFO:Checking exceptions
2025-01-17 21:19:50,926:INFO:Preloading libraries
2025-01-17 21:19:50,928:INFO:Copying training dataset
2025-01-17 21:19:50,928:INFO:Plot type: feature
2025-01-17 21:19:50,929:WARNING:No coef_ found. Trying feature_importances_
2025-01-17 21:19:51,056:INFO:Visual Rendered Successfully
2025-01-17 21:19:51,125:INFO:plot_model() successfully completed......................................
2025-01-17 21:19:51,126:INFO:Initializing plot_model()
2025-01-17 21:19:51,126:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>, system=True)
2025-01-17 21:19:51,126:INFO:Checking exceptions
2025-01-17 21:19:51,134:INFO:Preloading libraries
2025-01-17 21:19:51,137:INFO:Copying training dataset
2025-01-17 21:19:51,137:INFO:Plot type: learning
2025-01-17 21:19:51,366:INFO:Fitting Model
2025-01-17 21:20:00,377:INFO:Visual Rendered Successfully
2025-01-17 21:20:00,494:INFO:plot_model() successfully completed......................................
2025-01-17 21:20:18,776:INFO:Initializing interpret_model()
2025-01-17 21:20:18,777:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>)
2025-01-17 21:20:18,777:INFO:Checking exceptions
2025-01-17 21:20:18,778:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-01-17 21:21:09,845:INFO:Initializing interpret_model()
2025-01-17 21:21:09,847:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x163c24610>)
2025-01-17 21:21:09,847:INFO:Checking exceptions
2025-01-17 21:21:09,848:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-01-17 21:21:26,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 21:21:26,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 21:21:26,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 21:21:26,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 21:21:26,685:INFO:PyCaret ClassificationExperiment
2025-01-17 21:21:26,685:INFO:Logging name: clf-default-name
2025-01-17 21:21:26,685:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-01-17 21:21:26,685:INFO:version 3.3.1
2025-01-17 21:21:26,685:INFO:Initializing setup()
2025-01-17 21:21:26,685:INFO:self.USI: a8ef
2025-01-17 21:21:26,685:INFO:self._variable_keys: {'exp_name_log', 'html_param', 'y_test', '_available_plots', 'pipeline', 'idx', 'X', 'X_test', 'is_multiclass', 'y', 'gpu_n_jobs_param', 'fold_groups_param', 'log_plots_param', 'fold_generator', 'memory', 'gpu_param', 'data', 'n_jobs_param', 'exp_id', 'logging_param', 'fix_imbalance', 'fold_shuffle_param', 'y_train', 'USI', '_ml_usecase', 'target_param', 'X_train', 'seed'}
2025-01-17 21:21:26,685:INFO:Checking environment
2025-01-17 21:21:26,686:INFO:python_version: 3.10.13
2025-01-17 21:21:26,686:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-17 21:21:26,686:INFO:machine: arm64
2025-01-17 21:21:26,686:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-17 21:21:26,686:INFO:Memory: svmem(total=8589934592, available=2647212032, percent=69.2, used=3273621504, free=801275904, active=1846820864, inactive=1761804288, wired=1426800640)
2025-01-17 21:21:26,686:INFO:Physical Core: 8
2025-01-17 21:21:26,686:INFO:Logical Core: 8
2025-01-17 21:21:26,686:INFO:Checking libraries
2025-01-17 21:21:26,686:INFO:System:
2025-01-17 21:21:26,686:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-17 21:21:26,687:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-17 21:21:26,687:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-17 21:21:26,687:INFO:PyCaret required dependencies:
2025-01-17 21:21:26,715:INFO:                 pip: 24.2
2025-01-17 21:21:26,715:INFO:          setuptools: 75.1.0
2025-01-17 21:21:26,715:INFO:             pycaret: 3.3.1
2025-01-17 21:21:26,715:INFO:             IPython: 8.27.0
2025-01-17 21:21:26,715:INFO:          ipywidgets: 8.1.2
2025-01-17 21:21:26,715:INFO:                tqdm: 4.66.5
2025-01-17 21:21:26,715:INFO:               numpy: 1.26.4
2025-01-17 21:21:26,715:INFO:              pandas: 2.1.4
2025-01-17 21:21:26,715:INFO:              jinja2: 3.1.4
2025-01-17 21:21:26,715:INFO:               scipy: 1.11.4
2025-01-17 21:21:26,715:INFO:              joblib: 1.3.2
2025-01-17 21:21:26,715:INFO:             sklearn: 1.4.2
2025-01-17 21:21:26,715:INFO:                pyod: 2.0.2
2025-01-17 21:21:26,715:INFO:            imblearn: 0.13.0
2025-01-17 21:21:26,715:INFO:   category_encoders: 2.7.0
2025-01-17 21:21:26,715:INFO:            lightgbm: 4.4.0
2025-01-17 21:21:26,715:INFO:               numba: 0.60.0
2025-01-17 21:21:26,715:INFO:            requests: 2.32.3
2025-01-17 21:21:26,715:INFO:          matplotlib: 3.9.2
2025-01-17 21:21:26,715:INFO:          scikitplot: 0.3.7
2025-01-17 21:21:26,716:INFO:         yellowbrick: 1.5
2025-01-17 21:21:26,716:INFO:              plotly: 5.24.1
2025-01-17 21:21:26,716:INFO:    plotly-resampler: Not installed
2025-01-17 21:21:26,716:INFO:             kaleido: 0.2.1
2025-01-17 21:21:26,716:INFO:           schemdraw: 0.15
2025-01-17 21:21:26,716:INFO:         statsmodels: 0.14.4
2025-01-17 21:21:26,716:INFO:              sktime: 0.26.0
2025-01-17 21:21:26,716:INFO:               tbats: 1.1.3
2025-01-17 21:21:26,716:INFO:            pmdarima: 2.0.4
2025-01-17 21:21:26,716:INFO:              psutil: 5.9.0
2025-01-17 21:21:26,716:INFO:          markupsafe: 2.1.3
2025-01-17 21:21:26,716:INFO:             pickle5: Not installed
2025-01-17 21:21:26,716:INFO:         cloudpickle: 3.1.0
2025-01-17 21:21:26,716:INFO:         deprecation: 2.1.0
2025-01-17 21:21:26,716:INFO:              xxhash: 3.5.0
2025-01-17 21:21:26,716:INFO:           wurlitzer: 3.1.1
2025-01-17 21:21:26,716:INFO:PyCaret optional dependencies:
2025-01-17 21:21:26,791:INFO:                shap: 0.46.0
2025-01-17 21:21:26,791:INFO:           interpret: Not installed
2025-01-17 21:21:26,791:INFO:                umap: 0.5.7
2025-01-17 21:21:26,791:INFO:     ydata_profiling: Not installed
2025-01-17 21:21:26,791:INFO:  explainerdashboard: Not installed
2025-01-17 21:21:26,791:INFO:             autoviz: Not installed
2025-01-17 21:21:26,791:INFO:           fairlearn: Not installed
2025-01-17 21:21:26,791:INFO:          deepchecks: Not installed
2025-01-17 21:21:26,791:INFO:             xgboost: 2.1.3
2025-01-17 21:21:26,791:INFO:            catboost: Not installed
2025-01-17 21:21:26,791:INFO:              kmodes: Not installed
2025-01-17 21:21:26,791:INFO:             mlxtend: Not installed
2025-01-17 21:21:26,791:INFO:       statsforecast: Not installed
2025-01-17 21:21:26,791:INFO:        tune_sklearn: Not installed
2025-01-17 21:21:26,791:INFO:                 ray: Not installed
2025-01-17 21:21:26,792:INFO:            hyperopt: Not installed
2025-01-17 21:21:26,792:INFO:              optuna: Not installed
2025-01-17 21:21:26,792:INFO:               skopt: Not installed
2025-01-17 21:21:26,792:INFO:              mlflow: Not installed
2025-01-17 21:21:26,792:INFO:              gradio: Not installed
2025-01-17 21:21:26,792:INFO:             fastapi: Not installed
2025-01-17 21:21:26,792:INFO:             uvicorn: Not installed
2025-01-17 21:21:26,792:INFO:              m2cgen: Not installed
2025-01-17 21:21:26,792:INFO:           evidently: Not installed
2025-01-17 21:21:26,792:INFO:               fugue: Not installed
2025-01-17 21:21:26,792:INFO:           streamlit: Not installed
2025-01-17 21:21:26,792:INFO:             prophet: Not installed
2025-01-17 21:21:26,792:INFO:None
2025-01-17 21:21:26,792:INFO:Set up data.
2025-01-17 21:21:26,820:INFO:Set up folding strategy.
2025-01-17 21:21:26,820:INFO:Set up train/test split.
2025-01-17 21:21:26,842:INFO:Set up index.
2025-01-17 21:21:26,842:INFO:Assigning column types.
2025-01-17 21:21:26,849:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-17 21:21:26,881:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 21:21:26,883:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:21:26,907:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:21:26,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:21:26,944:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 21:21:26,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:21:26,964:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:21:26,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:21:26,966:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-17 21:21:26,997:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:21:27,017:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:21:27,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:21:27,051:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:21:27,070:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:21:27,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:21:27,072:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-01-17 21:21:27,123:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:21:27,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:21:27,176:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:21:27,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:21:27,180:INFO:Preparing preprocessing pipeline...
2025-01-17 21:21:27,182:INFO:Set up simple imputation.
2025-01-17 21:21:27,190:INFO:Set up encoding of ordinal features.
2025-01-17 21:21:27,194:INFO:Set up encoding of categorical features.
2025-01-17 21:21:27,389:INFO:Finished creating preprocessing pipeline.
2025-01-17 21:21:27,405:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-01-17 21:21:27,405:INFO:Creating final display dataframe.
2025-01-17 21:21:27,622:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       loan_status
2                   Target type            Binary
3           Original data shape       (45000, 14)
4        Transformed data shape       (45000, 26)
5   Transformed train set shape       (31499, 26)
6    Transformed test set shape       (13501, 26)
7              Numeric features                 8
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              a8ef
2025-01-17 21:21:27,680:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:21:27,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:21:27,737:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:21:27,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:21:27,739:INFO:setup() successfully completed in 1.06s...............
2025-01-17 21:21:27,744:INFO:Initializing compare_models()
2025-01-17 21:21:27,744:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-01-17 21:21:27,744:INFO:Checking exceptions
2025-01-17 21:21:27,755:INFO:Preparing display monitor
2025-01-17 21:21:27,790:INFO:Initializing Logistic Regression
2025-01-17 21:21:27,790:INFO:Total runtime is 4.351139068603516e-06 minutes
2025-01-17 21:21:27,793:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:27,794:INFO:Initializing create_model()
2025-01-17 21:21:27,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:27,795:INFO:Checking exceptions
2025-01-17 21:21:27,795:INFO:Importing libraries
2025-01-17 21:21:27,795:INFO:Copying training dataset
2025-01-17 21:21:27,816:INFO:Defining folds
2025-01-17 21:21:27,816:INFO:Declaring metric variables
2025-01-17 21:21:27,818:INFO:Importing untrained model
2025-01-17 21:21:27,821:INFO:Logistic Regression Imported successfully
2025-01-17 21:21:27,827:INFO:Starting cross validation
2025-01-17 21:21:27,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:36,598:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:36,630:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:36,638:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:36,640:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:36,729:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:36,797:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:36,829:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:36,927:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:38,980:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:39,004:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:21:39,046:INFO:Calculating mean and std
2025-01-17 21:21:39,049:INFO:Creating metrics dataframe
2025-01-17 21:21:39,052:INFO:Uploading results into container
2025-01-17 21:21:39,053:INFO:Uploading model into container now
2025-01-17 21:21:39,054:INFO:_master_model_container: 1
2025-01-17 21:21:39,054:INFO:_display_container: 2
2025-01-17 21:21:39,057:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 21:21:39,057:INFO:create_model() successfully completed......................................
2025-01-17 21:21:39,137:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:39,137:INFO:Creating metrics dataframe
2025-01-17 21:21:39,142:INFO:Initializing K Neighbors Classifier
2025-01-17 21:21:39,142:INFO:Total runtime is 0.18920069932937622 minutes
2025-01-17 21:21:39,144:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:39,144:INFO:Initializing create_model()
2025-01-17 21:21:39,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:39,145:INFO:Checking exceptions
2025-01-17 21:21:39,145:INFO:Importing libraries
2025-01-17 21:21:39,145:INFO:Copying training dataset
2025-01-17 21:21:39,164:INFO:Defining folds
2025-01-17 21:21:39,164:INFO:Declaring metric variables
2025-01-17 21:21:39,168:INFO:Importing untrained model
2025-01-17 21:21:39,172:INFO:K Neighbors Classifier Imported successfully
2025-01-17 21:21:39,178:INFO:Starting cross validation
2025-01-17 21:21:39,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:40,839:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:40,855:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:40,875:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:40,883:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:40,897:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:40,905:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:40,944:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:40,945:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:41,753:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:41,753:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:41,774:INFO:Calculating mean and std
2025-01-17 21:21:41,775:INFO:Creating metrics dataframe
2025-01-17 21:21:41,777:INFO:Uploading results into container
2025-01-17 21:21:41,777:INFO:Uploading model into container now
2025-01-17 21:21:41,778:INFO:_master_model_container: 2
2025-01-17 21:21:41,778:INFO:_display_container: 2
2025-01-17 21:21:41,778:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-01-17 21:21:41,778:INFO:create_model() successfully completed......................................
2025-01-17 21:21:41,848:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:41,848:INFO:Creating metrics dataframe
2025-01-17 21:21:41,853:INFO:Initializing Naive Bayes
2025-01-17 21:21:41,854:INFO:Total runtime is 0.23439423640569051 minutes
2025-01-17 21:21:41,856:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:41,856:INFO:Initializing create_model()
2025-01-17 21:21:41,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:41,856:INFO:Checking exceptions
2025-01-17 21:21:41,856:INFO:Importing libraries
2025-01-17 21:21:41,856:INFO:Copying training dataset
2025-01-17 21:21:41,871:INFO:Defining folds
2025-01-17 21:21:41,871:INFO:Declaring metric variables
2025-01-17 21:21:41,874:INFO:Importing untrained model
2025-01-17 21:21:41,877:INFO:Naive Bayes Imported successfully
2025-01-17 21:21:41,883:INFO:Starting cross validation
2025-01-17 21:21:41,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:42,350:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,356:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,440:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,447:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,450:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,468:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,491:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,521:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,721:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,731:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:42,743:INFO:Calculating mean and std
2025-01-17 21:21:42,744:INFO:Creating metrics dataframe
2025-01-17 21:21:42,745:INFO:Uploading results into container
2025-01-17 21:21:42,746:INFO:Uploading model into container now
2025-01-17 21:21:42,746:INFO:_master_model_container: 3
2025-01-17 21:21:42,746:INFO:_display_container: 2
2025-01-17 21:21:42,747:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-01-17 21:21:42,747:INFO:create_model() successfully completed......................................
2025-01-17 21:21:42,795:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:42,795:INFO:Creating metrics dataframe
2025-01-17 21:21:42,800:INFO:Initializing Decision Tree Classifier
2025-01-17 21:21:42,800:INFO:Total runtime is 0.2501699209213257 minutes
2025-01-17 21:21:42,802:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:42,802:INFO:Initializing create_model()
2025-01-17 21:21:42,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:42,802:INFO:Checking exceptions
2025-01-17 21:21:42,803:INFO:Importing libraries
2025-01-17 21:21:42,803:INFO:Copying training dataset
2025-01-17 21:21:42,818:INFO:Defining folds
2025-01-17 21:21:42,818:INFO:Declaring metric variables
2025-01-17 21:21:42,820:INFO:Importing untrained model
2025-01-17 21:21:42,823:INFO:Decision Tree Classifier Imported successfully
2025-01-17 21:21:42,827:INFO:Starting cross validation
2025-01-17 21:21:42,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:43,481:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,484:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,489:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,493:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,499:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,582:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,587:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,897:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,903:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:43,912:INFO:Calculating mean and std
2025-01-17 21:21:43,913:INFO:Creating metrics dataframe
2025-01-17 21:21:43,915:INFO:Uploading results into container
2025-01-17 21:21:43,915:INFO:Uploading model into container now
2025-01-17 21:21:43,916:INFO:_master_model_container: 4
2025-01-17 21:21:43,916:INFO:_display_container: 2
2025-01-17 21:21:43,916:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-01-17 21:21:43,916:INFO:create_model() successfully completed......................................
2025-01-17 21:21:43,965:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:43,965:INFO:Creating metrics dataframe
2025-01-17 21:21:43,971:INFO:Initializing SVM - Linear Kernel
2025-01-17 21:21:43,971:INFO:Total runtime is 0.26967946688334143 minutes
2025-01-17 21:21:43,973:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:43,973:INFO:Initializing create_model()
2025-01-17 21:21:43,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:43,973:INFO:Checking exceptions
2025-01-17 21:21:43,973:INFO:Importing libraries
2025-01-17 21:21:43,973:INFO:Copying training dataset
2025-01-17 21:21:43,988:INFO:Defining folds
2025-01-17 21:21:43,988:INFO:Declaring metric variables
2025-01-17 21:21:43,991:INFO:Importing untrained model
2025-01-17 21:21:43,993:INFO:SVM - Linear Kernel Imported successfully
2025-01-17 21:21:43,997:INFO:Starting cross validation
2025-01-17 21:21:44,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:45,905:INFO:Calculating mean and std
2025-01-17 21:21:45,906:INFO:Creating metrics dataframe
2025-01-17 21:21:45,907:INFO:Uploading results into container
2025-01-17 21:21:45,908:INFO:Uploading model into container now
2025-01-17 21:21:45,908:INFO:_master_model_container: 5
2025-01-17 21:21:45,908:INFO:_display_container: 2
2025-01-17 21:21:45,908:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-01-17 21:21:45,908:INFO:create_model() successfully completed......................................
2025-01-17 21:21:45,955:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:45,955:INFO:Creating metrics dataframe
2025-01-17 21:21:45,961:INFO:Initializing Ridge Classifier
2025-01-17 21:21:45,961:INFO:Total runtime is 0.30285069942474363 minutes
2025-01-17 21:21:45,963:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:45,963:INFO:Initializing create_model()
2025-01-17 21:21:45,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:45,963:INFO:Checking exceptions
2025-01-17 21:21:45,963:INFO:Importing libraries
2025-01-17 21:21:45,963:INFO:Copying training dataset
2025-01-17 21:21:45,978:INFO:Defining folds
2025-01-17 21:21:45,978:INFO:Declaring metric variables
2025-01-17 21:21:45,981:INFO:Importing untrained model
2025-01-17 21:21:45,983:INFO:Ridge Classifier Imported successfully
2025-01-17 21:21:45,987:INFO:Starting cross validation
2025-01-17 21:21:45,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:46,802:INFO:Calculating mean and std
2025-01-17 21:21:46,804:INFO:Creating metrics dataframe
2025-01-17 21:21:46,807:INFO:Uploading results into container
2025-01-17 21:21:46,808:INFO:Uploading model into container now
2025-01-17 21:21:46,810:INFO:_master_model_container: 6
2025-01-17 21:21:46,810:INFO:_display_container: 2
2025-01-17 21:21:46,811:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-01-17 21:21:46,811:INFO:create_model() successfully completed......................................
2025-01-17 21:21:46,879:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:46,879:INFO:Creating metrics dataframe
2025-01-17 21:21:46,885:INFO:Initializing Random Forest Classifier
2025-01-17 21:21:46,885:INFO:Total runtime is 0.31824968655904134 minutes
2025-01-17 21:21:46,887:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:46,887:INFO:Initializing create_model()
2025-01-17 21:21:46,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:46,887:INFO:Checking exceptions
2025-01-17 21:21:46,887:INFO:Importing libraries
2025-01-17 21:21:46,887:INFO:Copying training dataset
2025-01-17 21:21:46,902:INFO:Defining folds
2025-01-17 21:21:46,902:INFO:Declaring metric variables
2025-01-17 21:21:46,905:INFO:Importing untrained model
2025-01-17 21:21:46,907:INFO:Random Forest Classifier Imported successfully
2025-01-17 21:21:46,913:INFO:Starting cross validation
2025-01-17 21:21:46,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:51,999:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:52,019:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:52,030:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:52,053:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:52,058:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:52,074:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:52,145:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:52,150:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:53,397:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:53,467:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:21:53,486:INFO:Calculating mean and std
2025-01-17 21:21:53,486:INFO:Creating metrics dataframe
2025-01-17 21:21:53,488:INFO:Uploading results into container
2025-01-17 21:21:53,489:INFO:Uploading model into container now
2025-01-17 21:21:53,489:INFO:_master_model_container: 7
2025-01-17 21:21:53,489:INFO:_display_container: 2
2025-01-17 21:21:53,490:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-01-17 21:21:53,490:INFO:create_model() successfully completed......................................
2025-01-17 21:21:53,550:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:53,550:INFO:Creating metrics dataframe
2025-01-17 21:21:53,556:INFO:Initializing Quadratic Discriminant Analysis
2025-01-17 21:21:53,556:INFO:Total runtime is 0.4294377168019613 minutes
2025-01-17 21:21:53,559:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:53,559:INFO:Initializing create_model()
2025-01-17 21:21:53,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:53,559:INFO:Checking exceptions
2025-01-17 21:21:53,559:INFO:Importing libraries
2025-01-17 21:21:53,559:INFO:Copying training dataset
2025-01-17 21:21:53,579:INFO:Defining folds
2025-01-17 21:21:53,579:INFO:Declaring metric variables
2025-01-17 21:21:53,581:INFO:Importing untrained model
2025-01-17 21:21:53,584:INFO:Quadratic Discriminant Analysis Imported successfully
2025-01-17 21:21:53,590:INFO:Starting cross validation
2025-01-17 21:21:53,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:53,959:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:53,990:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,055:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,093:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,125:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,129:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,130:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,131:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,138:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,139:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,140:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,148:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,157:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,158:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,159:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,162:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,164:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,165:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,165:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,167:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,172:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,180:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,184:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,184:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,185:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,189:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,189:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,190:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,190:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,190:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,191:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,195:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,198:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,198:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,199:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,203:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,215:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,215:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,216:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,220:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,220:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,221:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,224:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,237:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,237:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,238:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,242:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,242:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,241:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,242:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,242:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,243:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,246:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,247:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,248:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,249:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,249:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,249:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,249:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,253:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,254:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,254:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,254:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,258:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,464:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,468:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:21:54,494:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,495:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,495:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,497:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,497:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,497:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,498:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,499:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,499:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,500:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,501:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,502:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:21:54,502:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:21:54,503:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:21:54,522:INFO:Calculating mean and std
2025-01-17 21:21:54,523:INFO:Creating metrics dataframe
2025-01-17 21:21:54,524:INFO:Uploading results into container
2025-01-17 21:21:54,525:INFO:Uploading model into container now
2025-01-17 21:21:54,525:INFO:_master_model_container: 8
2025-01-17 21:21:54,525:INFO:_display_container: 2
2025-01-17 21:21:54,525:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-01-17 21:21:54,525:INFO:create_model() successfully completed......................................
2025-01-17 21:21:54,572:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:54,572:INFO:Creating metrics dataframe
2025-01-17 21:21:54,578:INFO:Initializing Ada Boost Classifier
2025-01-17 21:21:54,578:INFO:Total runtime is 0.4464698473612468 minutes
2025-01-17 21:21:54,580:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:54,580:INFO:Initializing create_model()
2025-01-17 21:21:54,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:54,580:INFO:Checking exceptions
2025-01-17 21:21:54,580:INFO:Importing libraries
2025-01-17 21:21:54,580:INFO:Copying training dataset
2025-01-17 21:21:54,595:INFO:Defining folds
2025-01-17 21:21:54,595:INFO:Declaring metric variables
2025-01-17 21:21:54,597:INFO:Importing untrained model
2025-01-17 21:21:54,600:INFO:Ada Boost Classifier Imported successfully
2025-01-17 21:21:54,605:INFO:Starting cross validation
2025-01-17 21:21:54,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:21:54,883:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:54,927:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:54,947:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:54,955:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:54,981:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:55,026:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:55,036:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:55,053:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:57,405:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:57,449:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:21:58,715:INFO:Calculating mean and std
2025-01-17 21:21:58,716:INFO:Creating metrics dataframe
2025-01-17 21:21:58,717:INFO:Uploading results into container
2025-01-17 21:21:58,717:INFO:Uploading model into container now
2025-01-17 21:21:58,718:INFO:_master_model_container: 9
2025-01-17 21:21:58,718:INFO:_display_container: 2
2025-01-17 21:21:58,718:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-01-17 21:21:58,718:INFO:create_model() successfully completed......................................
2025-01-17 21:21:58,773:INFO:SubProcess create_model() end ==================================
2025-01-17 21:21:58,773:INFO:Creating metrics dataframe
2025-01-17 21:21:58,780:INFO:Initializing Gradient Boosting Classifier
2025-01-17 21:21:58,780:INFO:Total runtime is 0.5164980530738831 minutes
2025-01-17 21:21:58,782:INFO:SubProcess create_model() called ==================================
2025-01-17 21:21:58,782:INFO:Initializing create_model()
2025-01-17 21:21:58,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:21:58,782:INFO:Checking exceptions
2025-01-17 21:21:58,782:INFO:Importing libraries
2025-01-17 21:21:58,783:INFO:Copying training dataset
2025-01-17 21:21:58,830:INFO:Defining folds
2025-01-17 21:21:58,831:INFO:Declaring metric variables
2025-01-17 21:21:58,835:INFO:Importing untrained model
2025-01-17 21:21:58,841:INFO:Gradient Boosting Classifier Imported successfully
2025-01-17 21:21:58,847:INFO:Starting cross validation
2025-01-17 21:21:58,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:22:13,448:INFO:Calculating mean and std
2025-01-17 21:22:13,450:INFO:Creating metrics dataframe
2025-01-17 21:22:13,451:INFO:Uploading results into container
2025-01-17 21:22:13,452:INFO:Uploading model into container now
2025-01-17 21:22:13,452:INFO:_master_model_container: 10
2025-01-17 21:22:13,452:INFO:_display_container: 2
2025-01-17 21:22:13,452:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-01-17 21:22:13,452:INFO:create_model() successfully completed......................................
2025-01-17 21:22:13,515:INFO:SubProcess create_model() end ==================================
2025-01-17 21:22:13,516:INFO:Creating metrics dataframe
2025-01-17 21:22:13,523:INFO:Initializing Linear Discriminant Analysis
2025-01-17 21:22:13,523:INFO:Total runtime is 0.7622123877207438 minutes
2025-01-17 21:22:13,525:INFO:SubProcess create_model() called ==================================
2025-01-17 21:22:13,525:INFO:Initializing create_model()
2025-01-17 21:22:13,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:22:13,525:INFO:Checking exceptions
2025-01-17 21:22:13,525:INFO:Importing libraries
2025-01-17 21:22:13,525:INFO:Copying training dataset
2025-01-17 21:22:13,540:INFO:Defining folds
2025-01-17 21:22:13,541:INFO:Declaring metric variables
2025-01-17 21:22:13,543:INFO:Importing untrained model
2025-01-17 21:22:13,545:INFO:Linear Discriminant Analysis Imported successfully
2025-01-17 21:22:13,550:INFO:Starting cross validation
2025-01-17 21:22:13,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:22:14,624:INFO:Calculating mean and std
2025-01-17 21:22:14,626:INFO:Creating metrics dataframe
2025-01-17 21:22:14,627:INFO:Uploading results into container
2025-01-17 21:22:14,628:INFO:Uploading model into container now
2025-01-17 21:22:14,628:INFO:_master_model_container: 11
2025-01-17 21:22:14,628:INFO:_display_container: 2
2025-01-17 21:22:14,629:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-01-17 21:22:14,629:INFO:create_model() successfully completed......................................
2025-01-17 21:22:14,690:INFO:SubProcess create_model() end ==================================
2025-01-17 21:22:14,690:INFO:Creating metrics dataframe
2025-01-17 21:22:14,697:INFO:Initializing Extra Trees Classifier
2025-01-17 21:22:14,697:INFO:Total runtime is 0.7817850669225057 minutes
2025-01-17 21:22:14,699:INFO:SubProcess create_model() called ==================================
2025-01-17 21:22:14,699:INFO:Initializing create_model()
2025-01-17 21:22:14,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:22:14,699:INFO:Checking exceptions
2025-01-17 21:22:14,699:INFO:Importing libraries
2025-01-17 21:22:14,700:INFO:Copying training dataset
2025-01-17 21:22:14,713:INFO:Defining folds
2025-01-17 21:22:14,714:INFO:Declaring metric variables
2025-01-17 21:22:14,716:INFO:Importing untrained model
2025-01-17 21:22:14,719:INFO:Extra Trees Classifier Imported successfully
2025-01-17 21:22:14,725:INFO:Starting cross validation
2025-01-17 21:22:14,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:22:18,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:18,376:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:18,395:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:18,593:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:18,607:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:18,701:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:18,756:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:18,851:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:19,755:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:19,793:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:19,808:INFO:Calculating mean and std
2025-01-17 21:22:19,811:INFO:Creating metrics dataframe
2025-01-17 21:22:19,814:INFO:Uploading results into container
2025-01-17 21:22:19,815:INFO:Uploading model into container now
2025-01-17 21:22:19,816:INFO:_master_model_container: 12
2025-01-17 21:22:19,816:INFO:_display_container: 2
2025-01-17 21:22:19,818:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-01-17 21:22:19,819:INFO:create_model() successfully completed......................................
2025-01-17 21:22:19,906:INFO:SubProcess create_model() end ==================================
2025-01-17 21:22:19,906:INFO:Creating metrics dataframe
2025-01-17 21:22:19,913:INFO:Initializing Extreme Gradient Boosting
2025-01-17 21:22:19,913:INFO:Total runtime is 0.8687244494756063 minutes
2025-01-17 21:22:19,916:INFO:SubProcess create_model() called ==================================
2025-01-17 21:22:19,916:INFO:Initializing create_model()
2025-01-17 21:22:19,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:22:19,916:INFO:Checking exceptions
2025-01-17 21:22:19,916:INFO:Importing libraries
2025-01-17 21:22:19,916:INFO:Copying training dataset
2025-01-17 21:22:19,931:INFO:Defining folds
2025-01-17 21:22:19,932:INFO:Declaring metric variables
2025-01-17 21:22:19,935:INFO:Importing untrained model
2025-01-17 21:22:19,939:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:22:19,946:INFO:Starting cross validation
2025-01-17 21:22:19,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:22:21,205:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,207:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,223:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,253:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,260:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,261:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,278:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,765:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,768:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:21,782:INFO:Calculating mean and std
2025-01-17 21:22:21,783:INFO:Creating metrics dataframe
2025-01-17 21:22:21,785:INFO:Uploading results into container
2025-01-17 21:22:21,785:INFO:Uploading model into container now
2025-01-17 21:22:21,785:INFO:_master_model_container: 13
2025-01-17 21:22:21,786:INFO:_display_container: 2
2025-01-17 21:22:21,786:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:22:21,786:INFO:create_model() successfully completed......................................
2025-01-17 21:22:21,837:INFO:SubProcess create_model() end ==================================
2025-01-17 21:22:21,837:INFO:Creating metrics dataframe
2025-01-17 21:22:21,844:INFO:Initializing Light Gradient Boosting Machine
2025-01-17 21:22:21,845:INFO:Total runtime is 0.9009112358093262 minutes
2025-01-17 21:22:21,847:INFO:SubProcess create_model() called ==================================
2025-01-17 21:22:21,847:INFO:Initializing create_model()
2025-01-17 21:22:21,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:22:21,847:INFO:Checking exceptions
2025-01-17 21:22:21,847:INFO:Importing libraries
2025-01-17 21:22:21,847:INFO:Copying training dataset
2025-01-17 21:22:21,861:INFO:Defining folds
2025-01-17 21:22:21,861:INFO:Declaring metric variables
2025-01-17 21:22:21,863:INFO:Importing untrained model
2025-01-17 21:22:21,866:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-17 21:22:21,873:INFO:Starting cross validation
2025-01-17 21:22:21,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:22:25,325:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:25,361:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:25,377:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:25,394:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:25,416:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:25,422:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:25,429:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:25,523:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:26,761:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:26,794:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:26,805:INFO:Calculating mean and std
2025-01-17 21:22:26,806:INFO:Creating metrics dataframe
2025-01-17 21:22:26,807:INFO:Uploading results into container
2025-01-17 21:22:26,808:INFO:Uploading model into container now
2025-01-17 21:22:26,808:INFO:_master_model_container: 14
2025-01-17 21:22:26,808:INFO:_display_container: 2
2025-01-17 21:22:26,809:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-01-17 21:22:26,809:INFO:create_model() successfully completed......................................
2025-01-17 21:22:26,863:INFO:SubProcess create_model() end ==================================
2025-01-17 21:22:26,863:INFO:Creating metrics dataframe
2025-01-17 21:22:26,871:INFO:Initializing Dummy Classifier
2025-01-17 21:22:26,872:INFO:Total runtime is 0.9846949855486552 minutes
2025-01-17 21:22:26,874:INFO:SubProcess create_model() called ==================================
2025-01-17 21:22:26,874:INFO:Initializing create_model()
2025-01-17 21:22:26,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107f2f5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:22:26,875:INFO:Checking exceptions
2025-01-17 21:22:26,875:INFO:Importing libraries
2025-01-17 21:22:26,875:INFO:Copying training dataset
2025-01-17 21:22:26,892:INFO:Defining folds
2025-01-17 21:22:26,892:INFO:Declaring metric variables
2025-01-17 21:22:26,895:INFO:Importing untrained model
2025-01-17 21:22:26,897:INFO:Dummy Classifier Imported successfully
2025-01-17 21:22:26,905:INFO:Starting cross validation
2025-01-17 21:22:26,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:22:27,419:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,430:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,431:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,432:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,439:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,444:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,459:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,466:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,469:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,471:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,479:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,482:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,486:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,495:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,496:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,505:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,728:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,728:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:22:27,732:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,732:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:22:27,741:INFO:Calculating mean and std
2025-01-17 21:22:27,742:INFO:Creating metrics dataframe
2025-01-17 21:22:27,744:INFO:Uploading results into container
2025-01-17 21:22:27,744:INFO:Uploading model into container now
2025-01-17 21:22:27,745:INFO:_master_model_container: 15
2025-01-17 21:22:27,745:INFO:_display_container: 2
2025-01-17 21:22:27,745:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-01-17 21:22:27,745:INFO:create_model() successfully completed......................................
2025-01-17 21:22:27,797:INFO:SubProcess create_model() end ==================================
2025-01-17 21:22:27,797:INFO:Creating metrics dataframe
2025-01-17 21:22:27,808:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-17 21:22:27,815:INFO:Initializing create_model()
2025-01-17 21:22:27,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:22:27,816:INFO:Checking exceptions
2025-01-17 21:22:27,820:INFO:Importing libraries
2025-01-17 21:22:27,820:INFO:Copying training dataset
2025-01-17 21:22:27,838:INFO:Defining folds
2025-01-17 21:22:27,838:INFO:Declaring metric variables
2025-01-17 21:22:27,838:INFO:Importing untrained model
2025-01-17 21:22:27,838:INFO:Declaring custom model
2025-01-17 21:22:27,839:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:22:27,841:INFO:Cross validation set to False
2025-01-17 21:22:27,841:INFO:Fitting Model
2025-01-17 21:22:28,295:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:22:28,296:INFO:create_model() successfully completed......................................
2025-01-17 21:22:28,363:INFO:_master_model_container: 15
2025-01-17 21:22:28,363:INFO:_display_container: 2
2025-01-17 21:22:28,364:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:22:28,364:INFO:compare_models() successfully completed......................................
2025-01-17 21:22:28,368:INFO:Initializing finalize_model()
2025-01-17 21:22:28,368:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-01-17 21:22:28,369:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:22:28,380:INFO:Initializing create_model()
2025-01-17 21:22:28,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:22:28,380:INFO:Checking exceptions
2025-01-17 21:22:28,382:INFO:Importing libraries
2025-01-17 21:22:28,382:INFO:Copying training dataset
2025-01-17 21:22:28,382:INFO:Defining folds
2025-01-17 21:22:28,382:INFO:Declaring metric variables
2025-01-17 21:22:28,382:INFO:Importing untrained model
2025-01-17 21:22:28,382:INFO:Declaring custom model
2025-01-17 21:22:28,383:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:22:28,385:INFO:Cross validation set to False
2025-01-17 21:22:28,385:INFO:Fitting Model
2025-01-17 21:22:28,903:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:22:28,903:INFO:create_model() successfully completed......................................
2025-01-17 21:22:28,985:INFO:_master_model_container: 15
2025-01-17 21:22:28,986:INFO:_display_container: 2
2025-01-17 21:22:29,084:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:22:29,084:INFO:finalize_model() successfully completed......................................
2025-01-17 21:22:29,215:INFO:Initializing save_model()
2025-01-17 21:22:29,216:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=pycaret_best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-01-17 21:22:29,216:INFO:Adding model into prep_pipe
2025-01-17 21:22:29,216:WARNING:Only Model saved as it was a pipeline.
2025-01-17 21:22:29,231:INFO:pycaret_best_model.pkl saved in current working directory
2025-01-17 21:22:29,267:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:22:29,267:INFO:save_model() successfully completed......................................
2025-01-17 21:22:29,380:INFO:Initializing plot_model()
2025-01-17 21:22:29,381:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, system=True)
2025-01-17 21:22:29,381:INFO:Checking exceptions
2025-01-17 21:22:29,400:INFO:Preloading libraries
2025-01-17 21:22:29,404:INFO:Copying training dataset
2025-01-17 21:22:29,404:INFO:Plot type: auc
2025-01-17 21:22:29,739:INFO:Fitting Model
2025-01-17 21:22:29,740:INFO:Scoring test/hold-out set
2025-01-17 21:22:29,902:INFO:Visual Rendered Successfully
2025-01-17 21:22:29,955:INFO:plot_model() successfully completed......................................
2025-01-17 21:22:29,956:INFO:Initializing plot_model()
2025-01-17 21:22:29,956:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, system=True)
2025-01-17 21:22:29,956:INFO:Checking exceptions
2025-01-17 21:22:29,963:INFO:Preloading libraries
2025-01-17 21:22:29,965:INFO:Copying training dataset
2025-01-17 21:22:29,965:INFO:Plot type: confusion_matrix
2025-01-17 21:22:30,208:INFO:Fitting Model
2025-01-17 21:22:30,209:INFO:Scoring test/hold-out set
2025-01-17 21:22:30,294:INFO:Visual Rendered Successfully
2025-01-17 21:22:30,351:INFO:plot_model() successfully completed......................................
2025-01-17 21:22:30,352:INFO:Initializing plot_model()
2025-01-17 21:22:30,352:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, system=True)
2025-01-17 21:22:30,352:INFO:Checking exceptions
2025-01-17 21:22:30,359:INFO:Preloading libraries
2025-01-17 21:22:30,361:INFO:Copying training dataset
2025-01-17 21:22:30,361:INFO:Plot type: feature
2025-01-17 21:22:30,362:WARNING:No coef_ found. Trying feature_importances_
2025-01-17 21:22:30,487:INFO:Visual Rendered Successfully
2025-01-17 21:22:30,550:INFO:plot_model() successfully completed......................................
2025-01-17 21:22:30,551:INFO:Initializing plot_model()
2025-01-17 21:22:30,551:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>, system=True)
2025-01-17 21:22:30,551:INFO:Checking exceptions
2025-01-17 21:22:30,560:INFO:Preloading libraries
2025-01-17 21:22:30,562:INFO:Copying training dataset
2025-01-17 21:22:30,562:INFO:Plot type: learning
2025-01-17 21:22:30,803:INFO:Fitting Model
2025-01-17 21:22:38,435:INFO:Visual Rendered Successfully
2025-01-17 21:22:38,493:INFO:plot_model() successfully completed......................................
2025-01-17 21:22:39,586:INFO:Initializing interpret_model()
2025-01-17 21:22:39,586:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15b188730>)
2025-01-17 21:22:39,586:INFO:Checking exceptions
2025-01-17 21:22:39,586:INFO:Soft dependency imported: shap: 0.46.0
2025-01-17 21:22:44,380:INFO:plot type: summary
2025-01-17 21:22:44,380:INFO:Creating TreeExplainer
2025-01-17 21:22:44,397:INFO:Compiling shap values
2025-01-17 21:22:47,526:INFO:Visual Rendered Successfully
2025-01-17 21:22:47,526:INFO:interpret_model() successfully completed......................................
2025-01-17 21:24:58,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 21:24:58,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 21:24:58,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 21:24:58,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-17 21:25:01,133:INFO:PyCaret ClassificationExperiment
2025-01-17 21:25:01,133:INFO:Logging name: clf-default-name
2025-01-17 21:25:01,133:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-01-17 21:25:01,133:INFO:version 3.3.1
2025-01-17 21:25:01,133:INFO:Initializing setup()
2025-01-17 21:25:01,133:INFO:self.USI: 4ff5
2025-01-17 21:25:01,133:INFO:self._variable_keys: {'gpu_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'logging_param', 'X_test', '_ml_usecase', 'fold_groups_param', 'log_plots_param', 'data', 'seed', 'X', 'fold_shuffle_param', 'exp_id', 'y_train', 'fold_generator', 'y', 'target_param', 'X_train', 'pipeline', 'USI', 'y_test', '_available_plots', 'html_param', 'fix_imbalance', 'idx', 'exp_name_log'}
2025-01-17 21:25:01,133:INFO:Checking environment
2025-01-17 21:25:01,134:INFO:python_version: 3.10.13
2025-01-17 21:25:01,134:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-17 21:25:01,134:INFO:machine: arm64
2025-01-17 21:25:01,134:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-17 21:25:01,134:INFO:Memory: svmem(total=8589934592, available=2613952512, percent=69.6, used=3407314944, free=616579072, active=1990180864, inactive=1832583168, wired=1417134080)
2025-01-17 21:25:01,134:INFO:Physical Core: 8
2025-01-17 21:25:01,134:INFO:Logical Core: 8
2025-01-17 21:25:01,135:INFO:Checking libraries
2025-01-17 21:25:01,135:INFO:System:
2025-01-17 21:25:01,135:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-17 21:25:01,135:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-17 21:25:01,135:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-17 21:25:01,135:INFO:PyCaret required dependencies:
2025-01-17 21:25:01,439:INFO:                 pip: 24.2
2025-01-17 21:25:01,439:INFO:          setuptools: 75.1.0
2025-01-17 21:25:01,439:INFO:             pycaret: 3.3.1
2025-01-17 21:25:01,439:INFO:             IPython: 8.27.0
2025-01-17 21:25:01,439:INFO:          ipywidgets: 8.1.2
2025-01-17 21:25:01,439:INFO:                tqdm: 4.66.5
2025-01-17 21:25:01,439:INFO:               numpy: 1.26.4
2025-01-17 21:25:01,439:INFO:              pandas: 2.1.4
2025-01-17 21:25:01,440:INFO:              jinja2: 3.1.4
2025-01-17 21:25:01,440:INFO:               scipy: 1.11.4
2025-01-17 21:25:01,440:INFO:              joblib: 1.3.2
2025-01-17 21:25:01,440:INFO:             sklearn: 1.4.2
2025-01-17 21:25:01,440:INFO:                pyod: 2.0.2
2025-01-17 21:25:01,440:INFO:            imblearn: 0.13.0
2025-01-17 21:25:01,440:INFO:   category_encoders: 2.7.0
2025-01-17 21:25:01,440:INFO:            lightgbm: 4.4.0
2025-01-17 21:25:01,440:INFO:               numba: 0.60.0
2025-01-17 21:25:01,440:INFO:            requests: 2.32.3
2025-01-17 21:25:01,440:INFO:          matplotlib: 3.9.2
2025-01-17 21:25:01,440:INFO:          scikitplot: 0.3.7
2025-01-17 21:25:01,440:INFO:         yellowbrick: 1.5
2025-01-17 21:25:01,440:INFO:              plotly: 5.24.1
2025-01-17 21:25:01,440:INFO:    plotly-resampler: Not installed
2025-01-17 21:25:01,440:INFO:             kaleido: 0.2.1
2025-01-17 21:25:01,440:INFO:           schemdraw: 0.15
2025-01-17 21:25:01,440:INFO:         statsmodels: 0.14.4
2025-01-17 21:25:01,440:INFO:              sktime: 0.26.0
2025-01-17 21:25:01,440:INFO:               tbats: 1.1.3
2025-01-17 21:25:01,440:INFO:            pmdarima: 2.0.4
2025-01-17 21:25:01,440:INFO:              psutil: 5.9.0
2025-01-17 21:25:01,440:INFO:          markupsafe: 2.1.3
2025-01-17 21:25:01,440:INFO:             pickle5: Not installed
2025-01-17 21:25:01,440:INFO:         cloudpickle: 3.1.0
2025-01-17 21:25:01,440:INFO:         deprecation: 2.1.0
2025-01-17 21:25:01,440:INFO:              xxhash: 3.5.0
2025-01-17 21:25:01,440:INFO:           wurlitzer: 3.1.1
2025-01-17 21:25:01,440:INFO:PyCaret optional dependencies:
2025-01-17 21:25:01,468:INFO:                shap: 0.46.0
2025-01-17 21:25:01,468:INFO:           interpret: Not installed
2025-01-17 21:25:01,468:INFO:                umap: 0.5.7
2025-01-17 21:25:01,468:INFO:     ydata_profiling: Not installed
2025-01-17 21:25:01,468:INFO:  explainerdashboard: Not installed
2025-01-17 21:25:01,468:INFO:             autoviz: Not installed
2025-01-17 21:25:01,468:INFO:           fairlearn: Not installed
2025-01-17 21:25:01,468:INFO:          deepchecks: Not installed
2025-01-17 21:25:01,468:INFO:             xgboost: 2.1.3
2025-01-17 21:25:01,468:INFO:            catboost: Not installed
2025-01-17 21:25:01,468:INFO:              kmodes: Not installed
2025-01-17 21:25:01,468:INFO:             mlxtend: Not installed
2025-01-17 21:25:01,468:INFO:       statsforecast: Not installed
2025-01-17 21:25:01,468:INFO:        tune_sklearn: Not installed
2025-01-17 21:25:01,468:INFO:                 ray: Not installed
2025-01-17 21:25:01,468:INFO:            hyperopt: Not installed
2025-01-17 21:25:01,468:INFO:              optuna: Not installed
2025-01-17 21:25:01,468:INFO:               skopt: Not installed
2025-01-17 21:25:01,468:INFO:              mlflow: 2.19.0
2025-01-17 21:25:01,469:INFO:              gradio: Not installed
2025-01-17 21:25:01,469:INFO:             fastapi: Not installed
2025-01-17 21:25:01,469:INFO:             uvicorn: Not installed
2025-01-17 21:25:01,469:INFO:              m2cgen: Not installed
2025-01-17 21:25:01,469:INFO:           evidently: Not installed
2025-01-17 21:25:01,469:INFO:               fugue: Not installed
2025-01-17 21:25:01,469:INFO:           streamlit: Not installed
2025-01-17 21:25:01,469:INFO:             prophet: Not installed
2025-01-17 21:25:01,469:INFO:None
2025-01-17 21:25:01,469:INFO:Set up data.
2025-01-17 21:25:01,497:INFO:Set up folding strategy.
2025-01-17 21:25:01,497:INFO:Set up train/test split.
2025-01-17 21:25:01,519:INFO:Set up index.
2025-01-17 21:25:01,520:INFO:Assigning column types.
2025-01-17 21:25:01,527:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-17 21:25:01,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 21:25:01,562:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:25:01,585:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:25:01,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:25:01,618:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-17 21:25:01,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:25:01,638:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:25:01,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:25:01,640:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-17 21:25:01,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:25:01,690:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:25:01,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:25:01,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-01-17 21:25:01,743:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:25:01,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:25:01,745:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-01-17 21:25:01,795:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:25:01,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:25:01,847:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:25:01,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:25:01,851:INFO:Preparing preprocessing pipeline...
2025-01-17 21:25:01,853:INFO:Set up simple imputation.
2025-01-17 21:25:01,860:INFO:Set up encoding of ordinal features.
2025-01-17 21:25:01,864:INFO:Set up encoding of categorical features.
2025-01-17 21:25:02,060:INFO:Finished creating preprocessing pipeline.
2025-01-17 21:25:02,077:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-01-17 21:25:02,077:INFO:Creating final display dataframe.
2025-01-17 21:25:02,294:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       loan_status
2                   Target type            Binary
3           Original data shape       (45000, 14)
4        Transformed data shape       (45000, 26)
5   Transformed train set shape       (31499, 26)
6    Transformed test set shape       (13501, 26)
7              Numeric features                 8
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              4ff5
2025-01-17 21:25:02,350:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:25:02,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:25:02,403:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-17 21:25:02,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-17 21:25:02,405:INFO:setup() successfully completed in 1.28s...............
2025-01-17 21:25:02,409:INFO:Initializing compare_models()
2025-01-17 21:25:02,410:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-01-17 21:25:02,410:INFO:Checking exceptions
2025-01-17 21:25:02,418:INFO:Preparing display monitor
2025-01-17 21:25:02,454:INFO:Initializing Logistic Regression
2025-01-17 21:25:02,455:INFO:Total runtime is 6.115436553955078e-06 minutes
2025-01-17 21:25:02,457:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:02,458:INFO:Initializing create_model()
2025-01-17 21:25:02,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:02,458:INFO:Checking exceptions
2025-01-17 21:25:02,458:INFO:Importing libraries
2025-01-17 21:25:02,458:INFO:Copying training dataset
2025-01-17 21:25:02,475:INFO:Defining folds
2025-01-17 21:25:02,475:INFO:Declaring metric variables
2025-01-17 21:25:02,478:INFO:Importing untrained model
2025-01-17 21:25:02,481:INFO:Logistic Regression Imported successfully
2025-01-17 21:25:02,487:INFO:Starting cross validation
2025-01-17 21:25:02,490:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:11,383:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:11,421:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:11,438:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:11,453:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:11,538:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:11,556:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:11,625:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:11,663:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:13,736:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:13,773:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-01-17 21:25:13,815:INFO:Calculating mean and std
2025-01-17 21:25:13,817:INFO:Creating metrics dataframe
2025-01-17 21:25:13,821:INFO:Uploading results into container
2025-01-17 21:25:13,821:INFO:Uploading model into container now
2025-01-17 21:25:13,822:INFO:_master_model_container: 1
2025-01-17 21:25:13,822:INFO:_display_container: 2
2025-01-17 21:25:13,823:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-01-17 21:25:13,823:INFO:create_model() successfully completed......................................
2025-01-17 21:25:13,940:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:13,940:INFO:Creating metrics dataframe
2025-01-17 21:25:13,945:INFO:Initializing K Neighbors Classifier
2025-01-17 21:25:13,945:INFO:Total runtime is 0.19151020050048828 minutes
2025-01-17 21:25:13,947:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:13,947:INFO:Initializing create_model()
2025-01-17 21:25:13,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:13,947:INFO:Checking exceptions
2025-01-17 21:25:13,948:INFO:Importing libraries
2025-01-17 21:25:13,948:INFO:Copying training dataset
2025-01-17 21:25:13,964:INFO:Defining folds
2025-01-17 21:25:13,965:INFO:Declaring metric variables
2025-01-17 21:25:13,969:INFO:Importing untrained model
2025-01-17 21:25:13,973:INFO:K Neighbors Classifier Imported successfully
2025-01-17 21:25:13,978:INFO:Starting cross validation
2025-01-17 21:25:13,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:15,579:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:15,612:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:15,632:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:15,638:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:15,645:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:15,669:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:15,697:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:15,716:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:16,363:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:16,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:16,400:INFO:Calculating mean and std
2025-01-17 21:25:16,402:INFO:Creating metrics dataframe
2025-01-17 21:25:16,403:INFO:Uploading results into container
2025-01-17 21:25:16,404:INFO:Uploading model into container now
2025-01-17 21:25:16,405:INFO:_master_model_container: 2
2025-01-17 21:25:16,405:INFO:_display_container: 2
2025-01-17 21:25:16,405:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-01-17 21:25:16,405:INFO:create_model() successfully completed......................................
2025-01-17 21:25:16,477:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:16,477:INFO:Creating metrics dataframe
2025-01-17 21:25:16,482:INFO:Initializing Naive Bayes
2025-01-17 21:25:16,482:INFO:Total runtime is 0.23379900058110556 minutes
2025-01-17 21:25:16,484:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:16,485:INFO:Initializing create_model()
2025-01-17 21:25:16,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:16,485:INFO:Checking exceptions
2025-01-17 21:25:16,485:INFO:Importing libraries
2025-01-17 21:25:16,485:INFO:Copying training dataset
2025-01-17 21:25:16,500:INFO:Defining folds
2025-01-17 21:25:16,500:INFO:Declaring metric variables
2025-01-17 21:25:16,502:INFO:Importing untrained model
2025-01-17 21:25:16,505:INFO:Naive Bayes Imported successfully
2025-01-17 21:25:16,512:INFO:Starting cross validation
2025-01-17 21:25:16,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:16,958:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:16,964:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:16,982:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:17,004:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:17,012:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:17,028:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:17,051:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:17,064:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:17,313:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:17,320:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:17,335:INFO:Calculating mean and std
2025-01-17 21:25:17,335:INFO:Creating metrics dataframe
2025-01-17 21:25:17,337:INFO:Uploading results into container
2025-01-17 21:25:17,338:INFO:Uploading model into container now
2025-01-17 21:25:17,338:INFO:_master_model_container: 3
2025-01-17 21:25:17,338:INFO:_display_container: 2
2025-01-17 21:25:17,338:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-01-17 21:25:17,338:INFO:create_model() successfully completed......................................
2025-01-17 21:25:17,404:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:17,404:INFO:Creating metrics dataframe
2025-01-17 21:25:17,410:INFO:Initializing Decision Tree Classifier
2025-01-17 21:25:17,410:INFO:Total runtime is 0.2492577354113261 minutes
2025-01-17 21:25:17,412:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:17,412:INFO:Initializing create_model()
2025-01-17 21:25:17,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:17,412:INFO:Checking exceptions
2025-01-17 21:25:17,412:INFO:Importing libraries
2025-01-17 21:25:17,413:INFO:Copying training dataset
2025-01-17 21:25:17,427:INFO:Defining folds
2025-01-17 21:25:17,427:INFO:Declaring metric variables
2025-01-17 21:25:17,429:INFO:Importing untrained model
2025-01-17 21:25:17,432:INFO:Decision Tree Classifier Imported successfully
2025-01-17 21:25:17,437:INFO:Starting cross validation
2025-01-17 21:25:17,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:18,050:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,072:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,096:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,117:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,118:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,162:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,178:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,206:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,491:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,500:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:18,514:INFO:Calculating mean and std
2025-01-17 21:25:18,514:INFO:Creating metrics dataframe
2025-01-17 21:25:18,516:INFO:Uploading results into container
2025-01-17 21:25:18,516:INFO:Uploading model into container now
2025-01-17 21:25:18,516:INFO:_master_model_container: 4
2025-01-17 21:25:18,516:INFO:_display_container: 2
2025-01-17 21:25:18,517:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-01-17 21:25:18,517:INFO:create_model() successfully completed......................................
2025-01-17 21:25:18,583:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:18,583:INFO:Creating metrics dataframe
2025-01-17 21:25:18,588:INFO:Initializing SVM - Linear Kernel
2025-01-17 21:25:18,589:INFO:Total runtime is 0.2689020355542501 minutes
2025-01-17 21:25:18,591:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:18,591:INFO:Initializing create_model()
2025-01-17 21:25:18,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:18,591:INFO:Checking exceptions
2025-01-17 21:25:18,591:INFO:Importing libraries
2025-01-17 21:25:18,591:INFO:Copying training dataset
2025-01-17 21:25:18,606:INFO:Defining folds
2025-01-17 21:25:18,606:INFO:Declaring metric variables
2025-01-17 21:25:18,608:INFO:Importing untrained model
2025-01-17 21:25:18,611:INFO:SVM - Linear Kernel Imported successfully
2025-01-17 21:25:18,616:INFO:Starting cross validation
2025-01-17 21:25:18,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:20,516:INFO:Calculating mean and std
2025-01-17 21:25:20,517:INFO:Creating metrics dataframe
2025-01-17 21:25:20,519:INFO:Uploading results into container
2025-01-17 21:25:20,519:INFO:Uploading model into container now
2025-01-17 21:25:20,519:INFO:_master_model_container: 5
2025-01-17 21:25:20,520:INFO:_display_container: 2
2025-01-17 21:25:20,520:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-01-17 21:25:20,520:INFO:create_model() successfully completed......................................
2025-01-17 21:25:20,586:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:20,586:INFO:Creating metrics dataframe
2025-01-17 21:25:20,592:INFO:Initializing Ridge Classifier
2025-01-17 21:25:20,592:INFO:Total runtime is 0.3022889534632365 minutes
2025-01-17 21:25:20,594:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:20,594:INFO:Initializing create_model()
2025-01-17 21:25:20,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:20,594:INFO:Checking exceptions
2025-01-17 21:25:20,594:INFO:Importing libraries
2025-01-17 21:25:20,594:INFO:Copying training dataset
2025-01-17 21:25:20,609:INFO:Defining folds
2025-01-17 21:25:20,609:INFO:Declaring metric variables
2025-01-17 21:25:20,612:INFO:Importing untrained model
2025-01-17 21:25:20,615:INFO:Ridge Classifier Imported successfully
2025-01-17 21:25:20,620:INFO:Starting cross validation
2025-01-17 21:25:20,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:21,591:INFO:Calculating mean and std
2025-01-17 21:25:21,593:INFO:Creating metrics dataframe
2025-01-17 21:25:21,595:INFO:Uploading results into container
2025-01-17 21:25:21,595:INFO:Uploading model into container now
2025-01-17 21:25:21,596:INFO:_master_model_container: 6
2025-01-17 21:25:21,596:INFO:_display_container: 2
2025-01-17 21:25:21,596:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-01-17 21:25:21,596:INFO:create_model() successfully completed......................................
2025-01-17 21:25:21,673:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:21,673:INFO:Creating metrics dataframe
2025-01-17 21:25:21,679:INFO:Initializing Random Forest Classifier
2025-01-17 21:25:21,679:INFO:Total runtime is 0.3204103350639343 minutes
2025-01-17 21:25:21,681:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:21,681:INFO:Initializing create_model()
2025-01-17 21:25:21,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:21,681:INFO:Checking exceptions
2025-01-17 21:25:21,682:INFO:Importing libraries
2025-01-17 21:25:21,682:INFO:Copying training dataset
2025-01-17 21:25:21,697:INFO:Defining folds
2025-01-17 21:25:21,697:INFO:Declaring metric variables
2025-01-17 21:25:21,700:INFO:Importing untrained model
2025-01-17 21:25:21,704:INFO:Random Forest Classifier Imported successfully
2025-01-17 21:25:21,709:INFO:Starting cross validation
2025-01-17 21:25:21,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:26,592:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:26,598:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:26,612:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:26,701:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:26,726:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:26,749:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:26,750:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:26,790:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:28,077:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:28,088:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:28,099:INFO:Calculating mean and std
2025-01-17 21:25:28,101:INFO:Creating metrics dataframe
2025-01-17 21:25:28,102:INFO:Uploading results into container
2025-01-17 21:25:28,103:INFO:Uploading model into container now
2025-01-17 21:25:28,103:INFO:_master_model_container: 7
2025-01-17 21:25:28,103:INFO:_display_container: 2
2025-01-17 21:25:28,104:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-01-17 21:25:28,104:INFO:create_model() successfully completed......................................
2025-01-17 21:25:28,180:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:28,180:INFO:Creating metrics dataframe
2025-01-17 21:25:28,186:INFO:Initializing Quadratic Discriminant Analysis
2025-01-17 21:25:28,186:INFO:Total runtime is 0.428862182299296 minutes
2025-01-17 21:25:28,188:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:28,189:INFO:Initializing create_model()
2025-01-17 21:25:28,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:28,189:INFO:Checking exceptions
2025-01-17 21:25:28,189:INFO:Importing libraries
2025-01-17 21:25:28,189:INFO:Copying training dataset
2025-01-17 21:25:28,205:INFO:Defining folds
2025-01-17 21:25:28,205:INFO:Declaring metric variables
2025-01-17 21:25:28,209:INFO:Importing untrained model
2025-01-17 21:25:28,211:INFO:Quadratic Discriminant Analysis Imported successfully
2025-01-17 21:25:28,217:INFO:Starting cross validation
2025-01-17 21:25:28,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:28,554:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:28,567:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:28,568:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:28,681:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:28,706:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:28,723:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:28,737:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,737:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,739:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,745:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,746:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,746:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,746:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,747:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,747:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,758:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:28,759:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,759:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,760:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,766:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:28,771:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,771:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,772:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,778:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,778:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,779:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,784:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:28,788:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:28,799:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:28,805:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,805:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,806:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,811:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,812:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,812:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,816:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:28,821:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,822:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,823:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,824:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,825:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,826:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,828:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,828:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,830:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,831:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,832:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,833:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,835:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:28,837:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:28,866:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,867:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,867:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,871:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,871:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,871:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,871:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,872:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,872:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,875:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:28,876:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,876:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:28,877:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:28,880:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:29,066:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:29,073:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-01-17 21:25:29,097:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:29,097:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:29,098:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:29,100:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:29,100:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:29,100:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:29,102:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:29,104:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:29,104:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:29,104:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:29,106:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:29,106:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-01-17 21:25:29,107:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-01-17 21:25:29,107:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-01-17 21:25:29,116:INFO:Calculating mean and std
2025-01-17 21:25:29,117:INFO:Creating metrics dataframe
2025-01-17 21:25:29,119:INFO:Uploading results into container
2025-01-17 21:25:29,119:INFO:Uploading model into container now
2025-01-17 21:25:29,119:INFO:_master_model_container: 8
2025-01-17 21:25:29,119:INFO:_display_container: 2
2025-01-17 21:25:29,120:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-01-17 21:25:29,120:INFO:create_model() successfully completed......................................
2025-01-17 21:25:29,186:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:29,186:INFO:Creating metrics dataframe
2025-01-17 21:25:29,192:INFO:Initializing Ada Boost Classifier
2025-01-17 21:25:29,192:INFO:Total runtime is 0.4456311543782552 minutes
2025-01-17 21:25:29,194:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:29,195:INFO:Initializing create_model()
2025-01-17 21:25:29,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:29,195:INFO:Checking exceptions
2025-01-17 21:25:29,195:INFO:Importing libraries
2025-01-17 21:25:29,195:INFO:Copying training dataset
2025-01-17 21:25:29,209:INFO:Defining folds
2025-01-17 21:25:29,209:INFO:Declaring metric variables
2025-01-17 21:25:29,211:INFO:Importing untrained model
2025-01-17 21:25:29,214:INFO:Ada Boost Classifier Imported successfully
2025-01-17 21:25:29,219:INFO:Starting cross validation
2025-01-17 21:25:29,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:29,509:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:29,510:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:29,530:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:29,531:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:29,567:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:29,572:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:29,605:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:29,666:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:32,030:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:32,054:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-01-17 21:25:33,333:INFO:Calculating mean and std
2025-01-17 21:25:33,334:INFO:Creating metrics dataframe
2025-01-17 21:25:33,335:INFO:Uploading results into container
2025-01-17 21:25:33,336:INFO:Uploading model into container now
2025-01-17 21:25:33,336:INFO:_master_model_container: 9
2025-01-17 21:25:33,336:INFO:_display_container: 2
2025-01-17 21:25:33,336:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-01-17 21:25:33,336:INFO:create_model() successfully completed......................................
2025-01-17 21:25:33,402:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:33,402:INFO:Creating metrics dataframe
2025-01-17 21:25:33,409:INFO:Initializing Gradient Boosting Classifier
2025-01-17 21:25:33,409:INFO:Total runtime is 0.515907601515452 minutes
2025-01-17 21:25:33,411:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:33,411:INFO:Initializing create_model()
2025-01-17 21:25:33,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:33,411:INFO:Checking exceptions
2025-01-17 21:25:33,412:INFO:Importing libraries
2025-01-17 21:25:33,412:INFO:Copying training dataset
2025-01-17 21:25:33,427:INFO:Defining folds
2025-01-17 21:25:33,427:INFO:Declaring metric variables
2025-01-17 21:25:33,429:INFO:Importing untrained model
2025-01-17 21:25:33,432:INFO:Gradient Boosting Classifier Imported successfully
2025-01-17 21:25:33,437:INFO:Starting cross validation
2025-01-17 21:25:33,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:48,025:INFO:Calculating mean and std
2025-01-17 21:25:48,027:INFO:Creating metrics dataframe
2025-01-17 21:25:48,029:INFO:Uploading results into container
2025-01-17 21:25:48,029:INFO:Uploading model into container now
2025-01-17 21:25:48,030:INFO:_master_model_container: 10
2025-01-17 21:25:48,030:INFO:_display_container: 2
2025-01-17 21:25:48,030:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-01-17 21:25:48,031:INFO:create_model() successfully completed......................................
2025-01-17 21:25:48,111:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:48,111:INFO:Creating metrics dataframe
2025-01-17 21:25:48,119:INFO:Initializing Linear Discriminant Analysis
2025-01-17 21:25:48,119:INFO:Total runtime is 0.7610736370086669 minutes
2025-01-17 21:25:48,121:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:48,122:INFO:Initializing create_model()
2025-01-17 21:25:48,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:48,122:INFO:Checking exceptions
2025-01-17 21:25:48,122:INFO:Importing libraries
2025-01-17 21:25:48,122:INFO:Copying training dataset
2025-01-17 21:25:48,139:INFO:Defining folds
2025-01-17 21:25:48,139:INFO:Declaring metric variables
2025-01-17 21:25:48,142:INFO:Importing untrained model
2025-01-17 21:25:48,145:INFO:Linear Discriminant Analysis Imported successfully
2025-01-17 21:25:48,151:INFO:Starting cross validation
2025-01-17 21:25:48,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:49,117:INFO:Calculating mean and std
2025-01-17 21:25:49,118:INFO:Creating metrics dataframe
2025-01-17 21:25:49,119:INFO:Uploading results into container
2025-01-17 21:25:49,119:INFO:Uploading model into container now
2025-01-17 21:25:49,120:INFO:_master_model_container: 11
2025-01-17 21:25:49,120:INFO:_display_container: 2
2025-01-17 21:25:49,120:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-01-17 21:25:49,120:INFO:create_model() successfully completed......................................
2025-01-17 21:25:49,192:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:49,193:INFO:Creating metrics dataframe
2025-01-17 21:25:49,199:INFO:Initializing Extra Trees Classifier
2025-01-17 21:25:49,200:INFO:Total runtime is 0.7790858189264933 minutes
2025-01-17 21:25:49,202:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:49,202:INFO:Initializing create_model()
2025-01-17 21:25:49,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:49,202:INFO:Checking exceptions
2025-01-17 21:25:49,202:INFO:Importing libraries
2025-01-17 21:25:49,202:INFO:Copying training dataset
2025-01-17 21:25:49,217:INFO:Defining folds
2025-01-17 21:25:49,217:INFO:Declaring metric variables
2025-01-17 21:25:49,219:INFO:Importing untrained model
2025-01-17 21:25:49,222:INFO:Extra Trees Classifier Imported successfully
2025-01-17 21:25:49,227:INFO:Starting cross validation
2025-01-17 21:25:49,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:52,966:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:53,054:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:53,071:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:53,094:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:53,111:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:53,119:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:53,144:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:53,230:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:54,195:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:54,196:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:54,215:INFO:Calculating mean and std
2025-01-17 21:25:54,216:INFO:Creating metrics dataframe
2025-01-17 21:25:54,221:INFO:Uploading results into container
2025-01-17 21:25:54,225:INFO:Uploading model into container now
2025-01-17 21:25:54,226:INFO:_master_model_container: 12
2025-01-17 21:25:54,226:INFO:_display_container: 2
2025-01-17 21:25:54,226:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-01-17 21:25:54,227:INFO:create_model() successfully completed......................................
2025-01-17 21:25:54,325:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:54,325:INFO:Creating metrics dataframe
2025-01-17 21:25:54,332:INFO:Initializing Extreme Gradient Boosting
2025-01-17 21:25:54,332:INFO:Total runtime is 0.8646329840024312 minutes
2025-01-17 21:25:54,334:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:54,335:INFO:Initializing create_model()
2025-01-17 21:25:54,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:54,335:INFO:Checking exceptions
2025-01-17 21:25:54,335:INFO:Importing libraries
2025-01-17 21:25:54,335:INFO:Copying training dataset
2025-01-17 21:25:54,350:INFO:Defining folds
2025-01-17 21:25:54,350:INFO:Declaring metric variables
2025-01-17 21:25:54,354:INFO:Importing untrained model
2025-01-17 21:25:54,357:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:25:54,362:INFO:Starting cross validation
2025-01-17 21:25:54,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:55,539:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:55,547:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:55,577:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:55,579:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:55,587:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:55,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:55,670:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:55,678:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:56,133:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:56,137:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:56,146:INFO:Calculating mean and std
2025-01-17 21:25:56,146:INFO:Creating metrics dataframe
2025-01-17 21:25:56,148:INFO:Uploading results into container
2025-01-17 21:25:56,148:INFO:Uploading model into container now
2025-01-17 21:25:56,149:INFO:_master_model_container: 13
2025-01-17 21:25:56,149:INFO:_display_container: 2
2025-01-17 21:25:56,149:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:25:56,149:INFO:create_model() successfully completed......................................
2025-01-17 21:25:56,216:INFO:SubProcess create_model() end ==================================
2025-01-17 21:25:56,216:INFO:Creating metrics dataframe
2025-01-17 21:25:56,223:INFO:Initializing Light Gradient Boosting Machine
2025-01-17 21:25:56,223:INFO:Total runtime is 0.8961440523465474 minutes
2025-01-17 21:25:56,225:INFO:SubProcess create_model() called ==================================
2025-01-17 21:25:56,225:INFO:Initializing create_model()
2025-01-17 21:25:56,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:25:56,226:INFO:Checking exceptions
2025-01-17 21:25:56,226:INFO:Importing libraries
2025-01-17 21:25:56,226:INFO:Copying training dataset
2025-01-17 21:25:56,239:INFO:Defining folds
2025-01-17 21:25:56,239:INFO:Declaring metric variables
2025-01-17 21:25:56,242:INFO:Importing untrained model
2025-01-17 21:25:56,245:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-17 21:25:56,251:INFO:Starting cross validation
2025-01-17 21:25:56,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:25:59,441:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:59,507:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:59,507:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:59,516:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:59,518:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:59,706:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:59,762:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:25:59,775:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:00,738:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:00,757:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:00,769:INFO:Calculating mean and std
2025-01-17 21:26:00,770:INFO:Creating metrics dataframe
2025-01-17 21:26:00,771:INFO:Uploading results into container
2025-01-17 21:26:00,772:INFO:Uploading model into container now
2025-01-17 21:26:00,772:INFO:_master_model_container: 14
2025-01-17 21:26:00,772:INFO:_display_container: 2
2025-01-17 21:26:00,772:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-01-17 21:26:00,773:INFO:create_model() successfully completed......................................
2025-01-17 21:26:00,839:INFO:SubProcess create_model() end ==================================
2025-01-17 21:26:00,839:INFO:Creating metrics dataframe
2025-01-17 21:26:00,847:INFO:Initializing Dummy Classifier
2025-01-17 21:26:00,847:INFO:Total runtime is 0.973206086953481 minutes
2025-01-17 21:26:00,849:INFO:SubProcess create_model() called ==================================
2025-01-17 21:26:00,849:INFO:Initializing create_model()
2025-01-17 21:26:00,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103cd0610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:26:00,849:INFO:Checking exceptions
2025-01-17 21:26:00,849:INFO:Importing libraries
2025-01-17 21:26:00,849:INFO:Copying training dataset
2025-01-17 21:26:00,863:INFO:Defining folds
2025-01-17 21:26:00,863:INFO:Declaring metric variables
2025-01-17 21:26:00,866:INFO:Importing untrained model
2025-01-17 21:26:00,868:INFO:Dummy Classifier Imported successfully
2025-01-17 21:26:00,873:INFO:Starting cross validation
2025-01-17 21:26:00,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-17 21:26:01,218:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,234:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,322:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,342:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,362:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,364:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,378:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,382:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,390:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,401:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,432:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,438:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,442:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,446:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,451:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,455:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,653:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,657:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,679:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 188, in _score
    return super()._score(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 248, in transform
    args.append(X[self._include])
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['person_education', 'person_home_ownership', 'loan_intent'] not in index"

  warnings.warn(

2025-01-17 21:26:01,683:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-01-17 21:26:01,697:INFO:Calculating mean and std
2025-01-17 21:26:01,698:INFO:Creating metrics dataframe
2025-01-17 21:26:01,700:INFO:Uploading results into container
2025-01-17 21:26:01,700:INFO:Uploading model into container now
2025-01-17 21:26:01,701:INFO:_master_model_container: 15
2025-01-17 21:26:01,701:INFO:_display_container: 2
2025-01-17 21:26:01,701:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-01-17 21:26:01,701:INFO:create_model() successfully completed......................................
2025-01-17 21:26:01,768:INFO:SubProcess create_model() end ==================================
2025-01-17 21:26:01,768:INFO:Creating metrics dataframe
2025-01-17 21:26:01,778:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-17 21:26:01,783:INFO:Initializing create_model()
2025-01-17 21:26:01,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:26:01,783:INFO:Checking exceptions
2025-01-17 21:26:01,785:INFO:Importing libraries
2025-01-17 21:26:01,785:INFO:Copying training dataset
2025-01-17 21:26:01,833:INFO:Defining folds
2025-01-17 21:26:01,833:INFO:Declaring metric variables
2025-01-17 21:26:01,833:INFO:Importing untrained model
2025-01-17 21:26:01,833:INFO:Declaring custom model
2025-01-17 21:26:01,836:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:26:01,840:INFO:Cross validation set to False
2025-01-17 21:26:01,840:INFO:Fitting Model
2025-01-17 21:26:02,247:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:26:02,247:INFO:create_model() successfully completed......................................
2025-01-17 21:26:02,333:INFO:_master_model_container: 15
2025-01-17 21:26:02,333:INFO:_display_container: 2
2025-01-17 21:26:02,333:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:26:02,334:INFO:compare_models() successfully completed......................................
2025-01-17 21:26:02,337:INFO:Initializing finalize_model()
2025-01-17 21:26:02,338:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-01-17 21:26:02,338:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-01-17 21:26:02,346:INFO:Initializing create_model()
2025-01-17 21:26:02,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-01-17 21:26:02,346:INFO:Checking exceptions
2025-01-17 21:26:02,348:INFO:Importing libraries
2025-01-17 21:26:02,348:INFO:Copying training dataset
2025-01-17 21:26:02,349:INFO:Defining folds
2025-01-17 21:26:02,349:INFO:Declaring metric variables
2025-01-17 21:26:02,350:INFO:Importing untrained model
2025-01-17 21:26:02,350:INFO:Declaring custom model
2025-01-17 21:26:02,351:INFO:Extreme Gradient Boosting Imported successfully
2025-01-17 21:26:02,352:INFO:Cross validation set to False
2025-01-17 21:26:02,352:INFO:Fitting Model
2025-01-17 21:26:02,910:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:26:02,910:INFO:create_model() successfully completed......................................
2025-01-17 21:26:02,980:INFO:_master_model_container: 15
2025-01-17 21:26:02,980:INFO:_display_container: 2
2025-01-17 21:26:02,997:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:26:02,997:INFO:finalize_model() successfully completed......................................
2025-01-17 21:26:03,098:INFO:Initializing save_model()
2025-01-17 21:26:03,098:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=pycaret_best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-01-17 21:26:03,098:INFO:Adding model into prep_pipe
2025-01-17 21:26:03,098:WARNING:Only Model saved as it was a pipeline.
2025-01-17 21:26:03,108:INFO:pycaret_best_model.pkl saved in current working directory
2025-01-17 21:26:03,128:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'credit_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-01-17 21:26:03,128:INFO:save_model() successfully completed......................................
2025-01-17 21:26:03,237:INFO:Initializing plot_model()
2025-01-17 21:26:03,237:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, system=True)
2025-01-17 21:26:03,237:INFO:Checking exceptions
2025-01-17 21:26:03,247:INFO:Preloading libraries
2025-01-17 21:26:03,251:INFO:Copying training dataset
2025-01-17 21:26:03,251:INFO:Plot type: auc
2025-01-17 21:26:03,485:INFO:Fitting Model
2025-01-17 21:26:03,487:INFO:Scoring test/hold-out set
2025-01-17 21:26:03,643:INFO:Visual Rendered Successfully
2025-01-17 21:26:03,711:INFO:plot_model() successfully completed......................................
2025-01-17 21:26:03,712:INFO:Initializing plot_model()
2025-01-17 21:26:03,712:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, system=True)
2025-01-17 21:26:03,713:INFO:Checking exceptions
2025-01-17 21:26:03,720:INFO:Preloading libraries
2025-01-17 21:26:03,722:INFO:Copying training dataset
2025-01-17 21:26:03,722:INFO:Plot type: confusion_matrix
2025-01-17 21:26:03,932:INFO:Fitting Model
2025-01-17 21:26:03,933:INFO:Scoring test/hold-out set
2025-01-17 21:26:04,012:INFO:Visual Rendered Successfully
2025-01-17 21:26:04,080:INFO:plot_model() successfully completed......................................
2025-01-17 21:26:04,081:INFO:Initializing plot_model()
2025-01-17 21:26:04,081:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, system=True)
2025-01-17 21:26:04,081:INFO:Checking exceptions
2025-01-17 21:26:04,087:INFO:Preloading libraries
2025-01-17 21:26:04,089:INFO:Copying training dataset
2025-01-17 21:26:04,089:INFO:Plot type: feature
2025-01-17 21:26:04,090:WARNING:No coef_ found. Trying feature_importances_
2025-01-17 21:26:04,211:INFO:Visual Rendered Successfully
2025-01-17 21:26:04,281:INFO:plot_model() successfully completed......................................
2025-01-17 21:26:04,282:INFO:Initializing plot_model()
2025-01-17 21:26:04,282:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>, system=True)
2025-01-17 21:26:04,282:INFO:Checking exceptions
2025-01-17 21:26:04,288:INFO:Preloading libraries
2025-01-17 21:26:04,290:INFO:Copying training dataset
2025-01-17 21:26:04,290:INFO:Plot type: learning
2025-01-17 21:26:04,506:INFO:Fitting Model
2025-01-17 21:26:12,278:INFO:Visual Rendered Successfully
2025-01-17 21:26:12,352:INFO:plot_model() successfully completed......................................
2025-01-17 21:26:12,356:INFO:Initializing interpret_model()
2025-01-17 21:26:12,356:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x15d76a950>)
2025-01-17 21:26:12,356:INFO:Checking exceptions
2025-01-17 21:26:12,356:INFO:Soft dependency imported: shap: 0.46.0
2025-01-17 21:26:12,821:INFO:plot type: summary
2025-01-17 21:26:12,821:INFO:Creating TreeExplainer
2025-01-17 21:26:12,838:INFO:Compiling shap values
2025-01-17 21:26:15,786:INFO:Visual Rendered Successfully
2025-01-17 21:26:15,786:INFO:interpret_model() successfully completed......................................
2025-01-17 21:32:40,856:ERROR:
'explainerdashboard' is a soft dependency and not included in the pycaret installation. Please run: `pip install explainerdashboard` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-01-19 11:21:35,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-19 11:21:35,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-19 11:21:35,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-19 11:21:35,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-19 11:48:52,461:INFO:PyCaret RegressionExperiment
2025-01-19 11:48:52,462:INFO:Logging name: reg-default-name
2025-01-19 11:48:52,463:INFO:ML Usecase: MLUsecase.REGRESSION
2025-01-19 11:48:52,463:INFO:version 3.3.1
2025-01-19 11:48:52,463:INFO:Initializing setup()
2025-01-19 11:48:52,463:INFO:self.USI: e12b
2025-01-19 11:48:52,463:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'fold_generator', 'target_param', '_ml_usecase', 'html_param', 'X_train', 'exp_id', 'X', 'pipeline', 'USI', 'fold_shuffle_param', 'y', 'y_train', 'transform_target_param', 'gpu_param', 'X_test', 'gpu_n_jobs_param', 'n_jobs_param', 'exp_name_log', 'fold_groups_param', 'logging_param', 'seed', '_available_plots', 'data', 'memory', 'idx'}
2025-01-19 11:48:52,463:INFO:Checking environment
2025-01-19 11:48:52,463:INFO:python_version: 3.10.13
2025-01-19 11:48:52,463:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-19 11:48:52,464:INFO:machine: arm64
2025-01-19 11:48:52,464:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-19 11:48:52,466:INFO:Memory: svmem(total=8589934592, available=1516437504, percent=82.3, used=2950561792, free=63930368, active=1473249280, inactive=1452261376, wired=1477312512)
2025-01-19 11:48:52,467:INFO:Physical Core: 8
2025-01-19 11:48:52,467:INFO:Logical Core: 8
2025-01-19 11:48:52,467:INFO:Checking libraries
2025-01-19 11:48:52,469:INFO:System:
2025-01-19 11:48:52,469:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-19 11:48:52,469:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-19 11:48:52,469:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-19 11:48:52,469:INFO:PyCaret required dependencies:
2025-01-19 11:48:52,681:INFO:                 pip: 24.2
2025-01-19 11:48:52,681:INFO:          setuptools: 75.1.0
2025-01-19 11:48:52,681:INFO:             pycaret: 3.3.1
2025-01-19 11:48:52,681:INFO:             IPython: 8.27.0
2025-01-19 11:48:52,681:INFO:          ipywidgets: 8.1.2
2025-01-19 11:48:52,681:INFO:                tqdm: 4.66.5
2025-01-19 11:48:52,681:INFO:               numpy: 1.26.4
2025-01-19 11:48:52,681:INFO:              pandas: 2.1.4
2025-01-19 11:48:52,681:INFO:              jinja2: 3.1.4
2025-01-19 11:48:52,681:INFO:               scipy: 1.11.4
2025-01-19 11:48:52,681:INFO:              joblib: 1.3.2
2025-01-19 11:48:52,681:INFO:             sklearn: 1.4.2
2025-01-19 11:48:52,681:INFO:                pyod: 2.0.2
2025-01-19 11:48:52,681:INFO:            imblearn: 0.13.0
2025-01-19 11:48:52,681:INFO:   category_encoders: 2.7.0
2025-01-19 11:48:52,681:INFO:            lightgbm: 4.4.0
2025-01-19 11:48:52,681:INFO:               numba: 0.60.0
2025-01-19 11:48:52,681:INFO:            requests: 2.32.3
2025-01-19 11:48:52,681:INFO:          matplotlib: 3.9.2
2025-01-19 11:48:52,682:INFO:          scikitplot: 0.3.7
2025-01-19 11:48:52,682:INFO:         yellowbrick: 1.5
2025-01-19 11:48:52,682:INFO:              plotly: 5.24.1
2025-01-19 11:48:52,682:INFO:    plotly-resampler: Not installed
2025-01-19 11:48:52,682:INFO:             kaleido: 0.2.1
2025-01-19 11:48:52,682:INFO:           schemdraw: 0.15
2025-01-19 11:48:52,682:INFO:         statsmodels: 0.14.4
2025-01-19 11:48:52,682:INFO:              sktime: 0.26.0
2025-01-19 11:48:52,682:INFO:               tbats: 1.1.3
2025-01-19 11:48:52,682:INFO:            pmdarima: 2.0.4
2025-01-19 11:48:52,682:INFO:              psutil: 5.9.0
2025-01-19 11:48:52,682:INFO:          markupsafe: 2.1.3
2025-01-19 11:48:52,682:INFO:             pickle5: Not installed
2025-01-19 11:48:52,682:INFO:         cloudpickle: 3.1.0
2025-01-19 11:48:52,682:INFO:         deprecation: 2.1.0
2025-01-19 11:48:52,682:INFO:              xxhash: 3.5.0
2025-01-19 11:48:52,682:INFO:           wurlitzer: 3.1.1
2025-01-19 11:48:52,682:INFO:PyCaret optional dependencies:
2025-01-19 11:48:52,727:INFO:                shap: 0.46.0
2025-01-19 11:48:52,728:INFO:           interpret: Not installed
2025-01-19 11:48:52,728:INFO:                umap: 0.5.7
2025-01-19 11:48:52,728:INFO:     ydata_profiling: Not installed
2025-01-19 11:48:52,728:INFO:  explainerdashboard: Not installed
2025-01-19 11:48:52,728:INFO:             autoviz: Not installed
2025-01-19 11:48:52,728:INFO:           fairlearn: Not installed
2025-01-19 11:48:52,728:INFO:          deepchecks: Not installed
2025-01-19 11:48:52,728:INFO:             xgboost: 2.1.3
2025-01-19 11:48:52,728:INFO:            catboost: Not installed
2025-01-19 11:48:52,728:INFO:              kmodes: Not installed
2025-01-19 11:48:52,728:INFO:             mlxtend: Not installed
2025-01-19 11:48:52,728:INFO:       statsforecast: Not installed
2025-01-19 11:48:52,728:INFO:        tune_sklearn: Not installed
2025-01-19 11:48:52,728:INFO:                 ray: Not installed
2025-01-19 11:48:52,728:INFO:            hyperopt: Not installed
2025-01-19 11:48:52,728:INFO:              optuna: Not installed
2025-01-19 11:48:52,728:INFO:               skopt: Not installed
2025-01-19 11:48:52,728:INFO:              mlflow: 2.19.0
2025-01-19 11:48:52,728:INFO:              gradio: Not installed
2025-01-19 11:48:52,728:INFO:             fastapi: Not installed
2025-01-19 11:48:52,728:INFO:             uvicorn: Not installed
2025-01-19 11:48:52,728:INFO:              m2cgen: Not installed
2025-01-19 11:48:52,728:INFO:           evidently: Not installed
2025-01-19 11:48:52,728:INFO:               fugue: Not installed
2025-01-19 11:48:52,728:INFO:           streamlit: Not installed
2025-01-19 11:48:52,728:INFO:             prophet: Not installed
2025-01-19 11:48:52,728:INFO:None
2025-01-19 11:48:52,728:INFO:Set up data.
2025-01-19 11:48:52,767:INFO:Set up folding strategy.
2025-01-19 11:48:52,768:INFO:Set up train/test split.
2025-01-19 11:48:52,787:INFO:Set up index.
2025-01-19 11:48:52,788:INFO:Assigning column types.
2025-01-19 11:48:52,795:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-19 11:48:52,796:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,799:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,802:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,883:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:52,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:52,886:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,889:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,892:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,938:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,970:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:52,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:52,972:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-01-19 11:48:52,975:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-19 11:48:52,978:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,057:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,063:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,066:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,116:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,147:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,149:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-01-19 11:48:53,155:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,234:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,242:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,290:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,322:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,324:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-01-19 11:48:53,381:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,415:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,416:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,509:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,511:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-19 11:48:53,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,596:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-19 11:48:53,682:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,684:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-01-19 11:48:53,768:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,854:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:53,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:53,858:INFO:Preparing preprocessing pipeline...
2025-01-19 11:48:53,858:INFO:Set up simple imputation.
2025-01-19 11:48:53,865:INFO:Set up encoding of ordinal features.
2025-01-19 11:48:53,870:INFO:Set up encoding of categorical features.
2025-01-19 11:48:54,068:INFO:Finished creating preprocessing pipeline.
2025-01-19 11:48:54,091:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'loan_status'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 Transfor...
dtype: int64},
                                                                        {'col': 'previous_loan_defaults_on_file',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': No     0
Yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-01-19 11:48:54,091:INFO:Creating final display dataframe.
2025-01-19 11:48:54,465:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      credit_score
2                   Target type        Regression
3           Original data shape       (40479, 14)
4        Transformed data shape       (40479, 26)
5   Transformed train set shape       (28335, 26)
6    Transformed test set shape       (12144, 26)
7              Numeric features                 8
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              e12b
2025-01-19 11:48:54,565:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:54,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:54,656:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-19 11:48:54,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-19 11:48:54,658:INFO:setup() successfully completed in 2.21s...............
2025-01-19 11:50:35,476:INFO:Initializing compare_models()
2025-01-19 11:50:35,478:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-01-19 11:50:35,478:INFO:Checking exceptions
2025-01-19 11:50:35,509:INFO:Preparing display monitor
2025-01-19 11:50:35,675:INFO:Initializing Linear Regression
2025-01-19 11:50:35,676:INFO:Total runtime is 3.846883773803711e-05 minutes
2025-01-19 11:50:35,684:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:35,685:INFO:Initializing create_model()
2025-01-19 11:50:35,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:35,685:INFO:Checking exceptions
2025-01-19 11:50:35,686:INFO:Importing libraries
2025-01-19 11:50:35,686:INFO:Copying training dataset
2025-01-19 11:50:35,741:INFO:Defining folds
2025-01-19 11:50:35,742:INFO:Declaring metric variables
2025-01-19 11:50:35,754:INFO:Importing untrained model
2025-01-19 11:50:35,768:INFO:Linear Regression Imported successfully
2025-01-19 11:50:35,785:INFO:Starting cross validation
2025-01-19 11:50:35,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:42,380:INFO:Calculating mean and std
2025-01-19 11:50:42,383:INFO:Creating metrics dataframe
2025-01-19 11:50:42,390:INFO:Uploading results into container
2025-01-19 11:50:42,391:INFO:Uploading model into container now
2025-01-19 11:50:42,391:INFO:_master_model_container: 1
2025-01-19 11:50:42,391:INFO:_display_container: 2
2025-01-19 11:50:42,392:INFO:LinearRegression(n_jobs=-1)
2025-01-19 11:50:42,392:INFO:create_model() successfully completed......................................
2025-01-19 11:50:42,919:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:42,919:INFO:Creating metrics dataframe
2025-01-19 11:50:42,924:INFO:Initializing Lasso Regression
2025-01-19 11:50:42,924:INFO:Total runtime is 0.12083373467127481 minutes
2025-01-19 11:50:42,926:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:42,926:INFO:Initializing create_model()
2025-01-19 11:50:42,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:42,926:INFO:Checking exceptions
2025-01-19 11:50:42,926:INFO:Importing libraries
2025-01-19 11:50:42,926:INFO:Copying training dataset
2025-01-19 11:50:42,947:INFO:Defining folds
2025-01-19 11:50:42,947:INFO:Declaring metric variables
2025-01-19 11:50:42,951:INFO:Importing untrained model
2025-01-19 11:50:42,954:INFO:Lasso Regression Imported successfully
2025-01-19 11:50:42,961:INFO:Starting cross validation
2025-01-19 11:50:42,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:44,050:INFO:Calculating mean and std
2025-01-19 11:50:44,053:INFO:Creating metrics dataframe
2025-01-19 11:50:44,059:INFO:Uploading results into container
2025-01-19 11:50:44,059:INFO:Uploading model into container now
2025-01-19 11:50:44,060:INFO:_master_model_container: 2
2025-01-19 11:50:44,060:INFO:_display_container: 2
2025-01-19 11:50:44,061:INFO:Lasso(random_state=123)
2025-01-19 11:50:44,061:INFO:create_model() successfully completed......................................
2025-01-19 11:50:44,361:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:44,361:INFO:Creating metrics dataframe
2025-01-19 11:50:44,366:INFO:Initializing Ridge Regression
2025-01-19 11:50:44,366:INFO:Total runtime is 0.14487206935882568 minutes
2025-01-19 11:50:44,368:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:44,368:INFO:Initializing create_model()
2025-01-19 11:50:44,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:44,369:INFO:Checking exceptions
2025-01-19 11:50:44,369:INFO:Importing libraries
2025-01-19 11:50:44,369:INFO:Copying training dataset
2025-01-19 11:50:44,385:INFO:Defining folds
2025-01-19 11:50:44,385:INFO:Declaring metric variables
2025-01-19 11:50:44,388:INFO:Importing untrained model
2025-01-19 11:50:44,391:INFO:Ridge Regression Imported successfully
2025-01-19 11:50:44,396:INFO:Starting cross validation
2025-01-19 11:50:44,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:45,287:INFO:Calculating mean and std
2025-01-19 11:50:45,290:INFO:Creating metrics dataframe
2025-01-19 11:50:45,297:INFO:Uploading results into container
2025-01-19 11:50:45,298:INFO:Uploading model into container now
2025-01-19 11:50:45,299:INFO:_master_model_container: 3
2025-01-19 11:50:45,299:INFO:_display_container: 2
2025-01-19 11:50:45,299:INFO:Ridge(random_state=123)
2025-01-19 11:50:45,299:INFO:create_model() successfully completed......................................
2025-01-19 11:50:45,549:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:45,550:INFO:Creating metrics dataframe
2025-01-19 11:50:45,555:INFO:Initializing Elastic Net
2025-01-19 11:50:45,555:INFO:Total runtime is 0.16468573808670045 minutes
2025-01-19 11:50:45,558:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:45,558:INFO:Initializing create_model()
2025-01-19 11:50:45,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:45,558:INFO:Checking exceptions
2025-01-19 11:50:45,558:INFO:Importing libraries
2025-01-19 11:50:45,558:INFO:Copying training dataset
2025-01-19 11:50:45,572:INFO:Defining folds
2025-01-19 11:50:45,572:INFO:Declaring metric variables
2025-01-19 11:50:45,575:INFO:Importing untrained model
2025-01-19 11:50:45,579:INFO:Elastic Net Imported successfully
2025-01-19 11:50:45,584:INFO:Starting cross validation
2025-01-19 11:50:45,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:46,550:INFO:Calculating mean and std
2025-01-19 11:50:46,551:INFO:Creating metrics dataframe
2025-01-19 11:50:46,553:INFO:Uploading results into container
2025-01-19 11:50:46,553:INFO:Uploading model into container now
2025-01-19 11:50:46,553:INFO:_master_model_container: 4
2025-01-19 11:50:46,554:INFO:_display_container: 2
2025-01-19 11:50:46,554:INFO:ElasticNet(random_state=123)
2025-01-19 11:50:46,554:INFO:create_model() successfully completed......................................
2025-01-19 11:50:46,812:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:46,812:INFO:Creating metrics dataframe
2025-01-19 11:50:46,817:INFO:Initializing Least Angle Regression
2025-01-19 11:50:46,817:INFO:Total runtime is 0.18572822014490764 minutes
2025-01-19 11:50:46,819:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:46,820:INFO:Initializing create_model()
2025-01-19 11:50:46,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:46,820:INFO:Checking exceptions
2025-01-19 11:50:46,820:INFO:Importing libraries
2025-01-19 11:50:46,820:INFO:Copying training dataset
2025-01-19 11:50:46,835:INFO:Defining folds
2025-01-19 11:50:46,835:INFO:Declaring metric variables
2025-01-19 11:50:46,838:INFO:Importing untrained model
2025-01-19 11:50:46,841:INFO:Least Angle Regression Imported successfully
2025-01-19 11:50:46,847:INFO:Starting cross validation
2025-01-19 11:50:46,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:47,639:INFO:Calculating mean and std
2025-01-19 11:50:47,642:INFO:Creating metrics dataframe
2025-01-19 11:50:47,648:INFO:Uploading results into container
2025-01-19 11:50:47,649:INFO:Uploading model into container now
2025-01-19 11:50:47,650:INFO:_master_model_container: 5
2025-01-19 11:50:47,650:INFO:_display_container: 2
2025-01-19 11:50:47,651:INFO:Lars(random_state=123)
2025-01-19 11:50:47,651:INFO:create_model() successfully completed......................................
2025-01-19 11:50:47,923:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:47,923:INFO:Creating metrics dataframe
2025-01-19 11:50:47,929:INFO:Initializing Lasso Least Angle Regression
2025-01-19 11:50:47,929:INFO:Total runtime is 0.2042532722155253 minutes
2025-01-19 11:50:47,931:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:47,931:INFO:Initializing create_model()
2025-01-19 11:50:47,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:47,931:INFO:Checking exceptions
2025-01-19 11:50:47,931:INFO:Importing libraries
2025-01-19 11:50:47,931:INFO:Copying training dataset
2025-01-19 11:50:47,946:INFO:Defining folds
2025-01-19 11:50:47,946:INFO:Declaring metric variables
2025-01-19 11:50:47,949:INFO:Importing untrained model
2025-01-19 11:50:47,952:INFO:Lasso Least Angle Regression Imported successfully
2025-01-19 11:50:47,958:INFO:Starting cross validation
2025-01-19 11:50:47,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:48,750:INFO:Calculating mean and std
2025-01-19 11:50:48,751:INFO:Creating metrics dataframe
2025-01-19 11:50:48,753:INFO:Uploading results into container
2025-01-19 11:50:48,753:INFO:Uploading model into container now
2025-01-19 11:50:48,754:INFO:_master_model_container: 6
2025-01-19 11:50:48,754:INFO:_display_container: 2
2025-01-19 11:50:48,754:INFO:LassoLars(random_state=123)
2025-01-19 11:50:48,754:INFO:create_model() successfully completed......................................
2025-01-19 11:50:49,007:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:49,007:INFO:Creating metrics dataframe
2025-01-19 11:50:49,012:INFO:Initializing Orthogonal Matching Pursuit
2025-01-19 11:50:49,013:INFO:Total runtime is 0.22231506903966267 minutes
2025-01-19 11:50:49,015:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:49,015:INFO:Initializing create_model()
2025-01-19 11:50:49,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:49,015:INFO:Checking exceptions
2025-01-19 11:50:49,015:INFO:Importing libraries
2025-01-19 11:50:49,015:INFO:Copying training dataset
2025-01-19 11:50:49,029:INFO:Defining folds
2025-01-19 11:50:49,029:INFO:Declaring metric variables
2025-01-19 11:50:49,032:INFO:Importing untrained model
2025-01-19 11:50:49,035:INFO:Orthogonal Matching Pursuit Imported successfully
2025-01-19 11:50:49,041:INFO:Starting cross validation
2025-01-19 11:50:49,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:49,841:INFO:Calculating mean and std
2025-01-19 11:50:49,844:INFO:Creating metrics dataframe
2025-01-19 11:50:49,848:INFO:Uploading results into container
2025-01-19 11:50:49,848:INFO:Uploading model into container now
2025-01-19 11:50:49,849:INFO:_master_model_container: 7
2025-01-19 11:50:49,849:INFO:_display_container: 2
2025-01-19 11:50:49,851:INFO:OrthogonalMatchingPursuit()
2025-01-19 11:50:49,851:INFO:create_model() successfully completed......................................
2025-01-19 11:50:50,130:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:50,130:INFO:Creating metrics dataframe
2025-01-19 11:50:50,136:INFO:Initializing Bayesian Ridge
2025-01-19 11:50:50,136:INFO:Total runtime is 0.24103415409723916 minutes
2025-01-19 11:50:50,138:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:50,138:INFO:Initializing create_model()
2025-01-19 11:50:50,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:50,138:INFO:Checking exceptions
2025-01-19 11:50:50,138:INFO:Importing libraries
2025-01-19 11:50:50,138:INFO:Copying training dataset
2025-01-19 11:50:50,152:INFO:Defining folds
2025-01-19 11:50:50,152:INFO:Declaring metric variables
2025-01-19 11:50:50,154:INFO:Importing untrained model
2025-01-19 11:50:50,157:INFO:Bayesian Ridge Imported successfully
2025-01-19 11:50:50,163:INFO:Starting cross validation
2025-01-19 11:50:50,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:51,069:INFO:Calculating mean and std
2025-01-19 11:50:51,070:INFO:Creating metrics dataframe
2025-01-19 11:50:51,071:INFO:Uploading results into container
2025-01-19 11:50:51,072:INFO:Uploading model into container now
2025-01-19 11:50:51,072:INFO:_master_model_container: 8
2025-01-19 11:50:51,072:INFO:_display_container: 2
2025-01-19 11:50:51,073:INFO:BayesianRidge()
2025-01-19 11:50:51,073:INFO:create_model() successfully completed......................................
2025-01-19 11:50:51,354:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:51,354:INFO:Creating metrics dataframe
2025-01-19 11:50:51,360:INFO:Initializing Passive Aggressive Regressor
2025-01-19 11:50:51,361:INFO:Total runtime is 0.2614486853281657 minutes
2025-01-19 11:50:51,363:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:51,363:INFO:Initializing create_model()
2025-01-19 11:50:51,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:51,364:INFO:Checking exceptions
2025-01-19 11:50:51,364:INFO:Importing libraries
2025-01-19 11:50:51,364:INFO:Copying training dataset
2025-01-19 11:50:51,379:INFO:Defining folds
2025-01-19 11:50:51,379:INFO:Declaring metric variables
2025-01-19 11:50:51,381:INFO:Importing untrained model
2025-01-19 11:50:51,384:INFO:Passive Aggressive Regressor Imported successfully
2025-01-19 11:50:51,388:INFO:Starting cross validation
2025-01-19 11:50:51,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:52,695:INFO:Calculating mean and std
2025-01-19 11:50:52,698:INFO:Creating metrics dataframe
2025-01-19 11:50:52,701:INFO:Uploading results into container
2025-01-19 11:50:52,702:INFO:Uploading model into container now
2025-01-19 11:50:52,703:INFO:_master_model_container: 9
2025-01-19 11:50:52,703:INFO:_display_container: 2
2025-01-19 11:50:52,704:INFO:PassiveAggressiveRegressor(random_state=123)
2025-01-19 11:50:52,704:INFO:create_model() successfully completed......................................
2025-01-19 11:50:53,011:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:53,011:INFO:Creating metrics dataframe
2025-01-19 11:50:53,018:INFO:Initializing Huber Regressor
2025-01-19 11:50:53,018:INFO:Total runtime is 0.2890665014584859 minutes
2025-01-19 11:50:53,020:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:53,020:INFO:Initializing create_model()
2025-01-19 11:50:53,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:53,020:INFO:Checking exceptions
2025-01-19 11:50:53,020:INFO:Importing libraries
2025-01-19 11:50:53,020:INFO:Copying training dataset
2025-01-19 11:50:53,033:INFO:Defining folds
2025-01-19 11:50:53,034:INFO:Declaring metric variables
2025-01-19 11:50:53,036:INFO:Importing untrained model
2025-01-19 11:50:53,039:INFO:Huber Regressor Imported successfully
2025-01-19 11:50:53,045:INFO:Starting cross validation
2025-01-19 11:50:53,048:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:54,688:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-19 11:50:55,121:INFO:Calculating mean and std
2025-01-19 11:50:55,123:INFO:Creating metrics dataframe
2025-01-19 11:50:55,128:INFO:Uploading results into container
2025-01-19 11:50:55,128:INFO:Uploading model into container now
2025-01-19 11:50:55,129:INFO:_master_model_container: 10
2025-01-19 11:50:55,129:INFO:_display_container: 2
2025-01-19 11:50:55,130:INFO:HuberRegressor()
2025-01-19 11:50:55,130:INFO:create_model() successfully completed......................................
2025-01-19 11:50:55,392:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:55,392:INFO:Creating metrics dataframe
2025-01-19 11:50:55,399:INFO:Initializing K Neighbors Regressor
2025-01-19 11:50:55,399:INFO:Total runtime is 0.3287511030832926 minutes
2025-01-19 11:50:55,401:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:55,401:INFO:Initializing create_model()
2025-01-19 11:50:55,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:55,401:INFO:Checking exceptions
2025-01-19 11:50:55,401:INFO:Importing libraries
2025-01-19 11:50:55,402:INFO:Copying training dataset
2025-01-19 11:50:55,419:INFO:Defining folds
2025-01-19 11:50:55,420:INFO:Declaring metric variables
2025-01-19 11:50:55,423:INFO:Importing untrained model
2025-01-19 11:50:55,427:INFO:K Neighbors Regressor Imported successfully
2025-01-19 11:50:55,432:INFO:Starting cross validation
2025-01-19 11:50:55,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:57,419:INFO:Calculating mean and std
2025-01-19 11:50:57,420:INFO:Creating metrics dataframe
2025-01-19 11:50:57,421:INFO:Uploading results into container
2025-01-19 11:50:57,422:INFO:Uploading model into container now
2025-01-19 11:50:57,422:INFO:_master_model_container: 11
2025-01-19 11:50:57,422:INFO:_display_container: 2
2025-01-19 11:50:57,423:INFO:KNeighborsRegressor(n_jobs=-1)
2025-01-19 11:50:57,423:INFO:create_model() successfully completed......................................
2025-01-19 11:50:57,650:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:57,650:INFO:Creating metrics dataframe
2025-01-19 11:50:57,656:INFO:Initializing Decision Tree Regressor
2025-01-19 11:50:57,656:INFO:Total runtime is 0.36637891928354893 minutes
2025-01-19 11:50:57,658:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:57,659:INFO:Initializing create_model()
2025-01-19 11:50:57,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:57,659:INFO:Checking exceptions
2025-01-19 11:50:57,659:INFO:Importing libraries
2025-01-19 11:50:57,659:INFO:Copying training dataset
2025-01-19 11:50:57,672:INFO:Defining folds
2025-01-19 11:50:57,672:INFO:Declaring metric variables
2025-01-19 11:50:57,676:INFO:Importing untrained model
2025-01-19 11:50:57,679:INFO:Decision Tree Regressor Imported successfully
2025-01-19 11:50:57,777:INFO:Starting cross validation
2025-01-19 11:50:57,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:50:59,354:INFO:Calculating mean and std
2025-01-19 11:50:59,355:INFO:Creating metrics dataframe
2025-01-19 11:50:59,357:INFO:Uploading results into container
2025-01-19 11:50:59,358:INFO:Uploading model into container now
2025-01-19 11:50:59,358:INFO:_master_model_container: 12
2025-01-19 11:50:59,358:INFO:_display_container: 2
2025-01-19 11:50:59,359:INFO:DecisionTreeRegressor(random_state=123)
2025-01-19 11:50:59,359:INFO:create_model() successfully completed......................................
2025-01-19 11:50:59,678:INFO:SubProcess create_model() end ==================================
2025-01-19 11:50:59,678:INFO:Creating metrics dataframe
2025-01-19 11:50:59,685:INFO:Initializing Random Forest Regressor
2025-01-19 11:50:59,685:INFO:Total runtime is 0.4001906355222066 minutes
2025-01-19 11:50:59,687:INFO:SubProcess create_model() called ==================================
2025-01-19 11:50:59,687:INFO:Initializing create_model()
2025-01-19 11:50:59,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:50:59,687:INFO:Checking exceptions
2025-01-19 11:50:59,688:INFO:Importing libraries
2025-01-19 11:50:59,688:INFO:Copying training dataset
2025-01-19 11:50:59,702:INFO:Defining folds
2025-01-19 11:50:59,702:INFO:Declaring metric variables
2025-01-19 11:50:59,705:INFO:Importing untrained model
2025-01-19 11:50:59,708:INFO:Random Forest Regressor Imported successfully
2025-01-19 11:50:59,713:INFO:Starting cross validation
2025-01-19 11:50:59,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:51:40,063:INFO:Calculating mean and std
2025-01-19 11:51:40,067:INFO:Creating metrics dataframe
2025-01-19 11:51:40,074:INFO:Uploading results into container
2025-01-19 11:51:40,075:INFO:Uploading model into container now
2025-01-19 11:51:40,076:INFO:_master_model_container: 13
2025-01-19 11:51:40,076:INFO:_display_container: 2
2025-01-19 11:51:40,077:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-01-19 11:51:40,077:INFO:create_model() successfully completed......................................
2025-01-19 11:51:40,422:INFO:SubProcess create_model() end ==================================
2025-01-19 11:51:40,422:INFO:Creating metrics dataframe
2025-01-19 11:51:40,429:INFO:Initializing Extra Trees Regressor
2025-01-19 11:51:40,429:INFO:Total runtime is 1.079258652528127 minutes
2025-01-19 11:51:40,432:INFO:SubProcess create_model() called ==================================
2025-01-19 11:51:40,432:INFO:Initializing create_model()
2025-01-19 11:51:40,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:51:40,433:INFO:Checking exceptions
2025-01-19 11:51:40,433:INFO:Importing libraries
2025-01-19 11:51:40,433:INFO:Copying training dataset
2025-01-19 11:51:40,453:INFO:Defining folds
2025-01-19 11:51:40,453:INFO:Declaring metric variables
2025-01-19 11:51:40,459:INFO:Importing untrained model
2025-01-19 11:51:40,469:INFO:Extra Trees Regressor Imported successfully
2025-01-19 11:51:40,476:INFO:Starting cross validation
2025-01-19 11:51:40,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:52:05,322:INFO:Calculating mean and std
2025-01-19 11:52:05,327:INFO:Creating metrics dataframe
2025-01-19 11:52:05,335:INFO:Uploading results into container
2025-01-19 11:52:05,336:INFO:Uploading model into container now
2025-01-19 11:52:05,337:INFO:_master_model_container: 14
2025-01-19 11:52:05,337:INFO:_display_container: 2
2025-01-19 11:52:05,338:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-01-19 11:52:05,338:INFO:create_model() successfully completed......................................
2025-01-19 11:52:05,708:INFO:SubProcess create_model() end ==================================
2025-01-19 11:52:05,708:INFO:Creating metrics dataframe
2025-01-19 11:52:05,716:INFO:Initializing AdaBoost Regressor
2025-01-19 11:52:05,716:INFO:Total runtime is 1.500701634089152 minutes
2025-01-19 11:52:05,718:INFO:SubProcess create_model() called ==================================
2025-01-19 11:52:05,718:INFO:Initializing create_model()
2025-01-19 11:52:05,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:52:05,719:INFO:Checking exceptions
2025-01-19 11:52:05,719:INFO:Importing libraries
2025-01-19 11:52:05,719:INFO:Copying training dataset
2025-01-19 11:52:05,748:INFO:Defining folds
2025-01-19 11:52:05,749:INFO:Declaring metric variables
2025-01-19 11:52:05,753:INFO:Importing untrained model
2025-01-19 11:52:05,764:INFO:AdaBoost Regressor Imported successfully
2025-01-19 11:52:05,777:INFO:Starting cross validation
2025-01-19 11:52:05,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:52:06,437:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2025-01-19 11:52:10,900:INFO:Calculating mean and std
2025-01-19 11:52:10,902:INFO:Creating metrics dataframe
2025-01-19 11:52:10,904:INFO:Uploading results into container
2025-01-19 11:52:10,905:INFO:Uploading model into container now
2025-01-19 11:52:10,905:INFO:_master_model_container: 15
2025-01-19 11:52:10,905:INFO:_display_container: 2
2025-01-19 11:52:10,906:INFO:AdaBoostRegressor(random_state=123)
2025-01-19 11:52:10,906:INFO:create_model() successfully completed......................................
2025-01-19 11:52:11,134:INFO:SubProcess create_model() end ==================================
2025-01-19 11:52:11,136:INFO:Creating metrics dataframe
2025-01-19 11:52:11,143:INFO:Initializing Gradient Boosting Regressor
2025-01-19 11:52:11,143:INFO:Total runtime is 1.5911601503690083 minutes
2025-01-19 11:52:11,145:INFO:SubProcess create_model() called ==================================
2025-01-19 11:52:11,146:INFO:Initializing create_model()
2025-01-19 11:52:11,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:52:11,146:INFO:Checking exceptions
2025-01-19 11:52:11,146:INFO:Importing libraries
2025-01-19 11:52:11,146:INFO:Copying training dataset
2025-01-19 11:52:11,159:INFO:Defining folds
2025-01-19 11:52:11,159:INFO:Declaring metric variables
2025-01-19 11:52:11,163:INFO:Importing untrained model
2025-01-19 11:52:11,166:INFO:Gradient Boosting Regressor Imported successfully
2025-01-19 11:52:11,172:INFO:Starting cross validation
2025-01-19 11:52:11,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:52:23,396:INFO:Calculating mean and std
2025-01-19 11:52:23,398:INFO:Creating metrics dataframe
2025-01-19 11:52:23,399:INFO:Uploading results into container
2025-01-19 11:52:23,399:INFO:Uploading model into container now
2025-01-19 11:52:23,400:INFO:_master_model_container: 16
2025-01-19 11:52:23,400:INFO:_display_container: 2
2025-01-19 11:52:23,400:INFO:GradientBoostingRegressor(random_state=123)
2025-01-19 11:52:23,400:INFO:create_model() successfully completed......................................
2025-01-19 11:52:23,628:INFO:SubProcess create_model() end ==================================
2025-01-19 11:52:23,628:INFO:Creating metrics dataframe
2025-01-19 11:52:23,636:INFO:Initializing Extreme Gradient Boosting
2025-01-19 11:52:23,636:INFO:Total runtime is 1.799367868900299 minutes
2025-01-19 11:52:23,638:INFO:SubProcess create_model() called ==================================
2025-01-19 11:52:23,638:INFO:Initializing create_model()
2025-01-19 11:52:23,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:52:23,638:INFO:Checking exceptions
2025-01-19 11:52:23,638:INFO:Importing libraries
2025-01-19 11:52:23,638:INFO:Copying training dataset
2025-01-19 11:52:23,653:INFO:Defining folds
2025-01-19 11:52:23,654:INFO:Declaring metric variables
2025-01-19 11:52:23,657:INFO:Importing untrained model
2025-01-19 11:52:23,661:INFO:Extreme Gradient Boosting Imported successfully
2025-01-19 11:52:23,666:INFO:Starting cross validation
2025-01-19 11:52:23,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:52:25,465:INFO:Calculating mean and std
2025-01-19 11:52:25,466:INFO:Creating metrics dataframe
2025-01-19 11:52:25,467:INFO:Uploading results into container
2025-01-19 11:52:25,468:INFO:Uploading model into container now
2025-01-19 11:52:25,468:INFO:_master_model_container: 17
2025-01-19 11:52:25,468:INFO:_display_container: 2
2025-01-19 11:52:25,469:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2025-01-19 11:52:25,469:INFO:create_model() successfully completed......................................
2025-01-19 11:52:25,670:INFO:SubProcess create_model() end ==================================
2025-01-19 11:52:25,670:INFO:Creating metrics dataframe
2025-01-19 11:52:25,678:INFO:Initializing Light Gradient Boosting Machine
2025-01-19 11:52:25,678:INFO:Total runtime is 1.8334050178527832 minutes
2025-01-19 11:52:25,680:INFO:SubProcess create_model() called ==================================
2025-01-19 11:52:25,681:INFO:Initializing create_model()
2025-01-19 11:52:25,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:52:25,681:INFO:Checking exceptions
2025-01-19 11:52:25,681:INFO:Importing libraries
2025-01-19 11:52:25,681:INFO:Copying training dataset
2025-01-19 11:52:25,693:INFO:Defining folds
2025-01-19 11:52:25,693:INFO:Declaring metric variables
2025-01-19 11:52:25,697:INFO:Importing untrained model
2025-01-19 11:52:25,700:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-19 11:52:25,706:INFO:Starting cross validation
2025-01-19 11:52:25,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:52:30,040:INFO:Calculating mean and std
2025-01-19 11:52:30,041:INFO:Creating metrics dataframe
2025-01-19 11:52:30,042:INFO:Uploading results into container
2025-01-19 11:52:30,042:INFO:Uploading model into container now
2025-01-19 11:52:30,043:INFO:_master_model_container: 18
2025-01-19 11:52:30,043:INFO:_display_container: 2
2025-01-19 11:52:30,043:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-01-19 11:52:30,043:INFO:create_model() successfully completed......................................
2025-01-19 11:52:30,246:INFO:SubProcess create_model() end ==================================
2025-01-19 11:52:30,246:INFO:Creating metrics dataframe
2025-01-19 11:52:30,254:INFO:Initializing Dummy Regressor
2025-01-19 11:52:30,254:INFO:Total runtime is 1.9096762180328368 minutes
2025-01-19 11:52:30,256:INFO:SubProcess create_model() called ==================================
2025-01-19 11:52:30,257:INFO:Initializing create_model()
2025-01-19 11:52:30,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30a15ef50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:52:30,257:INFO:Checking exceptions
2025-01-19 11:52:30,257:INFO:Importing libraries
2025-01-19 11:52:30,257:INFO:Copying training dataset
2025-01-19 11:52:30,272:INFO:Defining folds
2025-01-19 11:52:30,272:INFO:Declaring metric variables
2025-01-19 11:52:30,275:INFO:Importing untrained model
2025-01-19 11:52:30,278:INFO:Dummy Regressor Imported successfully
2025-01-19 11:52:30,282:INFO:Starting cross validation
2025-01-19 11:52:30,284:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 11:52:31,226:INFO:Calculating mean and std
2025-01-19 11:52:31,227:INFO:Creating metrics dataframe
2025-01-19 11:52:31,229:INFO:Uploading results into container
2025-01-19 11:52:31,229:INFO:Uploading model into container now
2025-01-19 11:52:31,230:INFO:_master_model_container: 19
2025-01-19 11:52:31,230:INFO:_display_container: 2
2025-01-19 11:52:31,230:INFO:DummyRegressor()
2025-01-19 11:52:31,230:INFO:create_model() successfully completed......................................
2025-01-19 11:52:31,457:INFO:SubProcess create_model() end ==================================
2025-01-19 11:52:31,457:INFO:Creating metrics dataframe
2025-01-19 11:52:31,468:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-19 11:52:31,472:INFO:Initializing create_model()
2025-01-19 11:52:31,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 11:52:31,473:INFO:Checking exceptions
2025-01-19 11:52:31,474:INFO:Importing libraries
2025-01-19 11:52:31,474:INFO:Copying training dataset
2025-01-19 11:52:31,487:INFO:Defining folds
2025-01-19 11:52:31,487:INFO:Declaring metric variables
2025-01-19 11:52:31,487:INFO:Importing untrained model
2025-01-19 11:52:31,487:INFO:Declaring custom model
2025-01-19 11:52:31,487:INFO:Linear Regression Imported successfully
2025-01-19 11:52:31,488:INFO:Cross validation set to False
2025-01-19 11:52:31,489:INFO:Fitting Model
2025-01-19 11:52:31,674:INFO:LinearRegression(n_jobs=-1)
2025-01-19 11:52:31,674:INFO:create_model() successfully completed......................................
2025-01-19 11:52:31,898:INFO:_master_model_container: 19
2025-01-19 11:52:31,898:INFO:_display_container: 2
2025-01-19 11:52:31,898:INFO:LinearRegression(n_jobs=-1)
2025-01-19 11:52:31,898:INFO:compare_models() successfully completed......................................
2025-01-19 12:00:15,515:INFO:Initializing create_model()
2025-01-19 12:00:15,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 12:00:15,517:INFO:Checking exceptions
2025-01-19 12:00:15,548:INFO:Importing libraries
2025-01-19 12:00:15,548:INFO:Copying training dataset
2025-01-19 12:00:15,579:INFO:Defining folds
2025-01-19 12:00:15,579:INFO:Declaring metric variables
2025-01-19 12:00:15,583:INFO:Importing untrained model
2025-01-19 12:00:15,590:INFO:Linear Regression Imported successfully
2025-01-19 12:00:15,600:INFO:Starting cross validation
2025-01-19 12:00:15,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 12:00:21,129:INFO:Calculating mean and std
2025-01-19 12:00:21,133:INFO:Creating metrics dataframe
2025-01-19 12:00:21,141:INFO:Finalizing model
2025-01-19 12:00:21,353:INFO:Uploading results into container
2025-01-19 12:00:21,354:INFO:Uploading model into container now
2025-01-19 12:00:21,361:INFO:_master_model_container: 20
2025-01-19 12:00:21,362:INFO:_display_container: 3
2025-01-19 12:00:21,362:INFO:LinearRegression(n_jobs=-1)
2025-01-19 12:00:21,362:INFO:create_model() successfully completed......................................
2025-01-19 12:03:07,630:INFO:Initializing create_model()
2025-01-19 12:03:07,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 12:03:07,632:INFO:Checking exceptions
2025-01-19 12:03:07,671:INFO:Importing libraries
2025-01-19 12:03:07,671:INFO:Copying training dataset
2025-01-19 12:03:07,702:INFO:Defining folds
2025-01-19 12:03:07,702:INFO:Declaring metric variables
2025-01-19 12:03:07,705:INFO:Importing untrained model
2025-01-19 12:03:07,708:INFO:Linear Regression Imported successfully
2025-01-19 12:03:07,716:INFO:Starting cross validation
2025-01-19 12:03:07,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 12:03:08,528:INFO:Calculating mean and std
2025-01-19 12:03:08,528:INFO:Creating metrics dataframe
2025-01-19 12:03:08,532:INFO:Finalizing model
2025-01-19 12:03:08,738:INFO:Uploading results into container
2025-01-19 12:03:08,739:INFO:Uploading model into container now
2025-01-19 12:03:08,745:INFO:_master_model_container: 21
2025-01-19 12:03:08,745:INFO:_display_container: 4
2025-01-19 12:03:08,745:INFO:LinearRegression(n_jobs=-1)
2025-01-19 12:03:08,746:INFO:create_model() successfully completed......................................
2025-01-19 12:04:36,148:INFO:Initializing create_model()
2025-01-19 12:04:36,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 12:04:36,150:INFO:Checking exceptions
2025-01-19 12:04:36,185:INFO:Importing libraries
2025-01-19 12:04:36,185:INFO:Copying training dataset
2025-01-19 12:04:36,276:INFO:Defining folds
2025-01-19 12:04:36,276:INFO:Declaring metric variables
2025-01-19 12:04:36,278:INFO:Importing untrained model
2025-01-19 12:04:36,280:INFO:Decision Tree Regressor Imported successfully
2025-01-19 12:04:36,283:INFO:Starting cross validation
2025-01-19 12:04:36,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 12:04:37,332:INFO:Calculating mean and std
2025-01-19 12:04:37,333:INFO:Creating metrics dataframe
2025-01-19 12:04:37,335:INFO:Finalizing model
2025-01-19 12:04:37,671:INFO:Uploading results into container
2025-01-19 12:04:37,672:INFO:Uploading model into container now
2025-01-19 12:04:37,676:INFO:_master_model_container: 22
2025-01-19 12:04:37,676:INFO:_display_container: 5
2025-01-19 12:04:37,677:INFO:DecisionTreeRegressor(random_state=123)
2025-01-19 12:04:37,677:INFO:create_model() successfully completed......................................
2025-01-19 12:06:10,171:INFO:Initializing tune_model()
2025-01-19 12:06:10,172:INFO:tune_model(estimator=lr, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>)
2025-01-19 12:06:10,173:INFO:Checking exceptions
2025-01-19 12:07:31,428:INFO:Initializing tune_model()
2025-01-19 12:07:31,446:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>)
2025-01-19 12:07:31,448:INFO:Checking exceptions
2025-01-19 12:07:31,528:INFO:Copying training dataset
2025-01-19 12:07:31,538:INFO:Checking base model
2025-01-19 12:07:31,539:INFO:Base model : Linear Regression
2025-01-19 12:07:31,542:INFO:Declaring metric variables
2025-01-19 12:07:31,543:INFO:Defining Hyperparameters
2025-01-19 12:07:31,544:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-01-19 12:07:31,939:INFO:Tuning with n_jobs=-1
2025-01-19 12:07:31,939:INFO:Initializing GridSearchCV
2025-01-19 12:07:33,378:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-01-19 12:07:33,380:INFO:Hyperparameter search completed
2025-01-19 12:07:33,380:INFO:SubProcess create_model() called ==================================
2025-01-19 12:07:33,381:INFO:Initializing create_model()
2025-01-19 12:07:33,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17afa58d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-01-19 12:07:33,381:INFO:Checking exceptions
2025-01-19 12:07:33,381:INFO:Importing libraries
2025-01-19 12:07:33,381:INFO:Copying training dataset
2025-01-19 12:07:33,394:INFO:Defining folds
2025-01-19 12:07:33,394:INFO:Declaring metric variables
2025-01-19 12:07:33,398:INFO:Importing untrained model
2025-01-19 12:07:33,398:INFO:Declaring custom model
2025-01-19 12:07:33,401:INFO:Linear Regression Imported successfully
2025-01-19 12:07:33,407:INFO:Starting cross validation
2025-01-19 12:07:33,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 12:07:34,003:INFO:Calculating mean and std
2025-01-19 12:07:34,004:INFO:Creating metrics dataframe
2025-01-19 12:07:34,007:INFO:Finalizing model
2025-01-19 12:07:34,166:INFO:Uploading results into container
2025-01-19 12:07:34,167:INFO:Uploading model into container now
2025-01-19 12:07:34,167:INFO:_master_model_container: 23
2025-01-19 12:07:34,167:INFO:_display_container: 6
2025-01-19 12:07:34,168:INFO:LinearRegression(n_jobs=-1)
2025-01-19 12:07:34,168:INFO:create_model() successfully completed......................................
2025-01-19 12:07:34,485:INFO:SubProcess create_model() end ==================================
2025-01-19 12:07:34,485:INFO:choose_better activated
2025-01-19 12:07:34,487:INFO:SubProcess create_model() called ==================================
2025-01-19 12:07:34,487:INFO:Initializing create_model()
2025-01-19 12:07:34,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 12:07:34,487:INFO:Checking exceptions
2025-01-19 12:07:34,488:INFO:Importing libraries
2025-01-19 12:07:34,488:INFO:Copying training dataset
2025-01-19 12:07:34,496:INFO:Defining folds
2025-01-19 12:07:34,496:INFO:Declaring metric variables
2025-01-19 12:07:34,497:INFO:Importing untrained model
2025-01-19 12:07:34,497:INFO:Declaring custom model
2025-01-19 12:07:34,497:INFO:Linear Regression Imported successfully
2025-01-19 12:07:34,497:INFO:Starting cross validation
2025-01-19 12:07:34,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 12:07:35,115:INFO:Calculating mean and std
2025-01-19 12:07:35,115:INFO:Creating metrics dataframe
2025-01-19 12:07:35,117:INFO:Finalizing model
2025-01-19 12:07:35,236:INFO:Uploading results into container
2025-01-19 12:07:35,237:INFO:Uploading model into container now
2025-01-19 12:07:35,237:INFO:_master_model_container: 24
2025-01-19 12:07:35,237:INFO:_display_container: 7
2025-01-19 12:07:35,237:INFO:LinearRegression(n_jobs=-1)
2025-01-19 12:07:35,237:INFO:create_model() successfully completed......................................
2025-01-19 12:07:35,451:INFO:SubProcess create_model() end ==================================
2025-01-19 12:07:35,451:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.1173
2025-01-19 12:07:35,451:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.1173
2025-01-19 12:07:35,451:INFO:LinearRegression(n_jobs=-1) is best model
2025-01-19 12:07:35,451:INFO:choose_better completed
2025-01-19 12:07:35,451:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-01-19 12:07:35,458:INFO:_master_model_container: 24
2025-01-19 12:07:35,458:INFO:_display_container: 6
2025-01-19 12:07:35,459:INFO:LinearRegression(n_jobs=-1)
2025-01-19 12:07:35,459:INFO:tune_model() successfully completed......................................
2025-01-19 12:10:00,273:INFO:Initializing tune_model()
2025-01-19 12:10:00,274:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>)
2025-01-19 12:10:00,275:INFO:Checking exceptions
2025-01-19 12:10:00,316:INFO:Copying training dataset
2025-01-19 12:10:00,333:INFO:Checking base model
2025-01-19 12:10:00,334:INFO:Base model : Decision Tree Regressor
2025-01-19 12:10:00,338:INFO:Declaring metric variables
2025-01-19 12:10:00,346:INFO:Defining Hyperparameters
2025-01-19 12:10:00,658:INFO:Tuning with n_jobs=-1
2025-01-19 12:10:00,659:INFO:Initializing RandomizedSearchCV
2025-01-19 12:11:14,025:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'absolute_error'}
2025-01-19 12:11:14,029:INFO:Hyperparameter search completed
2025-01-19 12:11:14,030:INFO:SubProcess create_model() called ==================================
2025-01-19 12:11:14,031:INFO:Initializing create_model()
2025-01-19 12:11:14,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30bb14b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 6, 'criterion': 'absolute_error'})
2025-01-19 12:11:14,031:INFO:Checking exceptions
2025-01-19 12:11:14,031:INFO:Importing libraries
2025-01-19 12:11:14,031:INFO:Copying training dataset
2025-01-19 12:11:14,044:INFO:Defining folds
2025-01-19 12:11:14,045:INFO:Declaring metric variables
2025-01-19 12:11:14,047:INFO:Importing untrained model
2025-01-19 12:11:14,047:INFO:Declaring custom model
2025-01-19 12:11:14,051:INFO:Decision Tree Regressor Imported successfully
2025-01-19 12:11:14,055:INFO:Starting cross validation
2025-01-19 12:11:14,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 12:12:10,386:INFO:Calculating mean and std
2025-01-19 12:12:10,393:INFO:Creating metrics dataframe
2025-01-19 12:12:10,398:INFO:Finalizing model
2025-01-19 12:12:36,047:INFO:Uploading results into container
2025-01-19 12:12:36,048:INFO:Uploading model into container now
2025-01-19 12:12:36,049:INFO:_master_model_container: 25
2025-01-19 12:12:36,049:INFO:_display_container: 7
2025-01-19 12:12:36,049:INFO:DecisionTreeRegressor(criterion='absolute_error', max_depth=6, max_features=1.0,
                      min_impurity_decrease=0.002, min_samples_leaf=5,
                      min_samples_split=5, random_state=123)
2025-01-19 12:12:36,049:INFO:create_model() successfully completed......................................
2025-01-19 12:12:36,380:INFO:SubProcess create_model() end ==================================
2025-01-19 12:12:36,380:INFO:choose_better activated
2025-01-19 12:12:36,382:INFO:SubProcess create_model() called ==================================
2025-01-19 12:12:36,382:INFO:Initializing create_model()
2025-01-19 12:12:36,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 12:12:36,382:INFO:Checking exceptions
2025-01-19 12:12:36,383:INFO:Importing libraries
2025-01-19 12:12:36,383:INFO:Copying training dataset
2025-01-19 12:12:36,392:INFO:Defining folds
2025-01-19 12:12:36,392:INFO:Declaring metric variables
2025-01-19 12:12:36,392:INFO:Importing untrained model
2025-01-19 12:12:36,392:INFO:Declaring custom model
2025-01-19 12:12:36,393:INFO:Decision Tree Regressor Imported successfully
2025-01-19 12:12:36,393:INFO:Starting cross validation
2025-01-19 12:12:36,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-19 12:12:37,356:INFO:Calculating mean and std
2025-01-19 12:12:37,356:INFO:Creating metrics dataframe
2025-01-19 12:12:37,358:INFO:Finalizing model
2025-01-19 12:12:37,678:INFO:Uploading results into container
2025-01-19 12:12:37,679:INFO:Uploading model into container now
2025-01-19 12:12:37,679:INFO:_master_model_container: 26
2025-01-19 12:12:37,679:INFO:_display_container: 8
2025-01-19 12:12:37,679:INFO:DecisionTreeRegressor(random_state=123)
2025-01-19 12:12:37,679:INFO:create_model() successfully completed......................................
2025-01-19 12:12:37,865:INFO:SubProcess create_model() end ==================================
2025-01-19 12:12:37,865:INFO:DecisionTreeRegressor(random_state=123) result for R2 is -0.8537
2025-01-19 12:12:37,866:INFO:DecisionTreeRegressor(criterion='absolute_error', max_depth=6, max_features=1.0,
                      min_impurity_decrease=0.002, min_samples_leaf=5,
                      min_samples_split=5, random_state=123) result for R2 is 0.0779
2025-01-19 12:12:37,866:INFO:DecisionTreeRegressor(criterion='absolute_error', max_depth=6, max_features=1.0,
                      min_impurity_decrease=0.002, min_samples_leaf=5,
                      min_samples_split=5, random_state=123) is best model
2025-01-19 12:12:37,866:INFO:choose_better completed
2025-01-19 12:12:37,870:INFO:_master_model_container: 26
2025-01-19 12:12:37,870:INFO:_display_container: 7
2025-01-19 12:12:37,871:INFO:DecisionTreeRegressor(criterion='absolute_error', max_depth=6, max_features=1.0,
                      min_impurity_decrease=0.002, min_samples_leaf=5,
                      min_samples_split=5, random_state=123)
2025-01-19 12:12:37,871:INFO:tune_model() successfully completed......................................
2025-01-19 12:14:52,199:INFO:Initializing save_model()
2025-01-19 12:14:52,200:INFO:save_model(model=DecisionTreeRegressor(criterion='absolute_error', max_depth=6, max_features=1.0,
                      min_impurity_decrease=0.002, min_samples_leaf=5,
                      min_samples_split=5, random_state=123), model_name=Decision tree to predict credit score, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'loan_status'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 Transfor...
dtype: int64},
                                                                        {'col': 'previous_loan_defaults_on_file',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': No     0
Yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-01-19 12:14:52,200:INFO:Adding model into prep_pipe
2025-01-19 12:14:52,218:INFO:Decision tree to predict credit score.pkl saved in current working directory
2025-01-19 12:14:52,238:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'loan_status'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['person_gender',
                                             'person_education',...
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 DecisionTreeRegressor(criterion='absolute_error', max_depth=6,
                                       max_features=1.0,
                                       min_impurity_decrease=0.002,
                                       min_samples_leaf=5, min_samples_split=5,
                                       random_state=123))])
2025-01-19 12:14:52,238:INFO:save_model() successfully completed......................................
2025-01-19 12:16:05,854:INFO:Initializing finalize_model()
2025-01-19 12:16:05,856:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=DecisionTreeRegressor(criterion='absolute_error', max_depth=6, max_features=1.0,
                      min_impurity_decrease=0.002, min_samples_leaf=5,
                      min_samples_split=5, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-01-19 12:16:05,857:INFO:Finalizing DecisionTreeRegressor(criterion='absolute_error', max_depth=6, max_features=1.0,
                      min_impurity_decrease=0.002, min_samples_leaf=5,
                      min_samples_split=5, random_state=123)
2025-01-19 12:16:05,879:INFO:Initializing create_model()
2025-01-19 12:16:05,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30217df60>, estimator=DecisionTreeRegressor(criterion='absolute_error', max_depth=6, max_features=1.0,
                      min_impurity_decrease=0.002, min_samples_leaf=5,
                      min_samples_split=5, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-01-19 12:16:05,879:INFO:Checking exceptions
2025-01-19 12:16:05,892:INFO:Importing libraries
2025-01-19 12:16:05,892:INFO:Copying training dataset
2025-01-19 12:16:05,897:INFO:Defining folds
2025-01-19 12:16:05,897:INFO:Declaring metric variables
2025-01-19 12:16:05,897:INFO:Importing untrained model
2025-01-19 12:16:05,897:INFO:Declaring custom model
2025-01-19 12:16:05,899:INFO:Decision Tree Regressor Imported successfully
2025-01-19 12:16:05,904:INFO:Cross validation set to False
2025-01-19 12:16:05,905:INFO:Fitting Model
2025-01-19 12:16:57,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'loan_status'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['person_gender',
                                             'person_education',...
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 DecisionTreeRegressor(criterion='absolute_error', max_depth=6,
                                       max_features=1.0,
                                       min_impurity_decrease=0.002,
                                       min_samples_leaf=5, min_samples_split=5,
                                       random_state=123))])
2025-01-19 12:16:57,271:INFO:create_model() successfully completed......................................
2025-01-19 12:16:57,580:INFO:_master_model_container: 26
2025-01-19 12:16:57,580:INFO:_display_container: 7
2025-01-19 12:16:57,593:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'loan_status'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['person_gender',
                                             'person_education',...
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 DecisionTreeRegressor(criterion='absolute_error', max_depth=6,
                                       max_features=1.0,
                                       min_impurity_decrease=0.002,
                                       min_samples_leaf=5, min_samples_split=5,
                                       random_state=123))])
2025-01-19 12:16:57,593:INFO:finalize_model() successfully completed......................................
2025-01-19 12:17:29,665:INFO:Initializing save_model()
2025-01-19 12:17:29,665:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'loan_status'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['person_gender',
                                             'person_education',...
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 DecisionTreeRegressor(criterion='absolute_error', max_depth=6,
                                       max_features=1.0,
                                       min_impurity_decrease=0.002,
                                       min_samples_leaf=5, min_samples_split=5,
                                       random_state=123))]), model_name=Decision tree to predict credit score, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'loan_status'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 Transfor...
dtype: int64},
                                                                        {'col': 'previous_loan_defaults_on_file',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': No     0
Yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['person_education',
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-01-19 12:17:29,666:INFO:Adding model into prep_pipe
2025-01-19 12:17:29,666:WARNING:Only Model saved as it was a pipeline.
2025-01-19 12:17:29,673:INFO:Decision tree to predict credit score.pkl saved in current working directory
2025-01-19 12:17:29,690:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['person_age', 'person_income',
                                             'person_emp_exp', 'loan_amnt',
                                             'loan_int_rate',
                                             'loan_percent_income',
                                             'cb_person_cred_hist_length',
                                             'loan_status'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['person_gender',
                                             'person_education',...
                                             'person_home_ownership',
                                             'loan_intent'],
                                    transformer=OneHotEncoder(cols=['person_education',
                                                                    'person_home_ownership',
                                                                    'loan_intent'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 DecisionTreeRegressor(criterion='absolute_error', max_depth=6,
                                       max_features=1.0,
                                       min_impurity_decrease=0.002,
                                       min_samples_leaf=5, min_samples_split=5,
                                       random_state=123))])
2025-01-19 12:17:29,690:INFO:save_model() successfully completed......................................
2025-01-19 12:19:36,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-19 12:19:36,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-19 12:19:36,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-19 12:19:36,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-19 12:20:21,994:INFO:Initializing load_model()
2025-01-19 12:20:21,995:INFO:load_model(model_name=Decision tree to predict credit score.pkl, platform=None, authentication=None, verbose=True)
2025-01-19 12:20:49,705:INFO:Initializing load_model()
2025-01-19 12:20:49,705:INFO:load_model(model_name=Decision tree to predict credit score, platform=None, authentication=None, verbose=True)
2025-01-21 21:26:32,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-21 21:26:32,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-21 21:26:32,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-21 21:26:32,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-21 21:34:26,572:INFO:PyCaret RegressionExperiment
2025-01-21 21:34:26,573:INFO:Logging name: reg-default-name
2025-01-21 21:34:26,573:INFO:ML Usecase: MLUsecase.REGRESSION
2025-01-21 21:34:26,573:INFO:version 3.3.1
2025-01-21 21:34:26,573:INFO:Initializing setup()
2025-01-21 21:34:26,573:INFO:self.USI: 4cac
2025-01-21 21:34:26,573:INFO:self._variable_keys: {'n_jobs_param', '_ml_usecase', 'idx', 'y', 'target_param', 'fold_groups_param', 'X', 'logging_param', 'X_train', 'y_test', 'fold_generator', 'exp_id', 'html_param', 'transform_target_param', 'gpu_n_jobs_param', 'memory', '_available_plots', 'USI', 'log_plots_param', 'y_train', 'exp_name_log', 'data', 'X_test', 'seed', 'pipeline', 'fold_shuffle_param', 'gpu_param'}
2025-01-21 21:34:26,573:INFO:Checking environment
2025-01-21 21:34:26,573:INFO:python_version: 3.10.13
2025-01-21 21:34:26,573:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-21 21:34:26,573:INFO:machine: arm64
2025-01-21 21:34:26,573:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-21 21:34:26,573:INFO:Memory: svmem(total=8589934592, available=2653306880, percent=69.1, used=3857645568, free=134627328, active=2532884480, inactive=2510094336, wired=1324761088)
2025-01-21 21:34:26,574:INFO:Physical Core: 8
2025-01-21 21:34:26,574:INFO:Logical Core: 8
2025-01-21 21:34:26,574:INFO:Checking libraries
2025-01-21 21:34:26,574:INFO:System:
2025-01-21 21:34:26,574:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-21 21:34:26,574:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-21 21:34:26,574:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-21 21:34:26,574:INFO:PyCaret required dependencies:
2025-01-21 21:34:26,652:INFO:                 pip: 24.2
2025-01-21 21:34:26,652:INFO:          setuptools: 75.1.0
2025-01-21 21:34:26,652:INFO:             pycaret: 3.3.1
2025-01-21 21:34:26,652:INFO:             IPython: 8.27.0
2025-01-21 21:34:26,652:INFO:          ipywidgets: 8.1.2
2025-01-21 21:34:26,652:INFO:                tqdm: 4.66.5
2025-01-21 21:34:26,652:INFO:               numpy: 1.26.4
2025-01-21 21:34:26,652:INFO:              pandas: 2.1.4
2025-01-21 21:34:26,652:INFO:              jinja2: 3.1.4
2025-01-21 21:34:26,652:INFO:               scipy: 1.11.4
2025-01-21 21:34:26,652:INFO:              joblib: 1.3.2
2025-01-21 21:34:26,652:INFO:             sklearn: 1.4.2
2025-01-21 21:34:26,652:INFO:                pyod: 2.0.2
2025-01-21 21:34:26,652:INFO:            imblearn: 0.13.0
2025-01-21 21:34:26,652:INFO:   category_encoders: 2.7.0
2025-01-21 21:34:26,652:INFO:            lightgbm: 4.4.0
2025-01-21 21:34:26,652:INFO:               numba: 0.60.0
2025-01-21 21:34:26,652:INFO:            requests: 2.32.3
2025-01-21 21:34:26,652:INFO:          matplotlib: 3.9.2
2025-01-21 21:34:26,653:INFO:          scikitplot: 0.3.7
2025-01-21 21:34:26,653:INFO:         yellowbrick: 1.5
2025-01-21 21:34:26,653:INFO:              plotly: 5.24.1
2025-01-21 21:34:26,653:INFO:    plotly-resampler: Not installed
2025-01-21 21:34:26,653:INFO:             kaleido: 0.2.1
2025-01-21 21:34:26,653:INFO:           schemdraw: 0.15
2025-01-21 21:34:26,653:INFO:         statsmodels: 0.14.4
2025-01-21 21:34:26,653:INFO:              sktime: 0.26.0
2025-01-21 21:34:26,653:INFO:               tbats: 1.1.3
2025-01-21 21:34:26,653:INFO:            pmdarima: 2.0.4
2025-01-21 21:34:26,653:INFO:              psutil: 5.9.0
2025-01-21 21:34:26,653:INFO:          markupsafe: 2.1.3
2025-01-21 21:34:26,653:INFO:             pickle5: Not installed
2025-01-21 21:34:26,653:INFO:         cloudpickle: 3.1.0
2025-01-21 21:34:26,653:INFO:         deprecation: 2.1.0
2025-01-21 21:34:26,653:INFO:              xxhash: 3.5.0
2025-01-21 21:34:26,653:INFO:           wurlitzer: 3.1.1
2025-01-21 21:34:26,653:INFO:PyCaret optional dependencies:
2025-01-21 21:34:26,699:INFO:                shap: 0.46.0
2025-01-21 21:34:26,699:INFO:           interpret: Not installed
2025-01-21 21:34:26,699:INFO:                umap: 0.5.7
2025-01-21 21:34:26,699:INFO:     ydata_profiling: Not installed
2025-01-21 21:34:26,699:INFO:  explainerdashboard: Not installed
2025-01-21 21:34:26,699:INFO:             autoviz: Not installed
2025-01-21 21:34:26,699:INFO:           fairlearn: Not installed
2025-01-21 21:34:26,699:INFO:          deepchecks: Not installed
2025-01-21 21:34:26,699:INFO:             xgboost: 2.1.3
2025-01-21 21:34:26,699:INFO:            catboost: Not installed
2025-01-21 21:34:26,699:INFO:              kmodes: Not installed
2025-01-21 21:34:26,699:INFO:             mlxtend: Not installed
2025-01-21 21:34:26,699:INFO:       statsforecast: Not installed
2025-01-21 21:34:26,699:INFO:        tune_sklearn: Not installed
2025-01-21 21:34:26,699:INFO:                 ray: Not installed
2025-01-21 21:34:26,700:INFO:            hyperopt: Not installed
2025-01-21 21:34:26,700:INFO:              optuna: Not installed
2025-01-21 21:34:26,700:INFO:               skopt: Not installed
2025-01-21 21:34:26,700:INFO:              mlflow: 2.19.0
2025-01-21 21:34:26,700:INFO:              gradio: Not installed
2025-01-21 21:34:26,700:INFO:             fastapi: Not installed
2025-01-21 21:34:26,700:INFO:             uvicorn: Not installed
2025-01-21 21:34:26,700:INFO:              m2cgen: Not installed
2025-01-21 21:34:26,700:INFO:           evidently: Not installed
2025-01-21 21:34:26,700:INFO:               fugue: Not installed
2025-01-21 21:34:26,700:INFO:           streamlit: Not installed
2025-01-21 21:34:26,700:INFO:             prophet: Not installed
2025-01-21 21:34:26,700:INFO:None
2025-01-21 21:34:26,700:INFO:Set up data.
2025-01-21 21:34:26,706:INFO:Set up folding strategy.
2025-01-21 21:34:26,706:INFO:Set up train/test split.
2025-01-21 21:34:26,716:INFO:Set up index.
2025-01-21 21:34:26,716:INFO:Assigning column types.
2025-01-21 21:34:26,720:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-21 21:34:26,720:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,724:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,728:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,781:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,818:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:26,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:26,820:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,823:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,827:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,870:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,902:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:26,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:26,904:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-01-21 21:34:26,907:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,910:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,950:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,981:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:26,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:26,986:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:34:26,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,062:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,064:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-01-21 21:34:27,070:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,110:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,141:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,149:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,189:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,220:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,222:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-01-21 21:34:27,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,299:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,300:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,379:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,381:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-21 21:34:27,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,458:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,505:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:34:27,536:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,538:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-01-21 21:34:27,618:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,697:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:27,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:27,701:INFO:Preparing preprocessing pipeline...
2025-01-21 21:34:27,701:INFO:Set up simple imputation.
2025-01-21 21:34:27,704:INFO:Set up encoding of categorical features.
2025-01-21 21:34:27,704:INFO:Set up column name cleaning.
2025-01-21 21:34:27,756:INFO:Finished creating preprocessing pipeline.
2025-01-21 21:34:27,763:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone',
                                             'Hispanic or Latino'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-01-21 21:34:27,763:INFO:Creating final display dataframe.
2025-01-21 21:34:27,916:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  Total Population
2                   Target type        Regression
3           Original data shape        (1450, 12)
4        Transformed data shape        (1450, 12)
5   Transformed train set shape        (1014, 12)
6    Transformed test set shape         (436, 12)
7              Numeric features                 9
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              4cac
2025-01-21 21:34:28,000:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:28,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:28,079:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:34:28,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:34:28,082:INFO:setup() successfully completed in 1.51s...............
2025-01-21 21:34:43,670:INFO:Initializing compare_models()
2025-01-21 21:34:43,670:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-01-21 21:34:43,670:INFO:Checking exceptions
2025-01-21 21:34:43,674:INFO:Preparing display monitor
2025-01-21 21:34:43,730:INFO:Initializing Linear Regression
2025-01-21 21:34:43,731:INFO:Total runtime is 5.046526590983073e-06 minutes
2025-01-21 21:34:43,733:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:43,734:INFO:Initializing create_model()
2025-01-21 21:34:43,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:43,734:INFO:Checking exceptions
2025-01-21 21:34:43,734:INFO:Importing libraries
2025-01-21 21:34:43,734:INFO:Copying training dataset
2025-01-21 21:34:43,741:INFO:Defining folds
2025-01-21 21:34:43,741:INFO:Declaring metric variables
2025-01-21 21:34:43,743:INFO:Importing untrained model
2025-01-21 21:34:43,747:INFO:Linear Regression Imported successfully
2025-01-21 21:34:43,753:INFO:Starting cross validation
2025-01-21 21:34:43,762:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:48,104:INFO:Calculating mean and std
2025-01-21 21:34:48,107:INFO:Creating metrics dataframe
2025-01-21 21:34:48,113:INFO:Uploading results into container
2025-01-21 21:34:48,115:INFO:Uploading model into container now
2025-01-21 21:34:48,116:INFO:_master_model_container: 1
2025-01-21 21:34:48,116:INFO:_display_container: 2
2025-01-21 21:34:48,117:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:34:48,117:INFO:create_model() successfully completed......................................
2025-01-21 21:34:48,285:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:48,285:INFO:Creating metrics dataframe
2025-01-21 21:34:48,290:INFO:Initializing Lasso Regression
2025-01-21 21:34:48,290:INFO:Total runtime is 0.0759952465693156 minutes
2025-01-21 21:34:48,292:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:48,293:INFO:Initializing create_model()
2025-01-21 21:34:48,293:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:48,293:INFO:Checking exceptions
2025-01-21 21:34:48,293:INFO:Importing libraries
2025-01-21 21:34:48,293:INFO:Copying training dataset
2025-01-21 21:34:48,297:INFO:Defining folds
2025-01-21 21:34:48,297:INFO:Declaring metric variables
2025-01-21 21:34:48,299:INFO:Importing untrained model
2025-01-21 21:34:48,302:INFO:Lasso Regression Imported successfully
2025-01-21 21:34:48,307:INFO:Starting cross validation
2025-01-21 21:34:48,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:48,463:INFO:Calculating mean and std
2025-01-21 21:34:48,464:INFO:Creating metrics dataframe
2025-01-21 21:34:48,465:INFO:Uploading results into container
2025-01-21 21:34:48,466:INFO:Uploading model into container now
2025-01-21 21:34:48,466:INFO:_master_model_container: 2
2025-01-21 21:34:48,466:INFO:_display_container: 2
2025-01-21 21:34:48,467:INFO:Lasso(random_state=123)
2025-01-21 21:34:48,467:INFO:create_model() successfully completed......................................
2025-01-21 21:34:48,559:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:48,559:INFO:Creating metrics dataframe
2025-01-21 21:34:48,564:INFO:Initializing Ridge Regression
2025-01-21 21:34:48,564:INFO:Total runtime is 0.08056104977925618 minutes
2025-01-21 21:34:48,566:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:48,566:INFO:Initializing create_model()
2025-01-21 21:34:48,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:48,567:INFO:Checking exceptions
2025-01-21 21:34:48,567:INFO:Importing libraries
2025-01-21 21:34:48,567:INFO:Copying training dataset
2025-01-21 21:34:48,571:INFO:Defining folds
2025-01-21 21:34:48,572:INFO:Declaring metric variables
2025-01-21 21:34:48,574:INFO:Importing untrained model
2025-01-21 21:34:48,576:INFO:Ridge Regression Imported successfully
2025-01-21 21:34:48,580:INFO:Starting cross validation
2025-01-21 21:34:48,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:48,719:INFO:Calculating mean and std
2025-01-21 21:34:48,720:INFO:Creating metrics dataframe
2025-01-21 21:34:48,721:INFO:Uploading results into container
2025-01-21 21:34:48,722:INFO:Uploading model into container now
2025-01-21 21:34:48,722:INFO:_master_model_container: 3
2025-01-21 21:34:48,722:INFO:_display_container: 2
2025-01-21 21:34:48,723:INFO:Ridge(random_state=123)
2025-01-21 21:34:48,723:INFO:create_model() successfully completed......................................
2025-01-21 21:34:48,820:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:48,821:INFO:Creating metrics dataframe
2025-01-21 21:34:48,826:INFO:Initializing Elastic Net
2025-01-21 21:34:48,826:INFO:Total runtime is 0.08493096431096395 minutes
2025-01-21 21:34:48,829:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:48,829:INFO:Initializing create_model()
2025-01-21 21:34:48,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:48,829:INFO:Checking exceptions
2025-01-21 21:34:48,829:INFO:Importing libraries
2025-01-21 21:34:48,829:INFO:Copying training dataset
2025-01-21 21:34:48,834:INFO:Defining folds
2025-01-21 21:34:48,834:INFO:Declaring metric variables
2025-01-21 21:34:48,837:INFO:Importing untrained model
2025-01-21 21:34:48,840:INFO:Elastic Net Imported successfully
2025-01-21 21:34:48,844:INFO:Starting cross validation
2025-01-21 21:34:48,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:49,017:INFO:Calculating mean and std
2025-01-21 21:34:49,019:INFO:Creating metrics dataframe
2025-01-21 21:34:49,021:INFO:Uploading results into container
2025-01-21 21:34:49,022:INFO:Uploading model into container now
2025-01-21 21:34:49,022:INFO:_master_model_container: 4
2025-01-21 21:34:49,022:INFO:_display_container: 2
2025-01-21 21:34:49,023:INFO:ElasticNet(random_state=123)
2025-01-21 21:34:49,023:INFO:create_model() successfully completed......................................
2025-01-21 21:34:49,140:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:49,141:INFO:Creating metrics dataframe
2025-01-21 21:34:49,146:INFO:Initializing Least Angle Regression
2025-01-21 21:34:49,146:INFO:Total runtime is 0.0902656118075053 minutes
2025-01-21 21:34:49,149:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:49,149:INFO:Initializing create_model()
2025-01-21 21:34:49,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:49,149:INFO:Checking exceptions
2025-01-21 21:34:49,150:INFO:Importing libraries
2025-01-21 21:34:49,150:INFO:Copying training dataset
2025-01-21 21:34:49,154:INFO:Defining folds
2025-01-21 21:34:49,154:INFO:Declaring metric variables
2025-01-21 21:34:49,157:INFO:Importing untrained model
2025-01-21 21:34:49,160:INFO:Least Angle Regression Imported successfully
2025-01-21 21:34:49,166:INFO:Starting cross validation
2025-01-21 21:34:49,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:49,302:INFO:Calculating mean and std
2025-01-21 21:34:49,303:INFO:Creating metrics dataframe
2025-01-21 21:34:49,304:INFO:Uploading results into container
2025-01-21 21:34:49,305:INFO:Uploading model into container now
2025-01-21 21:34:49,305:INFO:_master_model_container: 5
2025-01-21 21:34:49,305:INFO:_display_container: 2
2025-01-21 21:34:49,306:INFO:Lars(random_state=123)
2025-01-21 21:34:49,306:INFO:create_model() successfully completed......................................
2025-01-21 21:34:49,402:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:49,403:INFO:Creating metrics dataframe
2025-01-21 21:34:49,408:INFO:Initializing Lasso Least Angle Regression
2025-01-21 21:34:49,409:INFO:Total runtime is 0.09463592767715455 minutes
2025-01-21 21:34:49,411:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:49,411:INFO:Initializing create_model()
2025-01-21 21:34:49,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:49,411:INFO:Checking exceptions
2025-01-21 21:34:49,411:INFO:Importing libraries
2025-01-21 21:34:49,411:INFO:Copying training dataset
2025-01-21 21:34:49,415:INFO:Defining folds
2025-01-21 21:34:49,415:INFO:Declaring metric variables
2025-01-21 21:34:49,418:INFO:Importing untrained model
2025-01-21 21:34:49,420:INFO:Lasso Least Angle Regression Imported successfully
2025-01-21 21:34:49,426:INFO:Starting cross validation
2025-01-21 21:34:49,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:49,548:INFO:Calculating mean and std
2025-01-21 21:34:49,549:INFO:Creating metrics dataframe
2025-01-21 21:34:49,550:INFO:Uploading results into container
2025-01-21 21:34:49,551:INFO:Uploading model into container now
2025-01-21 21:34:49,551:INFO:_master_model_container: 6
2025-01-21 21:34:49,551:INFO:_display_container: 2
2025-01-21 21:34:49,551:INFO:LassoLars(random_state=123)
2025-01-21 21:34:49,552:INFO:create_model() successfully completed......................................
2025-01-21 21:34:49,647:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:49,647:INFO:Creating metrics dataframe
2025-01-21 21:34:49,655:INFO:Initializing Orthogonal Matching Pursuit
2025-01-21 21:34:49,655:INFO:Total runtime is 0.09873889684677124 minutes
2025-01-21 21:34:49,674:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:49,675:INFO:Initializing create_model()
2025-01-21 21:34:49,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:49,676:INFO:Checking exceptions
2025-01-21 21:34:49,676:INFO:Importing libraries
2025-01-21 21:34:49,676:INFO:Copying training dataset
2025-01-21 21:34:49,681:INFO:Defining folds
2025-01-21 21:34:49,683:INFO:Declaring metric variables
2025-01-21 21:34:49,688:INFO:Importing untrained model
2025-01-21 21:34:49,691:INFO:Orthogonal Matching Pursuit Imported successfully
2025-01-21 21:34:49,695:INFO:Starting cross validation
2025-01-21 21:34:49,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:49,836:INFO:Calculating mean and std
2025-01-21 21:34:49,837:INFO:Creating metrics dataframe
2025-01-21 21:34:49,838:INFO:Uploading results into container
2025-01-21 21:34:49,839:INFO:Uploading model into container now
2025-01-21 21:34:49,839:INFO:_master_model_container: 7
2025-01-21 21:34:49,839:INFO:_display_container: 2
2025-01-21 21:34:49,839:INFO:OrthogonalMatchingPursuit()
2025-01-21 21:34:49,840:INFO:create_model() successfully completed......................................
2025-01-21 21:34:49,935:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:49,935:INFO:Creating metrics dataframe
2025-01-21 21:34:49,942:INFO:Initializing Bayesian Ridge
2025-01-21 21:34:49,942:INFO:Total runtime is 0.10352307955423991 minutes
2025-01-21 21:34:49,944:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:49,944:INFO:Initializing create_model()
2025-01-21 21:34:49,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:49,945:INFO:Checking exceptions
2025-01-21 21:34:49,945:INFO:Importing libraries
2025-01-21 21:34:49,945:INFO:Copying training dataset
2025-01-21 21:34:49,949:INFO:Defining folds
2025-01-21 21:34:49,949:INFO:Declaring metric variables
2025-01-21 21:34:49,951:INFO:Importing untrained model
2025-01-21 21:34:49,953:INFO:Bayesian Ridge Imported successfully
2025-01-21 21:34:49,959:INFO:Starting cross validation
2025-01-21 21:34:49,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:50,123:INFO:Calculating mean and std
2025-01-21 21:34:50,124:INFO:Creating metrics dataframe
2025-01-21 21:34:50,126:INFO:Uploading results into container
2025-01-21 21:34:50,126:INFO:Uploading model into container now
2025-01-21 21:34:50,127:INFO:_master_model_container: 8
2025-01-21 21:34:50,127:INFO:_display_container: 2
2025-01-21 21:34:50,127:INFO:BayesianRidge()
2025-01-21 21:34:50,127:INFO:create_model() successfully completed......................................
2025-01-21 21:34:50,226:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:50,227:INFO:Creating metrics dataframe
2025-01-21 21:34:50,233:INFO:Initializing Passive Aggressive Regressor
2025-01-21 21:34:50,233:INFO:Total runtime is 0.10837764739990234 minutes
2025-01-21 21:34:50,235:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:50,236:INFO:Initializing create_model()
2025-01-21 21:34:50,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:50,236:INFO:Checking exceptions
2025-01-21 21:34:50,236:INFO:Importing libraries
2025-01-21 21:34:50,236:INFO:Copying training dataset
2025-01-21 21:34:50,240:INFO:Defining folds
2025-01-21 21:34:50,240:INFO:Declaring metric variables
2025-01-21 21:34:50,242:INFO:Importing untrained model
2025-01-21 21:34:50,246:INFO:Passive Aggressive Regressor Imported successfully
2025-01-21 21:34:50,251:INFO:Starting cross validation
2025-01-21 21:34:50,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:50,404:INFO:Calculating mean and std
2025-01-21 21:34:50,405:INFO:Creating metrics dataframe
2025-01-21 21:34:50,407:INFO:Uploading results into container
2025-01-21 21:34:50,407:INFO:Uploading model into container now
2025-01-21 21:34:50,407:INFO:_master_model_container: 9
2025-01-21 21:34:50,407:INFO:_display_container: 2
2025-01-21 21:34:50,408:INFO:PassiveAggressiveRegressor(random_state=123)
2025-01-21 21:34:50,408:INFO:create_model() successfully completed......................................
2025-01-21 21:34:50,503:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:50,503:INFO:Creating metrics dataframe
2025-01-21 21:34:50,510:INFO:Initializing Huber Regressor
2025-01-21 21:34:50,510:INFO:Total runtime is 0.11299678087234497 minutes
2025-01-21 21:34:50,513:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:50,513:INFO:Initializing create_model()
2025-01-21 21:34:50,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:50,513:INFO:Checking exceptions
2025-01-21 21:34:50,513:INFO:Importing libraries
2025-01-21 21:34:50,513:INFO:Copying training dataset
2025-01-21 21:34:50,517:INFO:Defining folds
2025-01-21 21:34:50,517:INFO:Declaring metric variables
2025-01-21 21:34:50,520:INFO:Importing untrained model
2025-01-21 21:34:50,524:INFO:Huber Regressor Imported successfully
2025-01-21 21:34:50,529:INFO:Starting cross validation
2025-01-21 21:34:50,530:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:50,618:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,624:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,624:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,630:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,632:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,641:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,653:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,699:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,707:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:34:50,730:INFO:Calculating mean and std
2025-01-21 21:34:50,731:INFO:Creating metrics dataframe
2025-01-21 21:34:50,732:INFO:Uploading results into container
2025-01-21 21:34:50,733:INFO:Uploading model into container now
2025-01-21 21:34:50,733:INFO:_master_model_container: 10
2025-01-21 21:34:50,733:INFO:_display_container: 2
2025-01-21 21:34:50,734:INFO:HuberRegressor()
2025-01-21 21:34:50,734:INFO:create_model() successfully completed......................................
2025-01-21 21:34:50,836:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:50,836:INFO:Creating metrics dataframe
2025-01-21 21:34:50,843:INFO:Initializing K Neighbors Regressor
2025-01-21 21:34:50,843:INFO:Total runtime is 0.11854156255722045 minutes
2025-01-21 21:34:50,845:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:50,846:INFO:Initializing create_model()
2025-01-21 21:34:50,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:50,846:INFO:Checking exceptions
2025-01-21 21:34:50,846:INFO:Importing libraries
2025-01-21 21:34:50,846:INFO:Copying training dataset
2025-01-21 21:34:50,850:INFO:Defining folds
2025-01-21 21:34:50,850:INFO:Declaring metric variables
2025-01-21 21:34:50,862:INFO:Importing untrained model
2025-01-21 21:34:50,881:INFO:K Neighbors Regressor Imported successfully
2025-01-21 21:34:50,891:INFO:Starting cross validation
2025-01-21 21:34:50,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:51,073:INFO:Calculating mean and std
2025-01-21 21:34:51,074:INFO:Creating metrics dataframe
2025-01-21 21:34:51,076:INFO:Uploading results into container
2025-01-21 21:34:51,076:INFO:Uploading model into container now
2025-01-21 21:34:51,077:INFO:_master_model_container: 11
2025-01-21 21:34:51,077:INFO:_display_container: 2
2025-01-21 21:34:51,077:INFO:KNeighborsRegressor(n_jobs=-1)
2025-01-21 21:34:51,077:INFO:create_model() successfully completed......................................
2025-01-21 21:34:51,175:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:51,175:INFO:Creating metrics dataframe
2025-01-21 21:34:51,182:INFO:Initializing Decision Tree Regressor
2025-01-21 21:34:51,182:INFO:Total runtime is 0.12419772942860921 minutes
2025-01-21 21:34:51,185:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:51,185:INFO:Initializing create_model()
2025-01-21 21:34:51,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:51,185:INFO:Checking exceptions
2025-01-21 21:34:51,185:INFO:Importing libraries
2025-01-21 21:34:51,185:INFO:Copying training dataset
2025-01-21 21:34:51,189:INFO:Defining folds
2025-01-21 21:34:51,189:INFO:Declaring metric variables
2025-01-21 21:34:51,191:INFO:Importing untrained model
2025-01-21 21:34:51,194:INFO:Decision Tree Regressor Imported successfully
2025-01-21 21:34:51,198:INFO:Starting cross validation
2025-01-21 21:34:51,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:51,356:INFO:Calculating mean and std
2025-01-21 21:34:51,357:INFO:Creating metrics dataframe
2025-01-21 21:34:51,358:INFO:Uploading results into container
2025-01-21 21:34:51,359:INFO:Uploading model into container now
2025-01-21 21:34:51,359:INFO:_master_model_container: 12
2025-01-21 21:34:51,359:INFO:_display_container: 2
2025-01-21 21:34:51,359:INFO:DecisionTreeRegressor(random_state=123)
2025-01-21 21:34:51,360:INFO:create_model() successfully completed......................................
2025-01-21 21:34:51,459:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:51,459:INFO:Creating metrics dataframe
2025-01-21 21:34:51,466:INFO:Initializing Random Forest Regressor
2025-01-21 21:34:51,466:INFO:Total runtime is 0.1289247155189514 minutes
2025-01-21 21:34:51,468:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:51,468:INFO:Initializing create_model()
2025-01-21 21:34:51,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:51,468:INFO:Checking exceptions
2025-01-21 21:34:51,468:INFO:Importing libraries
2025-01-21 21:34:51,469:INFO:Copying training dataset
2025-01-21 21:34:51,472:INFO:Defining folds
2025-01-21 21:34:51,472:INFO:Declaring metric variables
2025-01-21 21:34:51,474:INFO:Importing untrained model
2025-01-21 21:34:51,477:INFO:Random Forest Regressor Imported successfully
2025-01-21 21:34:51,481:INFO:Starting cross validation
2025-01-21 21:34:51,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:53,005:INFO:Calculating mean and std
2025-01-21 21:34:53,006:INFO:Creating metrics dataframe
2025-01-21 21:34:53,008:INFO:Uploading results into container
2025-01-21 21:34:53,008:INFO:Uploading model into container now
2025-01-21 21:34:53,008:INFO:_master_model_container: 13
2025-01-21 21:34:53,009:INFO:_display_container: 2
2025-01-21 21:34:53,009:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:34:53,009:INFO:create_model() successfully completed......................................
2025-01-21 21:34:53,102:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:53,102:INFO:Creating metrics dataframe
2025-01-21 21:34:53,108:INFO:Initializing Extra Trees Regressor
2025-01-21 21:34:53,108:INFO:Total runtime is 0.15629666646321613 minutes
2025-01-21 21:34:53,110:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:53,111:INFO:Initializing create_model()
2025-01-21 21:34:53,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:53,111:INFO:Checking exceptions
2025-01-21 21:34:53,111:INFO:Importing libraries
2025-01-21 21:34:53,111:INFO:Copying training dataset
2025-01-21 21:34:53,115:INFO:Defining folds
2025-01-21 21:34:53,115:INFO:Declaring metric variables
2025-01-21 21:34:53,118:INFO:Importing untrained model
2025-01-21 21:34:53,121:INFO:Extra Trees Regressor Imported successfully
2025-01-21 21:34:53,126:INFO:Starting cross validation
2025-01-21 21:34:53,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:54,041:INFO:Calculating mean and std
2025-01-21 21:34:54,042:INFO:Creating metrics dataframe
2025-01-21 21:34:54,043:INFO:Uploading results into container
2025-01-21 21:34:54,044:INFO:Uploading model into container now
2025-01-21 21:34:54,044:INFO:_master_model_container: 14
2025-01-21 21:34:54,044:INFO:_display_container: 2
2025-01-21 21:34:54,045:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:34:54,045:INFO:create_model() successfully completed......................................
2025-01-21 21:34:54,140:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:54,141:INFO:Creating metrics dataframe
2025-01-21 21:34:54,147:INFO:Initializing AdaBoost Regressor
2025-01-21 21:34:54,148:INFO:Total runtime is 0.1736180822054545 minutes
2025-01-21 21:34:54,150:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:54,150:INFO:Initializing create_model()
2025-01-21 21:34:54,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:54,150:INFO:Checking exceptions
2025-01-21 21:34:54,150:INFO:Importing libraries
2025-01-21 21:34:54,150:INFO:Copying training dataset
2025-01-21 21:34:54,155:INFO:Defining folds
2025-01-21 21:34:54,155:INFO:Declaring metric variables
2025-01-21 21:34:54,157:INFO:Importing untrained model
2025-01-21 21:34:54,160:INFO:AdaBoost Regressor Imported successfully
2025-01-21 21:34:54,164:INFO:Starting cross validation
2025-01-21 21:34:54,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:54,681:INFO:Calculating mean and std
2025-01-21 21:34:54,682:INFO:Creating metrics dataframe
2025-01-21 21:34:54,684:INFO:Uploading results into container
2025-01-21 21:34:54,685:INFO:Uploading model into container now
2025-01-21 21:34:54,685:INFO:_master_model_container: 15
2025-01-21 21:34:54,685:INFO:_display_container: 2
2025-01-21 21:34:54,686:INFO:AdaBoostRegressor(random_state=123)
2025-01-21 21:34:54,686:INFO:create_model() successfully completed......................................
2025-01-21 21:34:54,785:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:54,785:INFO:Creating metrics dataframe
2025-01-21 21:34:54,792:INFO:Initializing Gradient Boosting Regressor
2025-01-21 21:34:54,792:INFO:Total runtime is 0.18436522881189982 minutes
2025-01-21 21:34:54,794:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:54,795:INFO:Initializing create_model()
2025-01-21 21:34:54,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:54,795:INFO:Checking exceptions
2025-01-21 21:34:54,795:INFO:Importing libraries
2025-01-21 21:34:54,795:INFO:Copying training dataset
2025-01-21 21:34:54,798:INFO:Defining folds
2025-01-21 21:34:54,798:INFO:Declaring metric variables
2025-01-21 21:34:54,801:INFO:Importing untrained model
2025-01-21 21:34:54,804:INFO:Gradient Boosting Regressor Imported successfully
2025-01-21 21:34:54,809:INFO:Starting cross validation
2025-01-21 21:34:54,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:55,859:INFO:Calculating mean and std
2025-01-21 21:34:55,859:INFO:Creating metrics dataframe
2025-01-21 21:34:55,861:INFO:Uploading results into container
2025-01-21 21:34:55,861:INFO:Uploading model into container now
2025-01-21 21:34:55,862:INFO:_master_model_container: 16
2025-01-21 21:34:55,862:INFO:_display_container: 2
2025-01-21 21:34:55,862:INFO:GradientBoostingRegressor(random_state=123)
2025-01-21 21:34:55,862:INFO:create_model() successfully completed......................................
2025-01-21 21:34:55,951:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:55,951:INFO:Creating metrics dataframe
2025-01-21 21:34:55,958:INFO:Initializing Extreme Gradient Boosting
2025-01-21 21:34:55,958:INFO:Total runtime is 0.2037989616394043 minutes
2025-01-21 21:34:55,960:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:55,961:INFO:Initializing create_model()
2025-01-21 21:34:55,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:55,961:INFO:Checking exceptions
2025-01-21 21:34:55,961:INFO:Importing libraries
2025-01-21 21:34:55,961:INFO:Copying training dataset
2025-01-21 21:34:55,964:INFO:Defining folds
2025-01-21 21:34:55,964:INFO:Declaring metric variables
2025-01-21 21:34:55,966:INFO:Importing untrained model
2025-01-21 21:34:55,969:INFO:Extreme Gradient Boosting Imported successfully
2025-01-21 21:34:55,974:INFO:Starting cross validation
2025-01-21 21:34:55,975:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:56,570:INFO:Calculating mean and std
2025-01-21 21:34:56,572:INFO:Creating metrics dataframe
2025-01-21 21:34:56,573:INFO:Uploading results into container
2025-01-21 21:34:56,573:INFO:Uploading model into container now
2025-01-21 21:34:56,574:INFO:_master_model_container: 17
2025-01-21 21:34:56,574:INFO:_display_container: 2
2025-01-21 21:34:56,575:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2025-01-21 21:34:56,575:INFO:create_model() successfully completed......................................
2025-01-21 21:34:56,666:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:56,667:INFO:Creating metrics dataframe
2025-01-21 21:34:56,674:INFO:Initializing Light Gradient Boosting Machine
2025-01-21 21:34:56,674:INFO:Total runtime is 0.21572864850362142 minutes
2025-01-21 21:34:56,676:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:56,676:INFO:Initializing create_model()
2025-01-21 21:34:56,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:56,677:INFO:Checking exceptions
2025-01-21 21:34:56,677:INFO:Importing libraries
2025-01-21 21:34:56,677:INFO:Copying training dataset
2025-01-21 21:34:56,680:INFO:Defining folds
2025-01-21 21:34:56,680:INFO:Declaring metric variables
2025-01-21 21:34:56,682:INFO:Importing untrained model
2025-01-21 21:34:56,685:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-21 21:34:56,692:INFO:Starting cross validation
2025-01-21 21:34:56,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:59,545:INFO:Calculating mean and std
2025-01-21 21:34:59,546:INFO:Creating metrics dataframe
2025-01-21 21:34:59,547:INFO:Uploading results into container
2025-01-21 21:34:59,548:INFO:Uploading model into container now
2025-01-21 21:34:59,548:INFO:_master_model_container: 18
2025-01-21 21:34:59,548:INFO:_display_container: 2
2025-01-21 21:34:59,548:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:34:59,548:INFO:create_model() successfully completed......................................
2025-01-21 21:34:59,637:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:59,637:INFO:Creating metrics dataframe
2025-01-21 21:34:59,644:INFO:Initializing Dummy Regressor
2025-01-21 21:34:59,644:INFO:Total runtime is 0.26523204644521076 minutes
2025-01-21 21:34:59,646:INFO:SubProcess create_model() called ==================================
2025-01-21 21:34:59,647:INFO:Initializing create_model()
2025-01-21 21:34:59,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15dfefa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:59,647:INFO:Checking exceptions
2025-01-21 21:34:59,647:INFO:Importing libraries
2025-01-21 21:34:59,647:INFO:Copying training dataset
2025-01-21 21:34:59,650:INFO:Defining folds
2025-01-21 21:34:59,650:INFO:Declaring metric variables
2025-01-21 21:34:59,652:INFO:Importing untrained model
2025-01-21 21:34:59,654:INFO:Dummy Regressor Imported successfully
2025-01-21 21:34:59,659:INFO:Starting cross validation
2025-01-21 21:34:59,660:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:34:59,776:INFO:Calculating mean and std
2025-01-21 21:34:59,777:INFO:Creating metrics dataframe
2025-01-21 21:34:59,778:INFO:Uploading results into container
2025-01-21 21:34:59,779:INFO:Uploading model into container now
2025-01-21 21:34:59,779:INFO:_master_model_container: 19
2025-01-21 21:34:59,779:INFO:_display_container: 2
2025-01-21 21:34:59,779:INFO:DummyRegressor()
2025-01-21 21:34:59,779:INFO:create_model() successfully completed......................................
2025-01-21 21:34:59,867:INFO:SubProcess create_model() end ==================================
2025-01-21 21:34:59,867:INFO:Creating metrics dataframe
2025-01-21 21:34:59,878:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-21 21:34:59,883:INFO:Initializing create_model()
2025-01-21 21:34:59,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15dfec460>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:34:59,883:INFO:Checking exceptions
2025-01-21 21:34:59,884:INFO:Importing libraries
2025-01-21 21:34:59,884:INFO:Copying training dataset
2025-01-21 21:34:59,888:INFO:Defining folds
2025-01-21 21:34:59,888:INFO:Declaring metric variables
2025-01-21 21:34:59,888:INFO:Importing untrained model
2025-01-21 21:34:59,888:INFO:Declaring custom model
2025-01-21 21:34:59,888:INFO:Linear Regression Imported successfully
2025-01-21 21:34:59,889:INFO:Cross validation set to False
2025-01-21 21:34:59,889:INFO:Fitting Model
2025-01-21 21:34:59,916:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:34:59,916:INFO:create_model() successfully completed......................................
2025-01-21 21:35:00,025:INFO:_master_model_container: 19
2025-01-21 21:35:00,025:INFO:_display_container: 2
2025-01-21 21:35:00,026:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:35:00,026:INFO:compare_models() successfully completed......................................
2025-01-21 21:36:00,818:INFO:PyCaret RegressionExperiment
2025-01-21 21:36:00,819:INFO:Logging name: reg-default-name
2025-01-21 21:36:00,819:INFO:ML Usecase: MLUsecase.REGRESSION
2025-01-21 21:36:00,819:INFO:version 3.3.1
2025-01-21 21:36:00,819:INFO:Initializing setup()
2025-01-21 21:36:00,819:INFO:self.USI: f973
2025-01-21 21:36:00,819:INFO:self._variable_keys: {'n_jobs_param', '_ml_usecase', 'idx', 'y', 'target_param', 'fold_groups_param', 'X', 'logging_param', 'X_train', 'y_test', 'fold_generator', 'exp_id', 'html_param', 'transform_target_param', 'gpu_n_jobs_param', 'memory', '_available_plots', 'USI', 'log_plots_param', 'y_train', 'exp_name_log', 'data', 'X_test', 'seed', 'pipeline', 'fold_shuffle_param', 'gpu_param'}
2025-01-21 21:36:00,819:INFO:Checking environment
2025-01-21 21:36:00,820:INFO:python_version: 3.10.13
2025-01-21 21:36:00,820:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-21 21:36:00,820:INFO:machine: arm64
2025-01-21 21:36:00,820:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-21 21:36:00,820:INFO:Memory: svmem(total=8589934592, available=1920827392, percent=77.6, used=3204104192, free=64798720, active=1871986688, inactive=1854111744, wired=1332117504)
2025-01-21 21:36:00,820:INFO:Physical Core: 8
2025-01-21 21:36:00,820:INFO:Logical Core: 8
2025-01-21 21:36:00,820:INFO:Checking libraries
2025-01-21 21:36:00,820:INFO:System:
2025-01-21 21:36:00,820:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-21 21:36:00,820:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-21 21:36:00,821:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-21 21:36:00,821:INFO:PyCaret required dependencies:
2025-01-21 21:36:00,821:INFO:                 pip: 24.2
2025-01-21 21:36:00,821:INFO:          setuptools: 75.1.0
2025-01-21 21:36:00,821:INFO:             pycaret: 3.3.1
2025-01-21 21:36:00,821:INFO:             IPython: 8.27.0
2025-01-21 21:36:00,821:INFO:          ipywidgets: 8.1.2
2025-01-21 21:36:00,821:INFO:                tqdm: 4.66.5
2025-01-21 21:36:00,821:INFO:               numpy: 1.26.4
2025-01-21 21:36:00,821:INFO:              pandas: 2.1.4
2025-01-21 21:36:00,821:INFO:              jinja2: 3.1.4
2025-01-21 21:36:00,821:INFO:               scipy: 1.11.4
2025-01-21 21:36:00,821:INFO:              joblib: 1.3.2
2025-01-21 21:36:00,822:INFO:             sklearn: 1.4.2
2025-01-21 21:36:00,822:INFO:                pyod: 2.0.2
2025-01-21 21:36:00,822:INFO:            imblearn: 0.13.0
2025-01-21 21:36:00,822:INFO:   category_encoders: 2.7.0
2025-01-21 21:36:00,822:INFO:            lightgbm: 4.4.0
2025-01-21 21:36:00,822:INFO:               numba: 0.60.0
2025-01-21 21:36:00,822:INFO:            requests: 2.32.3
2025-01-21 21:36:00,822:INFO:          matplotlib: 3.9.2
2025-01-21 21:36:00,822:INFO:          scikitplot: 0.3.7
2025-01-21 21:36:00,822:INFO:         yellowbrick: 1.5
2025-01-21 21:36:00,822:INFO:              plotly: 5.24.1
2025-01-21 21:36:00,822:INFO:    plotly-resampler: Not installed
2025-01-21 21:36:00,822:INFO:             kaleido: 0.2.1
2025-01-21 21:36:00,822:INFO:           schemdraw: 0.15
2025-01-21 21:36:00,822:INFO:         statsmodels: 0.14.4
2025-01-21 21:36:00,822:INFO:              sktime: 0.26.0
2025-01-21 21:36:00,822:INFO:               tbats: 1.1.3
2025-01-21 21:36:00,823:INFO:            pmdarima: 2.0.4
2025-01-21 21:36:00,823:INFO:              psutil: 5.9.0
2025-01-21 21:36:00,823:INFO:          markupsafe: 2.1.3
2025-01-21 21:36:00,823:INFO:             pickle5: Not installed
2025-01-21 21:36:00,823:INFO:         cloudpickle: 3.1.0
2025-01-21 21:36:00,823:INFO:         deprecation: 2.1.0
2025-01-21 21:36:00,823:INFO:              xxhash: 3.5.0
2025-01-21 21:36:00,823:INFO:           wurlitzer: 3.1.1
2025-01-21 21:36:00,823:INFO:PyCaret optional dependencies:
2025-01-21 21:36:00,823:INFO:                shap: 0.46.0
2025-01-21 21:36:00,823:INFO:           interpret: Not installed
2025-01-21 21:36:00,823:INFO:                umap: 0.5.7
2025-01-21 21:36:00,823:INFO:     ydata_profiling: Not installed
2025-01-21 21:36:00,823:INFO:  explainerdashboard: Not installed
2025-01-21 21:36:00,823:INFO:             autoviz: Not installed
2025-01-21 21:36:00,823:INFO:           fairlearn: Not installed
2025-01-21 21:36:00,823:INFO:          deepchecks: Not installed
2025-01-21 21:36:00,823:INFO:             xgboost: 2.1.3
2025-01-21 21:36:00,823:INFO:            catboost: Not installed
2025-01-21 21:36:00,824:INFO:              kmodes: Not installed
2025-01-21 21:36:00,824:INFO:             mlxtend: Not installed
2025-01-21 21:36:00,824:INFO:       statsforecast: Not installed
2025-01-21 21:36:00,824:INFO:        tune_sklearn: Not installed
2025-01-21 21:36:00,824:INFO:                 ray: Not installed
2025-01-21 21:36:00,824:INFO:            hyperopt: Not installed
2025-01-21 21:36:00,824:INFO:              optuna: Not installed
2025-01-21 21:36:00,824:INFO:               skopt: Not installed
2025-01-21 21:36:00,824:INFO:              mlflow: 2.19.0
2025-01-21 21:36:00,824:INFO:              gradio: Not installed
2025-01-21 21:36:00,824:INFO:             fastapi: Not installed
2025-01-21 21:36:00,824:INFO:             uvicorn: Not installed
2025-01-21 21:36:00,824:INFO:              m2cgen: Not installed
2025-01-21 21:36:00,824:INFO:           evidently: Not installed
2025-01-21 21:36:00,825:INFO:               fugue: Not installed
2025-01-21 21:36:00,825:INFO:           streamlit: Not installed
2025-01-21 21:36:00,825:INFO:             prophet: Not installed
2025-01-21 21:36:00,825:INFO:None
2025-01-21 21:36:00,825:INFO:Set up data.
2025-01-21 21:36:00,842:INFO:Set up folding strategy.
2025-01-21 21:36:00,843:INFO:Set up train/test split.
2025-01-21 21:36:00,850:INFO:Set up index.
2025-01-21 21:36:00,851:INFO:Assigning column types.
2025-01-21 21:36:00,853:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-21 21:36:00,854:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:36:00,860:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:36:00,864:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:00,910:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:00,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:00,943:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:00,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:00,945:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:36:00,948:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:36:00,952:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,047:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,050:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-01-21 21:36:01,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,057:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,139:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,139:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,145:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,148:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,220:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,222:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-01-21 21:36:01,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,301:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,382:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,382:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,384:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-01-21 21:36:01,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,462:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,462:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,542:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,544:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-21 21:36:01,590:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,621:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,669:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:01,700:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,702:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-01-21 21:36:01,779:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,862:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:01,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:01,866:INFO:Preparing preprocessing pipeline...
2025-01-21 21:36:01,866:INFO:Set up simple imputation.
2025-01-21 21:36:01,867:INFO:Set up encoding of categorical features.
2025-01-21 21:36:01,868:INFO:Set up column name cleaning.
2025-01-21 21:36:01,917:INFO:Finished creating preprocessing pipeline.
2025-01-21 21:36:01,922:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone',
                                             'Hispanic or Latino'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-01-21 21:36:01,922:INFO:Creating final display dataframe.
2025-01-21 21:36:02,080:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target  Female Population
2                   Target type         Regression
3           Original data shape         (1450, 12)
4        Transformed data shape         (1450, 12)
5   Transformed train set shape         (1014, 12)
6    Transformed test set shape          (436, 12)
7              Numeric features                  9
8          Categorical features                  2
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name   reg-default-name
21                          USI               f973
2025-01-21 21:36:02,165:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:02,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:02,243:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:02,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:02,246:INFO:setup() successfully completed in 1.44s...............
2025-01-21 21:36:04,842:INFO:PyCaret RegressionExperiment
2025-01-21 21:36:04,842:INFO:Logging name: reg-default-name
2025-01-21 21:36:04,842:INFO:ML Usecase: MLUsecase.REGRESSION
2025-01-21 21:36:04,842:INFO:version 3.3.1
2025-01-21 21:36:04,842:INFO:Initializing setup()
2025-01-21 21:36:04,842:INFO:self.USI: c874
2025-01-21 21:36:04,842:INFO:self._variable_keys: {'n_jobs_param', '_ml_usecase', 'idx', 'y', 'target_param', 'fold_groups_param', 'X', 'logging_param', 'X_train', 'y_test', 'fold_generator', 'exp_id', 'html_param', 'transform_target_param', 'gpu_n_jobs_param', 'memory', '_available_plots', 'USI', 'log_plots_param', 'y_train', 'exp_name_log', 'data', 'X_test', 'seed', 'pipeline', 'fold_shuffle_param', 'gpu_param'}
2025-01-21 21:36:04,842:INFO:Checking environment
2025-01-21 21:36:04,842:INFO:python_version: 3.10.13
2025-01-21 21:36:04,842:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-21 21:36:04,842:INFO:machine: arm64
2025-01-21 21:36:04,843:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-21 21:36:04,843:INFO:Memory: svmem(total=8589934592, available=1824538624, percent=78.8, used=3189833728, free=65519616, active=1787543552, inactive=1755299840, wired=1402290176)
2025-01-21 21:36:04,843:INFO:Physical Core: 8
2025-01-21 21:36:04,843:INFO:Logical Core: 8
2025-01-21 21:36:04,843:INFO:Checking libraries
2025-01-21 21:36:04,843:INFO:System:
2025-01-21 21:36:04,843:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-21 21:36:04,843:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-21 21:36:04,843:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-21 21:36:04,843:INFO:PyCaret required dependencies:
2025-01-21 21:36:04,843:INFO:                 pip: 24.2
2025-01-21 21:36:04,843:INFO:          setuptools: 75.1.0
2025-01-21 21:36:04,843:INFO:             pycaret: 3.3.1
2025-01-21 21:36:04,843:INFO:             IPython: 8.27.0
2025-01-21 21:36:04,843:INFO:          ipywidgets: 8.1.2
2025-01-21 21:36:04,843:INFO:                tqdm: 4.66.5
2025-01-21 21:36:04,843:INFO:               numpy: 1.26.4
2025-01-21 21:36:04,843:INFO:              pandas: 2.1.4
2025-01-21 21:36:04,843:INFO:              jinja2: 3.1.4
2025-01-21 21:36:04,843:INFO:               scipy: 1.11.4
2025-01-21 21:36:04,843:INFO:              joblib: 1.3.2
2025-01-21 21:36:04,843:INFO:             sklearn: 1.4.2
2025-01-21 21:36:04,844:INFO:                pyod: 2.0.2
2025-01-21 21:36:04,844:INFO:            imblearn: 0.13.0
2025-01-21 21:36:04,844:INFO:   category_encoders: 2.7.0
2025-01-21 21:36:04,844:INFO:            lightgbm: 4.4.0
2025-01-21 21:36:04,844:INFO:               numba: 0.60.0
2025-01-21 21:36:04,844:INFO:            requests: 2.32.3
2025-01-21 21:36:04,844:INFO:          matplotlib: 3.9.2
2025-01-21 21:36:04,844:INFO:          scikitplot: 0.3.7
2025-01-21 21:36:04,844:INFO:         yellowbrick: 1.5
2025-01-21 21:36:04,844:INFO:              plotly: 5.24.1
2025-01-21 21:36:04,844:INFO:    plotly-resampler: Not installed
2025-01-21 21:36:04,844:INFO:             kaleido: 0.2.1
2025-01-21 21:36:04,844:INFO:           schemdraw: 0.15
2025-01-21 21:36:04,844:INFO:         statsmodels: 0.14.4
2025-01-21 21:36:04,844:INFO:              sktime: 0.26.0
2025-01-21 21:36:04,844:INFO:               tbats: 1.1.3
2025-01-21 21:36:04,844:INFO:            pmdarima: 2.0.4
2025-01-21 21:36:04,844:INFO:              psutil: 5.9.0
2025-01-21 21:36:04,844:INFO:          markupsafe: 2.1.3
2025-01-21 21:36:04,844:INFO:             pickle5: Not installed
2025-01-21 21:36:04,844:INFO:         cloudpickle: 3.1.0
2025-01-21 21:36:04,844:INFO:         deprecation: 2.1.0
2025-01-21 21:36:04,844:INFO:              xxhash: 3.5.0
2025-01-21 21:36:04,844:INFO:           wurlitzer: 3.1.1
2025-01-21 21:36:04,844:INFO:PyCaret optional dependencies:
2025-01-21 21:36:04,844:INFO:                shap: 0.46.0
2025-01-21 21:36:04,844:INFO:           interpret: Not installed
2025-01-21 21:36:04,844:INFO:                umap: 0.5.7
2025-01-21 21:36:04,844:INFO:     ydata_profiling: Not installed
2025-01-21 21:36:04,844:INFO:  explainerdashboard: Not installed
2025-01-21 21:36:04,844:INFO:             autoviz: Not installed
2025-01-21 21:36:04,844:INFO:           fairlearn: Not installed
2025-01-21 21:36:04,844:INFO:          deepchecks: Not installed
2025-01-21 21:36:04,844:INFO:             xgboost: 2.1.3
2025-01-21 21:36:04,844:INFO:            catboost: Not installed
2025-01-21 21:36:04,844:INFO:              kmodes: Not installed
2025-01-21 21:36:04,844:INFO:             mlxtend: Not installed
2025-01-21 21:36:04,844:INFO:       statsforecast: Not installed
2025-01-21 21:36:04,844:INFO:        tune_sklearn: Not installed
2025-01-21 21:36:04,844:INFO:                 ray: Not installed
2025-01-21 21:36:04,844:INFO:            hyperopt: Not installed
2025-01-21 21:36:04,845:INFO:              optuna: Not installed
2025-01-21 21:36:04,845:INFO:               skopt: Not installed
2025-01-21 21:36:04,845:INFO:              mlflow: 2.19.0
2025-01-21 21:36:04,845:INFO:              gradio: Not installed
2025-01-21 21:36:04,845:INFO:             fastapi: Not installed
2025-01-21 21:36:04,845:INFO:             uvicorn: Not installed
2025-01-21 21:36:04,845:INFO:              m2cgen: Not installed
2025-01-21 21:36:04,845:INFO:           evidently: Not installed
2025-01-21 21:36:04,845:INFO:               fugue: Not installed
2025-01-21 21:36:04,845:INFO:           streamlit: Not installed
2025-01-21 21:36:04,845:INFO:             prophet: Not installed
2025-01-21 21:36:04,845:INFO:None
2025-01-21 21:36:04,845:INFO:Set up data.
2025-01-21 21:36:04,851:INFO:Set up folding strategy.
2025-01-21 21:36:04,851:INFO:Set up train/test split.
2025-01-21 21:36:04,854:INFO:Set up index.
2025-01-21 21:36:04,854:INFO:Assigning column types.
2025-01-21 21:36:04,857:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-21 21:36:04,857:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:36:04,860:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:36:04,864:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:04,904:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:04,935:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:04,936:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:04,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:04,938:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:36:04,941:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:36:04,944:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:04,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,016:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,019:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-01-21 21:36:05,022:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,025:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,096:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,102:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,105:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,176:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,178:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-01-21 21:36:05,184:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,256:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,264:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,304:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,335:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,337:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-01-21 21:36:05,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,414:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,492:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,494:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-21 21:36:05,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,570:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:36:05,648:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,650:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-01-21 21:36:05,725:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,803:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:05,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:05,806:INFO:Preparing preprocessing pipeline...
2025-01-21 21:36:05,806:INFO:Set up simple imputation.
2025-01-21 21:36:05,808:INFO:Set up encoding of categorical features.
2025-01-21 21:36:05,808:INFO:Set up column name cleaning.
2025-01-21 21:36:05,859:INFO:Finished creating preprocessing pipeline.
2025-01-21 21:36:05,864:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone',
                                             'Hispanic or Latino'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-01-21 21:36:05,864:INFO:Creating final display dataframe.
2025-01-21 21:36:06,028:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target  Female Population
2                   Target type         Regression
3           Original data shape         (1450, 12)
4        Transformed data shape         (1450, 12)
5   Transformed train set shape         (1014, 12)
6    Transformed test set shape          (436, 12)
7              Numeric features                  9
8          Categorical features                  2
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name   reg-default-name
21                          USI               c874
2025-01-21 21:36:06,111:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:06,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:06,189:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:36:06,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:36:06,191:INFO:setup() successfully completed in 1.35s...............
2025-01-21 21:36:06,195:INFO:Initializing compare_models()
2025-01-21 21:36:06,195:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-01-21 21:36:06,195:INFO:Checking exceptions
2025-01-21 21:36:06,197:INFO:Preparing display monitor
2025-01-21 21:36:06,216:INFO:Initializing Linear Regression
2025-01-21 21:36:06,216:INFO:Total runtime is 3.0001004536946616e-06 minutes
2025-01-21 21:36:06,219:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:06,219:INFO:Initializing create_model()
2025-01-21 21:36:06,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:06,219:INFO:Checking exceptions
2025-01-21 21:36:06,219:INFO:Importing libraries
2025-01-21 21:36:06,219:INFO:Copying training dataset
2025-01-21 21:36:06,225:INFO:Defining folds
2025-01-21 21:36:06,225:INFO:Declaring metric variables
2025-01-21 21:36:06,227:INFO:Importing untrained model
2025-01-21 21:36:06,230:INFO:Linear Regression Imported successfully
2025-01-21 21:36:06,235:INFO:Starting cross validation
2025-01-21 21:36:06,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:06,461:INFO:Calculating mean and std
2025-01-21 21:36:06,462:INFO:Creating metrics dataframe
2025-01-21 21:36:06,463:INFO:Uploading results into container
2025-01-21 21:36:06,463:INFO:Uploading model into container now
2025-01-21 21:36:06,464:INFO:_master_model_container: 1
2025-01-21 21:36:06,464:INFO:_display_container: 2
2025-01-21 21:36:06,464:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:36:06,464:INFO:create_model() successfully completed......................................
2025-01-21 21:36:06,640:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:06,640:INFO:Creating metrics dataframe
2025-01-21 21:36:06,645:INFO:Initializing Lasso Regression
2025-01-21 21:36:06,645:INFO:Total runtime is 0.00714804728825887 minutes
2025-01-21 21:36:06,648:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:06,648:INFO:Initializing create_model()
2025-01-21 21:36:06,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:06,649:INFO:Checking exceptions
2025-01-21 21:36:06,649:INFO:Importing libraries
2025-01-21 21:36:06,649:INFO:Copying training dataset
2025-01-21 21:36:06,652:INFO:Defining folds
2025-01-21 21:36:06,652:INFO:Declaring metric variables
2025-01-21 21:36:06,655:INFO:Importing untrained model
2025-01-21 21:36:06,658:INFO:Lasso Regression Imported successfully
2025-01-21 21:36:06,663:INFO:Starting cross validation
2025-01-21 21:36:06,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:06,843:INFO:Calculating mean and std
2025-01-21 21:36:06,843:INFO:Creating metrics dataframe
2025-01-21 21:36:06,845:INFO:Uploading results into container
2025-01-21 21:36:06,846:INFO:Uploading model into container now
2025-01-21 21:36:06,846:INFO:_master_model_container: 2
2025-01-21 21:36:06,846:INFO:_display_container: 2
2025-01-21 21:36:06,846:INFO:Lasso(random_state=123)
2025-01-21 21:36:06,846:INFO:create_model() successfully completed......................................
2025-01-21 21:36:06,984:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:06,985:INFO:Creating metrics dataframe
2025-01-21 21:36:06,990:INFO:Initializing Ridge Regression
2025-01-21 21:36:06,990:INFO:Total runtime is 0.012894900639851888 minutes
2025-01-21 21:36:06,992:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:06,993:INFO:Initializing create_model()
2025-01-21 21:36:06,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:06,993:INFO:Checking exceptions
2025-01-21 21:36:06,993:INFO:Importing libraries
2025-01-21 21:36:06,993:INFO:Copying training dataset
2025-01-21 21:36:06,996:INFO:Defining folds
2025-01-21 21:36:06,996:INFO:Declaring metric variables
2025-01-21 21:36:06,999:INFO:Importing untrained model
2025-01-21 21:36:07,001:INFO:Ridge Regression Imported successfully
2025-01-21 21:36:07,005:INFO:Starting cross validation
2025-01-21 21:36:07,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:07,136:INFO:Calculating mean and std
2025-01-21 21:36:07,136:INFO:Creating metrics dataframe
2025-01-21 21:36:07,138:INFO:Uploading results into container
2025-01-21 21:36:07,138:INFO:Uploading model into container now
2025-01-21 21:36:07,138:INFO:_master_model_container: 3
2025-01-21 21:36:07,138:INFO:_display_container: 2
2025-01-21 21:36:07,139:INFO:Ridge(random_state=123)
2025-01-21 21:36:07,139:INFO:create_model() successfully completed......................................
2025-01-21 21:36:07,236:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:07,237:INFO:Creating metrics dataframe
2025-01-21 21:36:07,242:INFO:Initializing Elastic Net
2025-01-21 21:36:07,242:INFO:Total runtime is 0.0170952836672465 minutes
2025-01-21 21:36:07,244:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:07,245:INFO:Initializing create_model()
2025-01-21 21:36:07,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:07,245:INFO:Checking exceptions
2025-01-21 21:36:07,245:INFO:Importing libraries
2025-01-21 21:36:07,245:INFO:Copying training dataset
2025-01-21 21:36:07,249:INFO:Defining folds
2025-01-21 21:36:07,249:INFO:Declaring metric variables
2025-01-21 21:36:07,251:INFO:Importing untrained model
2025-01-21 21:36:07,254:INFO:Elastic Net Imported successfully
2025-01-21 21:36:07,260:INFO:Starting cross validation
2025-01-21 21:36:07,261:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:07,413:INFO:Calculating mean and std
2025-01-21 21:36:07,414:INFO:Creating metrics dataframe
2025-01-21 21:36:07,416:INFO:Uploading results into container
2025-01-21 21:36:07,416:INFO:Uploading model into container now
2025-01-21 21:36:07,416:INFO:_master_model_container: 4
2025-01-21 21:36:07,417:INFO:_display_container: 2
2025-01-21 21:36:07,417:INFO:ElasticNet(random_state=123)
2025-01-21 21:36:07,417:INFO:create_model() successfully completed......................................
2025-01-21 21:36:07,512:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:07,512:INFO:Creating metrics dataframe
2025-01-21 21:36:07,518:INFO:Initializing Least Angle Regression
2025-01-21 21:36:07,518:INFO:Total runtime is 0.02169573704401652 minutes
2025-01-21 21:36:07,520:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:07,521:INFO:Initializing create_model()
2025-01-21 21:36:07,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:07,521:INFO:Checking exceptions
2025-01-21 21:36:07,521:INFO:Importing libraries
2025-01-21 21:36:07,521:INFO:Copying training dataset
2025-01-21 21:36:07,525:INFO:Defining folds
2025-01-21 21:36:07,525:INFO:Declaring metric variables
2025-01-21 21:36:07,527:INFO:Importing untrained model
2025-01-21 21:36:07,530:INFO:Least Angle Regression Imported successfully
2025-01-21 21:36:07,534:INFO:Starting cross validation
2025-01-21 21:36:07,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:07,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.401e+05, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,609:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.861e+05, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,610:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.179e+05, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,610:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.447e+05, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,610:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.685e+04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,610:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.132e+04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.269e+04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.863e+03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.653e+03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.042e+03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.269e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.634e+02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.128e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,611:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.853e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,615:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.989e+04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,616:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.348e+04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,616:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.507e+03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,616:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.534e+03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,616:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.534e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,617:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.315e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.672e+05, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.997e+05, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,647:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.396e+04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,648:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.996e+04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,648:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.482e+04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,648:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.969e+02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,648:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.974e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,668:INFO:Calculating mean and std
2025-01-21 21:36:07,669:INFO:Creating metrics dataframe
2025-01-21 21:36:07,670:INFO:Uploading results into container
2025-01-21 21:36:07,670:INFO:Uploading model into container now
2025-01-21 21:36:07,671:INFO:_master_model_container: 5
2025-01-21 21:36:07,671:INFO:_display_container: 2
2025-01-21 21:36:07,671:INFO:Lars(random_state=123)
2025-01-21 21:36:07,671:INFO:create_model() successfully completed......................................
2025-01-21 21:36:07,767:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:07,767:INFO:Creating metrics dataframe
2025-01-21 21:36:07,773:INFO:Initializing Lasso Least Angle Regression
2025-01-21 21:36:07,773:INFO:Total runtime is 0.025942218303680417 minutes
2025-01-21 21:36:07,775:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:07,775:INFO:Initializing create_model()
2025-01-21 21:36:07,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:07,775:INFO:Checking exceptions
2025-01-21 21:36:07,775:INFO:Importing libraries
2025-01-21 21:36:07,776:INFO:Copying training dataset
2025-01-21 21:36:07,779:INFO:Defining folds
2025-01-21 21:36:07,779:INFO:Declaring metric variables
2025-01-21 21:36:07,782:INFO:Importing untrained model
2025-01-21 21:36:07,784:INFO:Lasso Least Angle Regression Imported successfully
2025-01-21 21:36:07,788:INFO:Starting cross validation
2025-01-21 21:36:07,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:07,856:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.861e+05, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,856:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.179e+05, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.132e+04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.401e+05, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.863e+03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.447e+05, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.042e+03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.685e+04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.634e+02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=8.634e+02, previous alpha=6.275e+01, with an active set of 9 regressors.
  warnings.warn(

2025-01-21 21:36:07,857:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.269e+04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,858:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.653e+03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,858:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.269e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,858:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.989e+04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,859:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.348e+04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,859:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.507e+03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,859:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.534e+03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,859:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.534e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,860:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=1.537e+04, previous alpha=1.477e+01, with an active set of 8 regressors.
  warnings.warn(

2025-01-21 21:36:07,889:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.672e+05, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,890:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.997e+05, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,890:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.396e+04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,890:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.996e+04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,890:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.482e+04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,890:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.969e+02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,891:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.974e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:36:07,915:INFO:Calculating mean and std
2025-01-21 21:36:07,916:INFO:Creating metrics dataframe
2025-01-21 21:36:07,918:INFO:Uploading results into container
2025-01-21 21:36:07,918:INFO:Uploading model into container now
2025-01-21 21:36:07,918:INFO:_master_model_container: 6
2025-01-21 21:36:07,919:INFO:_display_container: 2
2025-01-21 21:36:07,919:INFO:LassoLars(random_state=123)
2025-01-21 21:36:07,919:INFO:create_model() successfully completed......................................
2025-01-21 21:36:08,015:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:08,015:INFO:Creating metrics dataframe
2025-01-21 21:36:08,021:INFO:Initializing Orthogonal Matching Pursuit
2025-01-21 21:36:08,021:INFO:Total runtime is 0.030082901318867997 minutes
2025-01-21 21:36:08,023:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:08,024:INFO:Initializing create_model()
2025-01-21 21:36:08,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:08,024:INFO:Checking exceptions
2025-01-21 21:36:08,024:INFO:Importing libraries
2025-01-21 21:36:08,024:INFO:Copying training dataset
2025-01-21 21:36:08,028:INFO:Defining folds
2025-01-21 21:36:08,028:INFO:Declaring metric variables
2025-01-21 21:36:08,030:INFO:Importing untrained model
2025-01-21 21:36:08,033:INFO:Orthogonal Matching Pursuit Imported successfully
2025-01-21 21:36:08,038:INFO:Starting cross validation
2025-01-21 21:36:08,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:08,174:INFO:Calculating mean and std
2025-01-21 21:36:08,175:INFO:Creating metrics dataframe
2025-01-21 21:36:08,177:INFO:Uploading results into container
2025-01-21 21:36:08,177:INFO:Uploading model into container now
2025-01-21 21:36:08,178:INFO:_master_model_container: 7
2025-01-21 21:36:08,178:INFO:_display_container: 2
2025-01-21 21:36:08,178:INFO:OrthogonalMatchingPursuit()
2025-01-21 21:36:08,178:INFO:create_model() successfully completed......................................
2025-01-21 21:36:08,274:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:08,274:INFO:Creating metrics dataframe
2025-01-21 21:36:08,280:INFO:Initializing Bayesian Ridge
2025-01-21 21:36:08,281:INFO:Total runtime is 0.03440638383229573 minutes
2025-01-21 21:36:08,283:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:08,283:INFO:Initializing create_model()
2025-01-21 21:36:08,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:08,283:INFO:Checking exceptions
2025-01-21 21:36:08,283:INFO:Importing libraries
2025-01-21 21:36:08,283:INFO:Copying training dataset
2025-01-21 21:36:08,287:INFO:Defining folds
2025-01-21 21:36:08,287:INFO:Declaring metric variables
2025-01-21 21:36:08,290:INFO:Importing untrained model
2025-01-21 21:36:08,293:INFO:Bayesian Ridge Imported successfully
2025-01-21 21:36:08,323:INFO:Starting cross validation
2025-01-21 21:36:08,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:08,494:INFO:Calculating mean and std
2025-01-21 21:36:08,495:INFO:Creating metrics dataframe
2025-01-21 21:36:08,497:INFO:Uploading results into container
2025-01-21 21:36:08,497:INFO:Uploading model into container now
2025-01-21 21:36:08,498:INFO:_master_model_container: 8
2025-01-21 21:36:08,498:INFO:_display_container: 2
2025-01-21 21:36:08,498:INFO:BayesianRidge()
2025-01-21 21:36:08,498:INFO:create_model() successfully completed......................................
2025-01-21 21:36:08,609:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:08,609:INFO:Creating metrics dataframe
2025-01-21 21:36:08,616:INFO:Initializing Passive Aggressive Regressor
2025-01-21 21:36:08,616:INFO:Total runtime is 0.03999568223953247 minutes
2025-01-21 21:36:08,619:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:08,619:INFO:Initializing create_model()
2025-01-21 21:36:08,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:08,619:INFO:Checking exceptions
2025-01-21 21:36:08,619:INFO:Importing libraries
2025-01-21 21:36:08,619:INFO:Copying training dataset
2025-01-21 21:36:08,624:INFO:Defining folds
2025-01-21 21:36:08,624:INFO:Declaring metric variables
2025-01-21 21:36:08,627:INFO:Importing untrained model
2025-01-21 21:36:08,630:INFO:Passive Aggressive Regressor Imported successfully
2025-01-21 21:36:08,634:INFO:Starting cross validation
2025-01-21 21:36:08,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:08,819:INFO:Calculating mean and std
2025-01-21 21:36:08,820:INFO:Creating metrics dataframe
2025-01-21 21:36:08,822:INFO:Uploading results into container
2025-01-21 21:36:08,823:INFO:Uploading model into container now
2025-01-21 21:36:08,823:INFO:_master_model_container: 9
2025-01-21 21:36:08,823:INFO:_display_container: 2
2025-01-21 21:36:08,824:INFO:PassiveAggressiveRegressor(random_state=123)
2025-01-21 21:36:08,824:INFO:create_model() successfully completed......................................
2025-01-21 21:36:08,926:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:08,927:INFO:Creating metrics dataframe
2025-01-21 21:36:08,934:INFO:Initializing Huber Regressor
2025-01-21 21:36:08,934:INFO:Total runtime is 0.04529683192571004 minutes
2025-01-21 21:36:08,936:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:08,937:INFO:Initializing create_model()
2025-01-21 21:36:08,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:08,937:INFO:Checking exceptions
2025-01-21 21:36:08,937:INFO:Importing libraries
2025-01-21 21:36:08,937:INFO:Copying training dataset
2025-01-21 21:36:08,942:INFO:Defining folds
2025-01-21 21:36:08,942:INFO:Declaring metric variables
2025-01-21 21:36:08,946:INFO:Importing untrained model
2025-01-21 21:36:08,949:INFO:Huber Regressor Imported successfully
2025-01-21 21:36:08,954:INFO:Starting cross validation
2025-01-21 21:36:08,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:09,041:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,052:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,052:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,053:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,072:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,077:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,089:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,099:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,134:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,139:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:36:09,168:INFO:Calculating mean and std
2025-01-21 21:36:09,169:INFO:Creating metrics dataframe
2025-01-21 21:36:09,171:INFO:Uploading results into container
2025-01-21 21:36:09,171:INFO:Uploading model into container now
2025-01-21 21:36:09,172:INFO:_master_model_container: 10
2025-01-21 21:36:09,172:INFO:_display_container: 2
2025-01-21 21:36:09,172:INFO:HuberRegressor()
2025-01-21 21:36:09,172:INFO:create_model() successfully completed......................................
2025-01-21 21:36:09,269:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:09,269:INFO:Creating metrics dataframe
2025-01-21 21:36:09,275:INFO:Initializing K Neighbors Regressor
2025-01-21 21:36:09,276:INFO:Total runtime is 0.05098933378855387 minutes
2025-01-21 21:36:09,278:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:09,278:INFO:Initializing create_model()
2025-01-21 21:36:09,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:09,278:INFO:Checking exceptions
2025-01-21 21:36:09,278:INFO:Importing libraries
2025-01-21 21:36:09,278:INFO:Copying training dataset
2025-01-21 21:36:09,282:INFO:Defining folds
2025-01-21 21:36:09,282:INFO:Declaring metric variables
2025-01-21 21:36:09,285:INFO:Importing untrained model
2025-01-21 21:36:09,287:INFO:K Neighbors Regressor Imported successfully
2025-01-21 21:36:09,292:INFO:Starting cross validation
2025-01-21 21:36:09,294:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:09,441:INFO:Calculating mean and std
2025-01-21 21:36:09,442:INFO:Creating metrics dataframe
2025-01-21 21:36:09,444:INFO:Uploading results into container
2025-01-21 21:36:09,444:INFO:Uploading model into container now
2025-01-21 21:36:09,445:INFO:_master_model_container: 11
2025-01-21 21:36:09,445:INFO:_display_container: 2
2025-01-21 21:36:09,445:INFO:KNeighborsRegressor(n_jobs=-1)
2025-01-21 21:36:09,445:INFO:create_model() successfully completed......................................
2025-01-21 21:36:09,654:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:09,654:INFO:Creating metrics dataframe
2025-01-21 21:36:09,662:INFO:Initializing Decision Tree Regressor
2025-01-21 21:36:09,662:INFO:Total runtime is 0.05742839972178141 minutes
2025-01-21 21:36:09,664:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:09,665:INFO:Initializing create_model()
2025-01-21 21:36:09,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:09,665:INFO:Checking exceptions
2025-01-21 21:36:09,665:INFO:Importing libraries
2025-01-21 21:36:09,665:INFO:Copying training dataset
2025-01-21 21:36:09,669:INFO:Defining folds
2025-01-21 21:36:09,670:INFO:Declaring metric variables
2025-01-21 21:36:09,672:INFO:Importing untrained model
2025-01-21 21:36:09,675:INFO:Decision Tree Regressor Imported successfully
2025-01-21 21:36:09,680:INFO:Starting cross validation
2025-01-21 21:36:09,682:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:09,874:INFO:Calculating mean and std
2025-01-21 21:36:09,875:INFO:Creating metrics dataframe
2025-01-21 21:36:09,878:INFO:Uploading results into container
2025-01-21 21:36:09,878:INFO:Uploading model into container now
2025-01-21 21:36:09,879:INFO:_master_model_container: 12
2025-01-21 21:36:09,879:INFO:_display_container: 2
2025-01-21 21:36:09,879:INFO:DecisionTreeRegressor(random_state=123)
2025-01-21 21:36:09,879:INFO:create_model() successfully completed......................................
2025-01-21 21:36:09,990:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:09,991:INFO:Creating metrics dataframe
2025-01-21 21:36:09,998:INFO:Initializing Random Forest Regressor
2025-01-21 21:36:09,998:INFO:Total runtime is 0.06302768389383952 minutes
2025-01-21 21:36:10,000:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:10,000:INFO:Initializing create_model()
2025-01-21 21:36:10,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:10,001:INFO:Checking exceptions
2025-01-21 21:36:10,001:INFO:Importing libraries
2025-01-21 21:36:10,001:INFO:Copying training dataset
2025-01-21 21:36:10,005:INFO:Defining folds
2025-01-21 21:36:10,005:INFO:Declaring metric variables
2025-01-21 21:36:10,007:INFO:Importing untrained model
2025-01-21 21:36:10,011:INFO:Random Forest Regressor Imported successfully
2025-01-21 21:36:10,016:INFO:Starting cross validation
2025-01-21 21:36:10,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:11,569:INFO:Calculating mean and std
2025-01-21 21:36:11,570:INFO:Creating metrics dataframe
2025-01-21 21:36:11,571:INFO:Uploading results into container
2025-01-21 21:36:11,572:INFO:Uploading model into container now
2025-01-21 21:36:11,572:INFO:_master_model_container: 13
2025-01-21 21:36:11,572:INFO:_display_container: 2
2025-01-21 21:36:11,573:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:36:11,573:INFO:create_model() successfully completed......................................
2025-01-21 21:36:11,667:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:11,667:INFO:Creating metrics dataframe
2025-01-21 21:36:11,674:INFO:Initializing Extra Trees Regressor
2025-01-21 21:36:11,674:INFO:Total runtime is 0.09096053441365559 minutes
2025-01-21 21:36:11,676:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:11,676:INFO:Initializing create_model()
2025-01-21 21:36:11,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:11,676:INFO:Checking exceptions
2025-01-21 21:36:11,676:INFO:Importing libraries
2025-01-21 21:36:11,676:INFO:Copying training dataset
2025-01-21 21:36:11,680:INFO:Defining folds
2025-01-21 21:36:11,680:INFO:Declaring metric variables
2025-01-21 21:36:11,682:INFO:Importing untrained model
2025-01-21 21:36:11,684:INFO:Extra Trees Regressor Imported successfully
2025-01-21 21:36:11,689:INFO:Starting cross validation
2025-01-21 21:36:11,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:12,536:INFO:Calculating mean and std
2025-01-21 21:36:12,537:INFO:Creating metrics dataframe
2025-01-21 21:36:12,539:INFO:Uploading results into container
2025-01-21 21:36:12,539:INFO:Uploading model into container now
2025-01-21 21:36:12,540:INFO:_master_model_container: 14
2025-01-21 21:36:12,540:INFO:_display_container: 2
2025-01-21 21:36:12,540:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:36:12,540:INFO:create_model() successfully completed......................................
2025-01-21 21:36:12,639:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:12,639:INFO:Creating metrics dataframe
2025-01-21 21:36:12,646:INFO:Initializing AdaBoost Regressor
2025-01-21 21:36:12,646:INFO:Total runtime is 0.10716209808985391 minutes
2025-01-21 21:36:12,648:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:12,649:INFO:Initializing create_model()
2025-01-21 21:36:12,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:12,649:INFO:Checking exceptions
2025-01-21 21:36:12,649:INFO:Importing libraries
2025-01-21 21:36:12,649:INFO:Copying training dataset
2025-01-21 21:36:12,653:INFO:Defining folds
2025-01-21 21:36:12,653:INFO:Declaring metric variables
2025-01-21 21:36:12,655:INFO:Importing untrained model
2025-01-21 21:36:12,657:INFO:AdaBoost Regressor Imported successfully
2025-01-21 21:36:12,661:INFO:Starting cross validation
2025-01-21 21:36:12,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:13,270:INFO:Calculating mean and std
2025-01-21 21:36:13,271:INFO:Creating metrics dataframe
2025-01-21 21:36:13,273:INFO:Uploading results into container
2025-01-21 21:36:13,273:INFO:Uploading model into container now
2025-01-21 21:36:13,273:INFO:_master_model_container: 15
2025-01-21 21:36:13,274:INFO:_display_container: 2
2025-01-21 21:36:13,274:INFO:AdaBoostRegressor(random_state=123)
2025-01-21 21:36:13,274:INFO:create_model() successfully completed......................................
2025-01-21 21:36:13,364:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:13,364:INFO:Creating metrics dataframe
2025-01-21 21:36:13,371:INFO:Initializing Gradient Boosting Regressor
2025-01-21 21:36:13,372:INFO:Total runtime is 0.11925465265909829 minutes
2025-01-21 21:36:13,373:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:13,374:INFO:Initializing create_model()
2025-01-21 21:36:13,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:13,374:INFO:Checking exceptions
2025-01-21 21:36:13,374:INFO:Importing libraries
2025-01-21 21:36:13,374:INFO:Copying training dataset
2025-01-21 21:36:13,377:INFO:Defining folds
2025-01-21 21:36:13,377:INFO:Declaring metric variables
2025-01-21 21:36:13,379:INFO:Importing untrained model
2025-01-21 21:36:13,382:INFO:Gradient Boosting Regressor Imported successfully
2025-01-21 21:36:13,387:INFO:Starting cross validation
2025-01-21 21:36:13,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:14,416:INFO:Calculating mean and std
2025-01-21 21:36:14,417:INFO:Creating metrics dataframe
2025-01-21 21:36:14,419:INFO:Uploading results into container
2025-01-21 21:36:14,419:INFO:Uploading model into container now
2025-01-21 21:36:14,419:INFO:_master_model_container: 16
2025-01-21 21:36:14,419:INFO:_display_container: 2
2025-01-21 21:36:14,420:INFO:GradientBoostingRegressor(random_state=123)
2025-01-21 21:36:14,420:INFO:create_model() successfully completed......................................
2025-01-21 21:36:14,508:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:14,508:INFO:Creating metrics dataframe
2025-01-21 21:36:14,515:INFO:Initializing Extreme Gradient Boosting
2025-01-21 21:36:14,516:INFO:Total runtime is 0.13832209904988604 minutes
2025-01-21 21:36:14,517:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:14,518:INFO:Initializing create_model()
2025-01-21 21:36:14,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:14,518:INFO:Checking exceptions
2025-01-21 21:36:14,518:INFO:Importing libraries
2025-01-21 21:36:14,518:INFO:Copying training dataset
2025-01-21 21:36:14,521:INFO:Defining folds
2025-01-21 21:36:14,521:INFO:Declaring metric variables
2025-01-21 21:36:14,523:INFO:Importing untrained model
2025-01-21 21:36:14,526:INFO:Extreme Gradient Boosting Imported successfully
2025-01-21 21:36:14,533:INFO:Starting cross validation
2025-01-21 21:36:14,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:15,070:INFO:Calculating mean and std
2025-01-21 21:36:15,071:INFO:Creating metrics dataframe
2025-01-21 21:36:15,072:INFO:Uploading results into container
2025-01-21 21:36:15,073:INFO:Uploading model into container now
2025-01-21 21:36:15,073:INFO:_master_model_container: 17
2025-01-21 21:36:15,073:INFO:_display_container: 2
2025-01-21 21:36:15,074:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2025-01-21 21:36:15,074:INFO:create_model() successfully completed......................................
2025-01-21 21:36:15,165:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:15,165:INFO:Creating metrics dataframe
2025-01-21 21:36:15,172:INFO:Initializing Light Gradient Boosting Machine
2025-01-21 21:36:15,172:INFO:Total runtime is 0.14926585356394448 minutes
2025-01-21 21:36:15,174:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:15,174:INFO:Initializing create_model()
2025-01-21 21:36:15,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:15,175:INFO:Checking exceptions
2025-01-21 21:36:15,175:INFO:Importing libraries
2025-01-21 21:36:15,175:INFO:Copying training dataset
2025-01-21 21:36:15,178:INFO:Defining folds
2025-01-21 21:36:15,178:INFO:Declaring metric variables
2025-01-21 21:36:15,180:INFO:Importing untrained model
2025-01-21 21:36:15,182:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-21 21:36:15,186:INFO:Starting cross validation
2025-01-21 21:36:15,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:17,959:INFO:Calculating mean and std
2025-01-21 21:36:17,959:INFO:Creating metrics dataframe
2025-01-21 21:36:17,961:INFO:Uploading results into container
2025-01-21 21:36:17,961:INFO:Uploading model into container now
2025-01-21 21:36:17,961:INFO:_master_model_container: 18
2025-01-21 21:36:17,961:INFO:_display_container: 2
2025-01-21 21:36:17,962:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:36:17,962:INFO:create_model() successfully completed......................................
2025-01-21 21:36:18,053:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:18,053:INFO:Creating metrics dataframe
2025-01-21 21:36:18,061:INFO:Initializing Dummy Regressor
2025-01-21 21:36:18,061:INFO:Total runtime is 0.19741489887237545 minutes
2025-01-21 21:36:18,063:INFO:SubProcess create_model() called ==================================
2025-01-21 21:36:18,063:INFO:Initializing create_model()
2025-01-21 21:36:18,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x168cc50c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:18,063:INFO:Checking exceptions
2025-01-21 21:36:18,063:INFO:Importing libraries
2025-01-21 21:36:18,063:INFO:Copying training dataset
2025-01-21 21:36:18,067:INFO:Defining folds
2025-01-21 21:36:18,067:INFO:Declaring metric variables
2025-01-21 21:36:18,090:INFO:Importing untrained model
2025-01-21 21:36:18,096:INFO:Dummy Regressor Imported successfully
2025-01-21 21:36:18,106:INFO:Starting cross validation
2025-01-21 21:36:18,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:36:18,217:INFO:Calculating mean and std
2025-01-21 21:36:18,218:INFO:Creating metrics dataframe
2025-01-21 21:36:18,219:INFO:Uploading results into container
2025-01-21 21:36:18,220:INFO:Uploading model into container now
2025-01-21 21:36:18,220:INFO:_master_model_container: 19
2025-01-21 21:36:18,220:INFO:_display_container: 2
2025-01-21 21:36:18,220:INFO:DummyRegressor()
2025-01-21 21:36:18,220:INFO:create_model() successfully completed......................................
2025-01-21 21:36:18,310:INFO:SubProcess create_model() end ==================================
2025-01-21 21:36:18,310:INFO:Creating metrics dataframe
2025-01-21 21:36:18,319:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-21 21:36:18,324:INFO:Initializing create_model()
2025-01-21 21:36:18,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15ce2d2d0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:36:18,324:INFO:Checking exceptions
2025-01-21 21:36:18,325:INFO:Importing libraries
2025-01-21 21:36:18,326:INFO:Copying training dataset
2025-01-21 21:36:18,329:INFO:Defining folds
2025-01-21 21:36:18,329:INFO:Declaring metric variables
2025-01-21 21:36:18,330:INFO:Importing untrained model
2025-01-21 21:36:18,330:INFO:Declaring custom model
2025-01-21 21:36:18,330:INFO:Linear Regression Imported successfully
2025-01-21 21:36:18,331:INFO:Cross validation set to False
2025-01-21 21:36:18,331:INFO:Fitting Model
2025-01-21 21:36:18,357:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:36:18,357:INFO:create_model() successfully completed......................................
2025-01-21 21:36:18,464:INFO:_master_model_container: 19
2025-01-21 21:36:18,464:INFO:_display_container: 2
2025-01-21 21:36:18,464:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:36:18,464:INFO:compare_models() successfully completed......................................
2025-01-21 21:37:02,805:INFO:PyCaret RegressionExperiment
2025-01-21 21:37:02,806:INFO:Logging name: reg-default-name
2025-01-21 21:37:02,806:INFO:ML Usecase: MLUsecase.REGRESSION
2025-01-21 21:37:02,806:INFO:version 3.3.1
2025-01-21 21:37:02,806:INFO:Initializing setup()
2025-01-21 21:37:02,806:INFO:self.USI: 5633
2025-01-21 21:37:02,806:INFO:self._variable_keys: {'n_jobs_param', '_ml_usecase', 'idx', 'y', 'target_param', 'fold_groups_param', 'X', 'logging_param', 'X_train', 'y_test', 'fold_generator', 'exp_id', 'html_param', 'transform_target_param', 'gpu_n_jobs_param', 'memory', '_available_plots', 'USI', 'log_plots_param', 'y_train', 'exp_name_log', 'data', 'X_test', 'seed', 'pipeline', 'fold_shuffle_param', 'gpu_param'}
2025-01-21 21:37:02,806:INFO:Checking environment
2025-01-21 21:37:02,806:INFO:python_version: 3.10.13
2025-01-21 21:37:02,806:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-21 21:37:02,806:INFO:machine: arm64
2025-01-21 21:37:02,806:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-21 21:37:02,806:INFO:Memory: svmem(total=8589934592, available=1943027712, percent=77.4, used=3286646784, free=74612736, active=1883799552, inactive=1865875456, wired=1402847232)
2025-01-21 21:37:02,806:INFO:Physical Core: 8
2025-01-21 21:37:02,806:INFO:Logical Core: 8
2025-01-21 21:37:02,806:INFO:Checking libraries
2025-01-21 21:37:02,806:INFO:System:
2025-01-21 21:37:02,806:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-21 21:37:02,806:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-21 21:37:02,806:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-21 21:37:02,806:INFO:PyCaret required dependencies:
2025-01-21 21:37:02,806:INFO:                 pip: 24.2
2025-01-21 21:37:02,807:INFO:          setuptools: 75.1.0
2025-01-21 21:37:02,807:INFO:             pycaret: 3.3.1
2025-01-21 21:37:02,807:INFO:             IPython: 8.27.0
2025-01-21 21:37:02,807:INFO:          ipywidgets: 8.1.2
2025-01-21 21:37:02,807:INFO:                tqdm: 4.66.5
2025-01-21 21:37:02,807:INFO:               numpy: 1.26.4
2025-01-21 21:37:02,807:INFO:              pandas: 2.1.4
2025-01-21 21:37:02,807:INFO:              jinja2: 3.1.4
2025-01-21 21:37:02,807:INFO:               scipy: 1.11.4
2025-01-21 21:37:02,807:INFO:              joblib: 1.3.2
2025-01-21 21:37:02,807:INFO:             sklearn: 1.4.2
2025-01-21 21:37:02,807:INFO:                pyod: 2.0.2
2025-01-21 21:37:02,807:INFO:            imblearn: 0.13.0
2025-01-21 21:37:02,807:INFO:   category_encoders: 2.7.0
2025-01-21 21:37:02,807:INFO:            lightgbm: 4.4.0
2025-01-21 21:37:02,807:INFO:               numba: 0.60.0
2025-01-21 21:37:02,807:INFO:            requests: 2.32.3
2025-01-21 21:37:02,807:INFO:          matplotlib: 3.9.2
2025-01-21 21:37:02,807:INFO:          scikitplot: 0.3.7
2025-01-21 21:37:02,807:INFO:         yellowbrick: 1.5
2025-01-21 21:37:02,807:INFO:              plotly: 5.24.1
2025-01-21 21:37:02,807:INFO:    plotly-resampler: Not installed
2025-01-21 21:37:02,807:INFO:             kaleido: 0.2.1
2025-01-21 21:37:02,807:INFO:           schemdraw: 0.15
2025-01-21 21:37:02,807:INFO:         statsmodels: 0.14.4
2025-01-21 21:37:02,807:INFO:              sktime: 0.26.0
2025-01-21 21:37:02,807:INFO:               tbats: 1.1.3
2025-01-21 21:37:02,807:INFO:            pmdarima: 2.0.4
2025-01-21 21:37:02,808:INFO:              psutil: 5.9.0
2025-01-21 21:37:02,808:INFO:          markupsafe: 2.1.3
2025-01-21 21:37:02,808:INFO:             pickle5: Not installed
2025-01-21 21:37:02,808:INFO:         cloudpickle: 3.1.0
2025-01-21 21:37:02,808:INFO:         deprecation: 2.1.0
2025-01-21 21:37:02,808:INFO:              xxhash: 3.5.0
2025-01-21 21:37:02,808:INFO:           wurlitzer: 3.1.1
2025-01-21 21:37:02,808:INFO:PyCaret optional dependencies:
2025-01-21 21:37:02,808:INFO:                shap: 0.46.0
2025-01-21 21:37:02,808:INFO:           interpret: Not installed
2025-01-21 21:37:02,808:INFO:                umap: 0.5.7
2025-01-21 21:37:02,808:INFO:     ydata_profiling: Not installed
2025-01-21 21:37:02,808:INFO:  explainerdashboard: Not installed
2025-01-21 21:37:02,808:INFO:             autoviz: Not installed
2025-01-21 21:37:02,808:INFO:           fairlearn: Not installed
2025-01-21 21:37:02,808:INFO:          deepchecks: Not installed
2025-01-21 21:37:02,808:INFO:             xgboost: 2.1.3
2025-01-21 21:37:02,808:INFO:            catboost: Not installed
2025-01-21 21:37:02,808:INFO:              kmodes: Not installed
2025-01-21 21:37:02,808:INFO:             mlxtend: Not installed
2025-01-21 21:37:02,808:INFO:       statsforecast: Not installed
2025-01-21 21:37:02,808:INFO:        tune_sklearn: Not installed
2025-01-21 21:37:02,808:INFO:                 ray: Not installed
2025-01-21 21:37:02,808:INFO:            hyperopt: Not installed
2025-01-21 21:37:02,808:INFO:              optuna: Not installed
2025-01-21 21:37:02,808:INFO:               skopt: Not installed
2025-01-21 21:37:02,808:INFO:              mlflow: 2.19.0
2025-01-21 21:37:02,808:INFO:              gradio: Not installed
2025-01-21 21:37:02,808:INFO:             fastapi: Not installed
2025-01-21 21:37:02,808:INFO:             uvicorn: Not installed
2025-01-21 21:37:02,808:INFO:              m2cgen: Not installed
2025-01-21 21:37:02,808:INFO:           evidently: Not installed
2025-01-21 21:37:02,808:INFO:               fugue: Not installed
2025-01-21 21:37:02,808:INFO:           streamlit: Not installed
2025-01-21 21:37:02,808:INFO:             prophet: Not installed
2025-01-21 21:37:02,808:INFO:None
2025-01-21 21:37:02,808:INFO:Set up data.
2025-01-21 21:37:02,815:INFO:Set up folding strategy.
2025-01-21 21:37:02,816:INFO:Set up train/test split.
2025-01-21 21:37:02,819:INFO:Set up index.
2025-01-21 21:37:02,819:INFO:Assigning column types.
2025-01-21 21:37:02,821:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-21 21:37:02,822:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,825:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,828:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,900:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:02,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:02,902:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,905:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,978:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:02,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:02,981:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-01-21 21:37:02,984:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:37:02,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,057:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,062:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,065:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,105:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,136:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,138:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-01-21 21:37:03,144:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,217:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,217:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,225:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,266:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,296:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,297:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,299:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-01-21 21:37:03,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,376:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,455:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,456:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-21 21:37:03,502:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,532:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:37:03,610:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,612:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-01-21 21:37:03,687:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,764:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:03,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:03,768:INFO:Preparing preprocessing pipeline...
2025-01-21 21:37:03,768:INFO:Set up simple imputation.
2025-01-21 21:37:03,770:INFO:Set up encoding of categorical features.
2025-01-21 21:37:03,770:INFO:Set up column name cleaning.
2025-01-21 21:37:03,819:INFO:Finished creating preprocessing pipeline.
2025-01-21 21:37:03,824:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone',
                                             'Hispanic or Latino'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-01-21 21:37:03,824:INFO:Creating final display dataframe.
2025-01-21 21:37:03,964:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target  Female Population
2                   Target type         Regression
3           Original data shape         (2900, 12)
4        Transformed data shape         (2900, 12)
5   Transformed train set shape         (2029, 12)
6    Transformed test set shape          (871, 12)
7              Numeric features                  9
8          Categorical features                  2
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name   reg-default-name
21                          USI               5633
2025-01-21 21:37:04,046:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:04,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:04,124:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:37:04,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:37:04,127:INFO:setup() successfully completed in 1.32s...............
2025-01-21 21:37:04,130:INFO:Initializing compare_models()
2025-01-21 21:37:04,131:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-01-21 21:37:04,131:INFO:Checking exceptions
2025-01-21 21:37:04,133:INFO:Preparing display monitor
2025-01-21 21:37:04,148:INFO:Initializing Linear Regression
2025-01-21 21:37:04,149:INFO:Total runtime is 2.9802322387695312e-06 minutes
2025-01-21 21:37:04,151:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:04,151:INFO:Initializing create_model()
2025-01-21 21:37:04,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:04,151:INFO:Checking exceptions
2025-01-21 21:37:04,151:INFO:Importing libraries
2025-01-21 21:37:04,151:INFO:Copying training dataset
2025-01-21 21:37:04,158:INFO:Defining folds
2025-01-21 21:37:04,158:INFO:Declaring metric variables
2025-01-21 21:37:04,160:INFO:Importing untrained model
2025-01-21 21:37:04,162:INFO:Linear Regression Imported successfully
2025-01-21 21:37:04,166:INFO:Starting cross validation
2025-01-21 21:37:04,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:04,339:INFO:Calculating mean and std
2025-01-21 21:37:04,339:INFO:Creating metrics dataframe
2025-01-21 21:37:04,341:INFO:Uploading results into container
2025-01-21 21:37:04,341:INFO:Uploading model into container now
2025-01-21 21:37:04,342:INFO:_master_model_container: 1
2025-01-21 21:37:04,342:INFO:_display_container: 2
2025-01-21 21:37:04,342:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:37:04,342:INFO:create_model() successfully completed......................................
2025-01-21 21:37:04,523:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:04,523:INFO:Creating metrics dataframe
2025-01-21 21:37:04,528:INFO:Initializing Lasso Regression
2025-01-21 21:37:04,528:INFO:Total runtime is 0.006327533721923828 minutes
2025-01-21 21:37:04,530:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:04,530:INFO:Initializing create_model()
2025-01-21 21:37:04,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:04,531:INFO:Checking exceptions
2025-01-21 21:37:04,531:INFO:Importing libraries
2025-01-21 21:37:04,531:INFO:Copying training dataset
2025-01-21 21:37:04,534:INFO:Defining folds
2025-01-21 21:37:04,534:INFO:Declaring metric variables
2025-01-21 21:37:04,536:INFO:Importing untrained model
2025-01-21 21:37:04,538:INFO:Lasso Regression Imported successfully
2025-01-21 21:37:04,542:INFO:Starting cross validation
2025-01-21 21:37:04,543:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:04,695:INFO:Calculating mean and std
2025-01-21 21:37:04,696:INFO:Creating metrics dataframe
2025-01-21 21:37:04,697:INFO:Uploading results into container
2025-01-21 21:37:04,697:INFO:Uploading model into container now
2025-01-21 21:37:04,698:INFO:_master_model_container: 2
2025-01-21 21:37:04,698:INFO:_display_container: 2
2025-01-21 21:37:04,698:INFO:Lasso(random_state=123)
2025-01-21 21:37:04,698:INFO:create_model() successfully completed......................................
2025-01-21 21:37:04,817:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:04,817:INFO:Creating metrics dataframe
2025-01-21 21:37:04,821:INFO:Initializing Ridge Regression
2025-01-21 21:37:04,822:INFO:Total runtime is 0.011218814055124919 minutes
2025-01-21 21:37:04,824:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:04,824:INFO:Initializing create_model()
2025-01-21 21:37:04,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:04,824:INFO:Checking exceptions
2025-01-21 21:37:04,824:INFO:Importing libraries
2025-01-21 21:37:04,824:INFO:Copying training dataset
2025-01-21 21:37:04,828:INFO:Defining folds
2025-01-21 21:37:04,828:INFO:Declaring metric variables
2025-01-21 21:37:04,829:INFO:Importing untrained model
2025-01-21 21:37:04,831:INFO:Ridge Regression Imported successfully
2025-01-21 21:37:04,835:INFO:Starting cross validation
2025-01-21 21:37:04,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:04,956:INFO:Calculating mean and std
2025-01-21 21:37:04,956:INFO:Creating metrics dataframe
2025-01-21 21:37:04,958:INFO:Uploading results into container
2025-01-21 21:37:04,958:INFO:Uploading model into container now
2025-01-21 21:37:04,958:INFO:_master_model_container: 3
2025-01-21 21:37:04,958:INFO:_display_container: 2
2025-01-21 21:37:04,958:INFO:Ridge(random_state=123)
2025-01-21 21:37:04,958:INFO:create_model() successfully completed......................................
2025-01-21 21:37:05,047:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:05,048:INFO:Creating metrics dataframe
2025-01-21 21:37:05,052:INFO:Initializing Elastic Net
2025-01-21 21:37:05,053:INFO:Total runtime is 0.015068213144938152 minutes
2025-01-21 21:37:05,055:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:05,055:INFO:Initializing create_model()
2025-01-21 21:37:05,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:05,055:INFO:Checking exceptions
2025-01-21 21:37:05,055:INFO:Importing libraries
2025-01-21 21:37:05,055:INFO:Copying training dataset
2025-01-21 21:37:05,058:INFO:Defining folds
2025-01-21 21:37:05,058:INFO:Declaring metric variables
2025-01-21 21:37:05,060:INFO:Importing untrained model
2025-01-21 21:37:05,062:INFO:Elastic Net Imported successfully
2025-01-21 21:37:05,066:INFO:Starting cross validation
2025-01-21 21:37:05,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:05,222:INFO:Calculating mean and std
2025-01-21 21:37:05,223:INFO:Creating metrics dataframe
2025-01-21 21:37:05,225:INFO:Uploading results into container
2025-01-21 21:37:05,225:INFO:Uploading model into container now
2025-01-21 21:37:05,225:INFO:_master_model_container: 4
2025-01-21 21:37:05,225:INFO:_display_container: 2
2025-01-21 21:37:05,226:INFO:ElasticNet(random_state=123)
2025-01-21 21:37:05,226:INFO:create_model() successfully completed......................................
2025-01-21 21:37:05,321:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:05,321:INFO:Creating metrics dataframe
2025-01-21 21:37:05,327:INFO:Initializing Least Angle Regression
2025-01-21 21:37:05,327:INFO:Total runtime is 0.019637465476989746 minutes
2025-01-21 21:37:05,329:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:05,329:INFO:Initializing create_model()
2025-01-21 21:37:05,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:05,329:INFO:Checking exceptions
2025-01-21 21:37:05,329:INFO:Importing libraries
2025-01-21 21:37:05,329:INFO:Copying training dataset
2025-01-21 21:37:05,334:INFO:Defining folds
2025-01-21 21:37:05,334:INFO:Declaring metric variables
2025-01-21 21:37:05,336:INFO:Importing untrained model
2025-01-21 21:37:05,338:INFO:Least Angle Regression Imported successfully
2025-01-21 21:37:05,343:INFO:Starting cross validation
2025-01-21 21:37:05,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:05,387:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.027e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,388:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.795e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,388:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.880e+06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,388:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.595e+06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,388:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.124e+06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,389:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.246e+06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,389:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.492e+05, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,389:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.640e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,389:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.192e+03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,395:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.654e-06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,396:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.413e-07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,399:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.184e-06, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.431e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,434:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.813e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.766e+06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.848e+06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.916e+04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.541e+04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.158e+10, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,438:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.204e-06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,438:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.615e-06, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,445:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.270e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,445:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.766e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,445:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.573e+06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,445:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.045e+06, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,446:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.868e+06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,446:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.201e+05, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,446:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.030e+04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,446:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.527e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,481:INFO:Calculating mean and std
2025-01-21 21:37:05,482:INFO:Creating metrics dataframe
2025-01-21 21:37:05,483:INFO:Uploading results into container
2025-01-21 21:37:05,484:INFO:Uploading model into container now
2025-01-21 21:37:05,484:INFO:_master_model_container: 5
2025-01-21 21:37:05,484:INFO:_display_container: 2
2025-01-21 21:37:05,485:INFO:Lars(random_state=123)
2025-01-21 21:37:05,485:INFO:create_model() successfully completed......................................
2025-01-21 21:37:05,579:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:05,579:INFO:Creating metrics dataframe
2025-01-21 21:37:05,585:INFO:Initializing Lasso Least Angle Regression
2025-01-21 21:37:05,585:INFO:Total runtime is 0.023942617575327556 minutes
2025-01-21 21:37:05,587:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:05,588:INFO:Initializing create_model()
2025-01-21 21:37:05,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:05,588:INFO:Checking exceptions
2025-01-21 21:37:05,588:INFO:Importing libraries
2025-01-21 21:37:05,588:INFO:Copying training dataset
2025-01-21 21:37:05,592:INFO:Defining folds
2025-01-21 21:37:05,592:INFO:Declaring metric variables
2025-01-21 21:37:05,594:INFO:Importing untrained model
2025-01-21 21:37:05,597:INFO:Lasso Least Angle Regression Imported successfully
2025-01-21 21:37:05,601:INFO:Starting cross validation
2025-01-21 21:37:05,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:05,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.027e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,649:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.795e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,650:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 4 iterations, alpha=3.112e+07, previous alpha=1.320e+07, with an active set of 3 regressors.
  warnings.warn(

2025-01-21 21:37:05,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.431e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.813e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,677:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.766e+06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,678:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=2.279e+07, previous alpha=2.473e+06, with an active set of 5 regressors.
  warnings.warn(

2025-01-21 21:37:05,705:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 3 iterations, alpha=6.968e+07, previous alpha=6.968e+07, with an active set of 2 regressors.
  warnings.warn(

2025-01-21 21:37:05,705:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.270e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,705:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.766e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:37:05,706:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 4 iterations, alpha=3.148e+07, previous alpha=1.199e+07, with an active set of 3 regressors.
  warnings.warn(

2025-01-21 21:37:05,724:INFO:Calculating mean and std
2025-01-21 21:37:05,725:INFO:Creating metrics dataframe
2025-01-21 21:37:05,727:INFO:Uploading results into container
2025-01-21 21:37:05,727:INFO:Uploading model into container now
2025-01-21 21:37:05,727:INFO:_master_model_container: 6
2025-01-21 21:37:05,727:INFO:_display_container: 2
2025-01-21 21:37:05,728:INFO:LassoLars(random_state=123)
2025-01-21 21:37:05,728:INFO:create_model() successfully completed......................................
2025-01-21 21:37:05,822:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:05,822:INFO:Creating metrics dataframe
2025-01-21 21:37:05,827:INFO:Initializing Orthogonal Matching Pursuit
2025-01-21 21:37:05,828:INFO:Total runtime is 0.02798544963200887 minutes
2025-01-21 21:37:05,830:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:05,830:INFO:Initializing create_model()
2025-01-21 21:37:05,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:05,830:INFO:Checking exceptions
2025-01-21 21:37:05,830:INFO:Importing libraries
2025-01-21 21:37:05,830:INFO:Copying training dataset
2025-01-21 21:37:05,834:INFO:Defining folds
2025-01-21 21:37:05,834:INFO:Declaring metric variables
2025-01-21 21:37:05,836:INFO:Importing untrained model
2025-01-21 21:37:05,838:INFO:Orthogonal Matching Pursuit Imported successfully
2025-01-21 21:37:05,842:INFO:Starting cross validation
2025-01-21 21:37:05,843:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:05,965:INFO:Calculating mean and std
2025-01-21 21:37:05,966:INFO:Creating metrics dataframe
2025-01-21 21:37:05,967:INFO:Uploading results into container
2025-01-21 21:37:05,968:INFO:Uploading model into container now
2025-01-21 21:37:05,968:INFO:_master_model_container: 7
2025-01-21 21:37:05,968:INFO:_display_container: 2
2025-01-21 21:37:05,969:INFO:OrthogonalMatchingPursuit()
2025-01-21 21:37:05,969:INFO:create_model() successfully completed......................................
2025-01-21 21:37:06,060:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:06,060:INFO:Creating metrics dataframe
2025-01-21 21:37:06,065:INFO:Initializing Bayesian Ridge
2025-01-21 21:37:06,065:INFO:Total runtime is 0.03194509744644165 minutes
2025-01-21 21:37:06,067:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:06,067:INFO:Initializing create_model()
2025-01-21 21:37:06,067:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:06,067:INFO:Checking exceptions
2025-01-21 21:37:06,067:INFO:Importing libraries
2025-01-21 21:37:06,068:INFO:Copying training dataset
2025-01-21 21:37:06,071:INFO:Defining folds
2025-01-21 21:37:06,071:INFO:Declaring metric variables
2025-01-21 21:37:06,073:INFO:Importing untrained model
2025-01-21 21:37:06,075:INFO:Bayesian Ridge Imported successfully
2025-01-21 21:37:06,079:INFO:Starting cross validation
2025-01-21 21:37:06,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:06,223:INFO:Calculating mean and std
2025-01-21 21:37:06,224:INFO:Creating metrics dataframe
2025-01-21 21:37:06,225:INFO:Uploading results into container
2025-01-21 21:37:06,226:INFO:Uploading model into container now
2025-01-21 21:37:06,226:INFO:_master_model_container: 8
2025-01-21 21:37:06,226:INFO:_display_container: 2
2025-01-21 21:37:06,227:INFO:BayesianRidge()
2025-01-21 21:37:06,227:INFO:create_model() successfully completed......................................
2025-01-21 21:37:06,321:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:06,321:INFO:Creating metrics dataframe
2025-01-21 21:37:06,327:INFO:Initializing Passive Aggressive Regressor
2025-01-21 21:37:06,327:INFO:Total runtime is 0.036309802532196046 minutes
2025-01-21 21:37:06,329:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:06,329:INFO:Initializing create_model()
2025-01-21 21:37:06,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:06,329:INFO:Checking exceptions
2025-01-21 21:37:06,330:INFO:Importing libraries
2025-01-21 21:37:06,330:INFO:Copying training dataset
2025-01-21 21:37:06,333:INFO:Defining folds
2025-01-21 21:37:06,333:INFO:Declaring metric variables
2025-01-21 21:37:06,335:INFO:Importing untrained model
2025-01-21 21:37:06,338:INFO:Passive Aggressive Regressor Imported successfully
2025-01-21 21:37:06,341:INFO:Starting cross validation
2025-01-21 21:37:06,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:06,541:INFO:Calculating mean and std
2025-01-21 21:37:06,543:INFO:Creating metrics dataframe
2025-01-21 21:37:06,544:INFO:Uploading results into container
2025-01-21 21:37:06,545:INFO:Uploading model into container now
2025-01-21 21:37:06,545:INFO:_master_model_container: 9
2025-01-21 21:37:06,545:INFO:_display_container: 2
2025-01-21 21:37:06,546:INFO:PassiveAggressiveRegressor(random_state=123)
2025-01-21 21:37:06,546:INFO:create_model() successfully completed......................................
2025-01-21 21:37:06,651:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:06,651:INFO:Creating metrics dataframe
2025-01-21 21:37:06,658:INFO:Initializing Huber Regressor
2025-01-21 21:37:06,658:INFO:Total runtime is 0.041826649506886804 minutes
2025-01-21 21:37:06,660:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:06,660:INFO:Initializing create_model()
2025-01-21 21:37:06,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:06,661:INFO:Checking exceptions
2025-01-21 21:37:06,661:INFO:Importing libraries
2025-01-21 21:37:06,661:INFO:Copying training dataset
2025-01-21 21:37:06,665:INFO:Defining folds
2025-01-21 21:37:06,665:INFO:Declaring metric variables
2025-01-21 21:37:06,667:INFO:Importing untrained model
2025-01-21 21:37:06,670:INFO:Huber Regressor Imported successfully
2025-01-21 21:37:06,674:INFO:Starting cross validation
2025-01-21 21:37:06,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:06,763:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,765:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,776:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,780:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,792:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,796:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,801:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,832:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,870:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:37:06,888:INFO:Calculating mean and std
2025-01-21 21:37:06,889:INFO:Creating metrics dataframe
2025-01-21 21:37:06,891:INFO:Uploading results into container
2025-01-21 21:37:06,891:INFO:Uploading model into container now
2025-01-21 21:37:06,892:INFO:_master_model_container: 10
2025-01-21 21:37:06,892:INFO:_display_container: 2
2025-01-21 21:37:06,892:INFO:HuberRegressor()
2025-01-21 21:37:06,892:INFO:create_model() successfully completed......................................
2025-01-21 21:37:06,990:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:06,990:INFO:Creating metrics dataframe
2025-01-21 21:37:06,997:INFO:Initializing K Neighbors Regressor
2025-01-21 21:37:06,997:INFO:Total runtime is 0.047470283508300785 minutes
2025-01-21 21:37:06,999:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:06,999:INFO:Initializing create_model()
2025-01-21 21:37:06,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:06,999:INFO:Checking exceptions
2025-01-21 21:37:06,999:INFO:Importing libraries
2025-01-21 21:37:06,999:INFO:Copying training dataset
2025-01-21 21:37:07,004:INFO:Defining folds
2025-01-21 21:37:07,004:INFO:Declaring metric variables
2025-01-21 21:37:07,006:INFO:Importing untrained model
2025-01-21 21:37:07,009:INFO:K Neighbors Regressor Imported successfully
2025-01-21 21:37:07,013:INFO:Starting cross validation
2025-01-21 21:37:07,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:07,161:INFO:Calculating mean and std
2025-01-21 21:37:07,162:INFO:Creating metrics dataframe
2025-01-21 21:37:07,164:INFO:Uploading results into container
2025-01-21 21:37:07,164:INFO:Uploading model into container now
2025-01-21 21:37:07,165:INFO:_master_model_container: 11
2025-01-21 21:37:07,165:INFO:_display_container: 2
2025-01-21 21:37:07,165:INFO:KNeighborsRegressor(n_jobs=-1)
2025-01-21 21:37:07,165:INFO:create_model() successfully completed......................................
2025-01-21 21:37:07,280:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:07,281:INFO:Creating metrics dataframe
2025-01-21 21:37:07,287:INFO:Initializing Decision Tree Regressor
2025-01-21 21:37:07,287:INFO:Total runtime is 0.05230891704559327 minutes
2025-01-21 21:37:07,289:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:07,289:INFO:Initializing create_model()
2025-01-21 21:37:07,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:07,289:INFO:Checking exceptions
2025-01-21 21:37:07,290:INFO:Importing libraries
2025-01-21 21:37:07,290:INFO:Copying training dataset
2025-01-21 21:37:07,293:INFO:Defining folds
2025-01-21 21:37:07,293:INFO:Declaring metric variables
2025-01-21 21:37:07,295:INFO:Importing untrained model
2025-01-21 21:37:07,298:INFO:Decision Tree Regressor Imported successfully
2025-01-21 21:37:07,302:INFO:Starting cross validation
2025-01-21 21:37:07,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:07,472:INFO:Calculating mean and std
2025-01-21 21:37:07,473:INFO:Creating metrics dataframe
2025-01-21 21:37:07,475:INFO:Uploading results into container
2025-01-21 21:37:07,475:INFO:Uploading model into container now
2025-01-21 21:37:07,476:INFO:_master_model_container: 12
2025-01-21 21:37:07,476:INFO:_display_container: 2
2025-01-21 21:37:07,476:INFO:DecisionTreeRegressor(random_state=123)
2025-01-21 21:37:07,476:INFO:create_model() successfully completed......................................
2025-01-21 21:37:07,571:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:07,571:INFO:Creating metrics dataframe
2025-01-21 21:37:07,578:INFO:Initializing Random Forest Regressor
2025-01-21 21:37:07,578:INFO:Total runtime is 0.05715663035710653 minutes
2025-01-21 21:37:07,580:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:07,580:INFO:Initializing create_model()
2025-01-21 21:37:07,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:07,580:INFO:Checking exceptions
2025-01-21 21:37:07,580:INFO:Importing libraries
2025-01-21 21:37:07,581:INFO:Copying training dataset
2025-01-21 21:37:07,584:INFO:Defining folds
2025-01-21 21:37:07,584:INFO:Declaring metric variables
2025-01-21 21:37:07,586:INFO:Importing untrained model
2025-01-21 21:37:07,588:INFO:Random Forest Regressor Imported successfully
2025-01-21 21:37:07,592:INFO:Starting cross validation
2025-01-21 21:37:07,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:10,746:INFO:Calculating mean and std
2025-01-21 21:37:10,747:INFO:Creating metrics dataframe
2025-01-21 21:37:10,749:INFO:Uploading results into container
2025-01-21 21:37:10,749:INFO:Uploading model into container now
2025-01-21 21:37:10,750:INFO:_master_model_container: 13
2025-01-21 21:37:10,750:INFO:_display_container: 2
2025-01-21 21:37:10,750:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:37:10,750:INFO:create_model() successfully completed......................................
2025-01-21 21:37:10,842:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:10,842:INFO:Creating metrics dataframe
2025-01-21 21:37:10,849:INFO:Initializing Extra Trees Regressor
2025-01-21 21:37:10,849:INFO:Total runtime is 0.11166998545328777 minutes
2025-01-21 21:37:10,851:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:10,851:INFO:Initializing create_model()
2025-01-21 21:37:10,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:10,851:INFO:Checking exceptions
2025-01-21 21:37:10,851:INFO:Importing libraries
2025-01-21 21:37:10,851:INFO:Copying training dataset
2025-01-21 21:37:10,855:INFO:Defining folds
2025-01-21 21:37:10,855:INFO:Declaring metric variables
2025-01-21 21:37:10,857:INFO:Importing untrained model
2025-01-21 21:37:10,859:INFO:Extra Trees Regressor Imported successfully
2025-01-21 21:37:10,863:INFO:Starting cross validation
2025-01-21 21:37:10,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:12,134:INFO:Calculating mean and std
2025-01-21 21:37:12,135:INFO:Creating metrics dataframe
2025-01-21 21:37:12,137:INFO:Uploading results into container
2025-01-21 21:37:12,137:INFO:Uploading model into container now
2025-01-21 21:37:12,138:INFO:_master_model_container: 14
2025-01-21 21:37:12,138:INFO:_display_container: 2
2025-01-21 21:37:12,138:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:37:12,138:INFO:create_model() successfully completed......................................
2025-01-21 21:37:12,231:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:12,231:INFO:Creating metrics dataframe
2025-01-21 21:37:12,238:INFO:Initializing AdaBoost Regressor
2025-01-21 21:37:12,238:INFO:Total runtime is 0.134831698735555 minutes
2025-01-21 21:37:12,240:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:12,241:INFO:Initializing create_model()
2025-01-21 21:37:12,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:12,241:INFO:Checking exceptions
2025-01-21 21:37:12,241:INFO:Importing libraries
2025-01-21 21:37:12,241:INFO:Copying training dataset
2025-01-21 21:37:12,245:INFO:Defining folds
2025-01-21 21:37:12,245:INFO:Declaring metric variables
2025-01-21 21:37:12,247:INFO:Importing untrained model
2025-01-21 21:37:12,249:INFO:AdaBoost Regressor Imported successfully
2025-01-21 21:37:12,253:INFO:Starting cross validation
2025-01-21 21:37:12,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:12,585:INFO:Calculating mean and std
2025-01-21 21:37:12,586:INFO:Creating metrics dataframe
2025-01-21 21:37:12,588:INFO:Uploading results into container
2025-01-21 21:37:12,588:INFO:Uploading model into container now
2025-01-21 21:37:12,589:INFO:_master_model_container: 15
2025-01-21 21:37:12,589:INFO:_display_container: 2
2025-01-21 21:37:12,589:INFO:AdaBoostRegressor(random_state=123)
2025-01-21 21:37:12,589:INFO:create_model() successfully completed......................................
2025-01-21 21:37:12,693:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:12,693:INFO:Creating metrics dataframe
2025-01-21 21:37:12,701:INFO:Initializing Gradient Boosting Regressor
2025-01-21 21:37:12,701:INFO:Total runtime is 0.1425420641899109 minutes
2025-01-21 21:37:12,703:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:12,704:INFO:Initializing create_model()
2025-01-21 21:37:12,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:12,704:INFO:Checking exceptions
2025-01-21 21:37:12,704:INFO:Importing libraries
2025-01-21 21:37:12,704:INFO:Copying training dataset
2025-01-21 21:37:12,708:INFO:Defining folds
2025-01-21 21:37:12,708:INFO:Declaring metric variables
2025-01-21 21:37:12,710:INFO:Importing untrained model
2025-01-21 21:37:12,713:INFO:Gradient Boosting Regressor Imported successfully
2025-01-21 21:37:12,717:INFO:Starting cross validation
2025-01-21 21:37:12,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:14,540:INFO:Calculating mean and std
2025-01-21 21:37:14,541:INFO:Creating metrics dataframe
2025-01-21 21:37:14,542:INFO:Uploading results into container
2025-01-21 21:37:14,542:INFO:Uploading model into container now
2025-01-21 21:37:14,543:INFO:_master_model_container: 16
2025-01-21 21:37:14,543:INFO:_display_container: 2
2025-01-21 21:37:14,543:INFO:GradientBoostingRegressor(random_state=123)
2025-01-21 21:37:14,544:INFO:create_model() successfully completed......................................
2025-01-21 21:37:14,640:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:14,640:INFO:Creating metrics dataframe
2025-01-21 21:37:14,647:INFO:Initializing Extreme Gradient Boosting
2025-01-21 21:37:14,647:INFO:Total runtime is 0.1749834974606832 minutes
2025-01-21 21:37:14,650:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:14,650:INFO:Initializing create_model()
2025-01-21 21:37:14,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:14,650:INFO:Checking exceptions
2025-01-21 21:37:14,650:INFO:Importing libraries
2025-01-21 21:37:14,650:INFO:Copying training dataset
2025-01-21 21:37:14,654:INFO:Defining folds
2025-01-21 21:37:14,654:INFO:Declaring metric variables
2025-01-21 21:37:14,657:INFO:Importing untrained model
2025-01-21 21:37:14,659:INFO:Extreme Gradient Boosting Imported successfully
2025-01-21 21:37:14,664:INFO:Starting cross validation
2025-01-21 21:37:14,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:15,124:INFO:Calculating mean and std
2025-01-21 21:37:15,125:INFO:Creating metrics dataframe
2025-01-21 21:37:15,127:INFO:Uploading results into container
2025-01-21 21:37:15,127:INFO:Uploading model into container now
2025-01-21 21:37:15,127:INFO:_master_model_container: 17
2025-01-21 21:37:15,128:INFO:_display_container: 2
2025-01-21 21:37:15,128:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2025-01-21 21:37:15,129:INFO:create_model() successfully completed......................................
2025-01-21 21:37:15,229:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:15,229:INFO:Creating metrics dataframe
2025-01-21 21:37:15,237:INFO:Initializing Light Gradient Boosting Machine
2025-01-21 21:37:15,237:INFO:Total runtime is 0.18481206496556601 minutes
2025-01-21 21:37:15,240:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:15,240:INFO:Initializing create_model()
2025-01-21 21:37:15,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:15,240:INFO:Checking exceptions
2025-01-21 21:37:15,240:INFO:Importing libraries
2025-01-21 21:37:15,240:INFO:Copying training dataset
2025-01-21 21:37:15,245:INFO:Defining folds
2025-01-21 21:37:15,245:INFO:Declaring metric variables
2025-01-21 21:37:15,248:INFO:Importing untrained model
2025-01-21 21:37:15,251:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-21 21:37:15,255:INFO:Starting cross validation
2025-01-21 21:37:15,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:18,282:INFO:Calculating mean and std
2025-01-21 21:37:18,284:INFO:Creating metrics dataframe
2025-01-21 21:37:18,286:INFO:Uploading results into container
2025-01-21 21:37:18,286:INFO:Uploading model into container now
2025-01-21 21:37:18,286:INFO:_master_model_container: 18
2025-01-21 21:37:18,286:INFO:_display_container: 2
2025-01-21 21:37:18,287:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:37:18,287:INFO:create_model() successfully completed......................................
2025-01-21 21:37:18,377:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:18,378:INFO:Creating metrics dataframe
2025-01-21 21:37:18,385:INFO:Initializing Dummy Regressor
2025-01-21 21:37:18,385:INFO:Total runtime is 0.2372779687245687 minutes
2025-01-21 21:37:18,387:INFO:SubProcess create_model() called ==================================
2025-01-21 21:37:18,387:INFO:Initializing create_model()
2025-01-21 21:37:18,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b39aad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:18,387:INFO:Checking exceptions
2025-01-21 21:37:18,387:INFO:Importing libraries
2025-01-21 21:37:18,387:INFO:Copying training dataset
2025-01-21 21:37:18,391:INFO:Defining folds
2025-01-21 21:37:18,391:INFO:Declaring metric variables
2025-01-21 21:37:18,393:INFO:Importing untrained model
2025-01-21 21:37:18,395:INFO:Dummy Regressor Imported successfully
2025-01-21 21:37:18,400:INFO:Starting cross validation
2025-01-21 21:37:18,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:37:18,525:INFO:Calculating mean and std
2025-01-21 21:37:18,526:INFO:Creating metrics dataframe
2025-01-21 21:37:18,527:INFO:Uploading results into container
2025-01-21 21:37:18,527:INFO:Uploading model into container now
2025-01-21 21:37:18,527:INFO:_master_model_container: 19
2025-01-21 21:37:18,527:INFO:_display_container: 2
2025-01-21 21:37:18,528:INFO:DummyRegressor()
2025-01-21 21:37:18,528:INFO:create_model() successfully completed......................................
2025-01-21 21:37:18,617:INFO:SubProcess create_model() end ==================================
2025-01-21 21:37:18,617:INFO:Creating metrics dataframe
2025-01-21 21:37:18,625:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-21 21:37:18,630:INFO:Initializing create_model()
2025-01-21 21:37:18,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1694eb310>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:37:18,631:INFO:Checking exceptions
2025-01-21 21:37:18,632:INFO:Importing libraries
2025-01-21 21:37:18,632:INFO:Copying training dataset
2025-01-21 21:37:18,636:INFO:Defining folds
2025-01-21 21:37:18,636:INFO:Declaring metric variables
2025-01-21 21:37:18,636:INFO:Importing untrained model
2025-01-21 21:37:18,636:INFO:Declaring custom model
2025-01-21 21:37:18,636:INFO:Linear Regression Imported successfully
2025-01-21 21:37:18,637:INFO:Cross validation set to False
2025-01-21 21:37:18,637:INFO:Fitting Model
2025-01-21 21:37:18,664:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:37:18,664:INFO:create_model() successfully completed......................................
2025-01-21 21:37:18,773:INFO:_master_model_container: 19
2025-01-21 21:37:18,774:INFO:_display_container: 2
2025-01-21 21:37:18,774:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:37:18,774:INFO:compare_models() successfully completed......................................
2025-01-21 21:40:25,738:INFO:PyCaret RegressionExperiment
2025-01-21 21:40:25,739:INFO:Logging name: reg-default-name
2025-01-21 21:40:25,739:INFO:ML Usecase: MLUsecase.REGRESSION
2025-01-21 21:40:25,739:INFO:version 3.3.1
2025-01-21 21:40:25,739:INFO:Initializing setup()
2025-01-21 21:40:25,739:INFO:self.USI: 60e6
2025-01-21 21:40:25,739:INFO:self._variable_keys: {'n_jobs_param', '_ml_usecase', 'idx', 'y', 'target_param', 'fold_groups_param', 'X', 'logging_param', 'X_train', 'y_test', 'fold_generator', 'exp_id', 'html_param', 'transform_target_param', 'gpu_n_jobs_param', 'memory', '_available_plots', 'USI', 'log_plots_param', 'y_train', 'exp_name_log', 'data', 'X_test', 'seed', 'pipeline', 'fold_shuffle_param', 'gpu_param'}
2025-01-21 21:40:25,739:INFO:Checking environment
2025-01-21 21:40:25,740:INFO:python_version: 3.10.13
2025-01-21 21:40:25,740:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-21 21:40:25,740:INFO:machine: arm64
2025-01-21 21:40:25,740:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-21 21:40:25,740:INFO:Memory: svmem(total=8589934592, available=1704558592, percent=80.2, used=3059810304, free=63553536, active=1657815040, inactive=1637187584, wired=1401995264)
2025-01-21 21:40:25,740:INFO:Physical Core: 8
2025-01-21 21:40:25,740:INFO:Logical Core: 8
2025-01-21 21:40:25,740:INFO:Checking libraries
2025-01-21 21:40:25,740:INFO:System:
2025-01-21 21:40:25,740:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-21 21:40:25,740:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-21 21:40:25,740:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-21 21:40:25,740:INFO:PyCaret required dependencies:
2025-01-21 21:40:25,740:INFO:                 pip: 24.2
2025-01-21 21:40:25,740:INFO:          setuptools: 75.1.0
2025-01-21 21:40:25,740:INFO:             pycaret: 3.3.1
2025-01-21 21:40:25,740:INFO:             IPython: 8.27.0
2025-01-21 21:40:25,740:INFO:          ipywidgets: 8.1.2
2025-01-21 21:40:25,740:INFO:                tqdm: 4.66.5
2025-01-21 21:40:25,740:INFO:               numpy: 1.26.4
2025-01-21 21:40:25,740:INFO:              pandas: 2.1.4
2025-01-21 21:40:25,740:INFO:              jinja2: 3.1.4
2025-01-21 21:40:25,741:INFO:               scipy: 1.11.4
2025-01-21 21:40:25,741:INFO:              joblib: 1.3.2
2025-01-21 21:40:25,741:INFO:             sklearn: 1.4.2
2025-01-21 21:40:25,741:INFO:                pyod: 2.0.2
2025-01-21 21:40:25,741:INFO:            imblearn: 0.13.0
2025-01-21 21:40:25,741:INFO:   category_encoders: 2.7.0
2025-01-21 21:40:25,741:INFO:            lightgbm: 4.4.0
2025-01-21 21:40:25,741:INFO:               numba: 0.60.0
2025-01-21 21:40:25,741:INFO:            requests: 2.32.3
2025-01-21 21:40:25,741:INFO:          matplotlib: 3.9.2
2025-01-21 21:40:25,741:INFO:          scikitplot: 0.3.7
2025-01-21 21:40:25,741:INFO:         yellowbrick: 1.5
2025-01-21 21:40:25,741:INFO:              plotly: 5.24.1
2025-01-21 21:40:25,741:INFO:    plotly-resampler: Not installed
2025-01-21 21:40:25,741:INFO:             kaleido: 0.2.1
2025-01-21 21:40:25,741:INFO:           schemdraw: 0.15
2025-01-21 21:40:25,741:INFO:         statsmodels: 0.14.4
2025-01-21 21:40:25,741:INFO:              sktime: 0.26.0
2025-01-21 21:40:25,741:INFO:               tbats: 1.1.3
2025-01-21 21:40:25,741:INFO:            pmdarima: 2.0.4
2025-01-21 21:40:25,741:INFO:              psutil: 5.9.0
2025-01-21 21:40:25,741:INFO:          markupsafe: 2.1.3
2025-01-21 21:40:25,741:INFO:             pickle5: Not installed
2025-01-21 21:40:25,741:INFO:         cloudpickle: 3.1.0
2025-01-21 21:40:25,741:INFO:         deprecation: 2.1.0
2025-01-21 21:40:25,741:INFO:              xxhash: 3.5.0
2025-01-21 21:40:25,741:INFO:           wurlitzer: 3.1.1
2025-01-21 21:40:25,741:INFO:PyCaret optional dependencies:
2025-01-21 21:40:25,741:INFO:                shap: 0.46.0
2025-01-21 21:40:25,741:INFO:           interpret: Not installed
2025-01-21 21:40:25,741:INFO:                umap: 0.5.7
2025-01-21 21:40:25,741:INFO:     ydata_profiling: Not installed
2025-01-21 21:40:25,741:INFO:  explainerdashboard: Not installed
2025-01-21 21:40:25,741:INFO:             autoviz: Not installed
2025-01-21 21:40:25,741:INFO:           fairlearn: Not installed
2025-01-21 21:40:25,741:INFO:          deepchecks: Not installed
2025-01-21 21:40:25,741:INFO:             xgboost: 2.1.3
2025-01-21 21:40:25,741:INFO:            catboost: Not installed
2025-01-21 21:40:25,741:INFO:              kmodes: Not installed
2025-01-21 21:40:25,741:INFO:             mlxtend: Not installed
2025-01-21 21:40:25,741:INFO:       statsforecast: Not installed
2025-01-21 21:40:25,741:INFO:        tune_sklearn: Not installed
2025-01-21 21:40:25,741:INFO:                 ray: Not installed
2025-01-21 21:40:25,741:INFO:            hyperopt: Not installed
2025-01-21 21:40:25,741:INFO:              optuna: Not installed
2025-01-21 21:40:25,741:INFO:               skopt: Not installed
2025-01-21 21:40:25,741:INFO:              mlflow: 2.19.0
2025-01-21 21:40:25,742:INFO:              gradio: Not installed
2025-01-21 21:40:25,742:INFO:             fastapi: Not installed
2025-01-21 21:40:25,742:INFO:             uvicorn: Not installed
2025-01-21 21:40:25,742:INFO:              m2cgen: Not installed
2025-01-21 21:40:25,742:INFO:           evidently: Not installed
2025-01-21 21:40:25,742:INFO:               fugue: Not installed
2025-01-21 21:40:25,742:INFO:           streamlit: Not installed
2025-01-21 21:40:25,742:INFO:             prophet: Not installed
2025-01-21 21:40:25,742:INFO:None
2025-01-21 21:40:25,742:INFO:Set up data.
2025-01-21 21:40:25,750:INFO:Set up folding strategy.
2025-01-21 21:40:25,750:INFO:Set up train/test split.
2025-01-21 21:40:25,754:INFO:Set up index.
2025-01-21 21:40:25,754:INFO:Assigning column types.
2025-01-21 21:40:25,756:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-21 21:40:25,757:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,760:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,763:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,863:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:25,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:25,866:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,869:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,872:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,914:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,946:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:25,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:25,948:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-01-21 21:40:25,951:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,954:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:25,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,027:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,032:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,035:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,076:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,107:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,109:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-01-21 21:40:26,115:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,156:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,186:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,263:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,263:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,265:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-01-21 21:40:26,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,341:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,341:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,388:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,418:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,420:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-21 21:40:26,465:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,496:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,542:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:26,573:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,575:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-01-21 21:40:26,651:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,729:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:26,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:26,733:INFO:Preparing preprocessing pipeline...
2025-01-21 21:40:26,733:INFO:Set up simple imputation.
2025-01-21 21:40:26,734:INFO:Set up encoding of categorical features.
2025-01-21 21:40:26,735:INFO:Set up column name cleaning.
2025-01-21 21:40:26,784:INFO:Finished creating preprocessing pipeline.
2025-01-21 21:40:26,789:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone',
                                             'Hispanic or Latino'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-01-21 21:40:26,789:INFO:Creating final display dataframe.
2025-01-21 21:40:26,929:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target  Female Population
2                   Target type         Regression
3           Original data shape         (2900, 12)
4        Transformed data shape         (2900, 12)
5   Transformed train set shape         (2029, 12)
6    Transformed test set shape          (871, 12)
7              Numeric features                  9
8          Categorical features                  2
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name   reg-default-name
21                          USI               60e6
2025-01-21 21:40:27,012:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:27,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:27,093:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:27,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:27,095:INFO:setup() successfully completed in 1.36s...............
2025-01-21 21:40:27,101:INFO:Initializing compare_models()
2025-01-21 21:40:27,101:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-01-21 21:40:27,102:INFO:Checking exceptions
2025-01-21 21:40:27,105:INFO:Preparing display monitor
2025-01-21 21:40:27,123:INFO:Initializing Linear Regression
2025-01-21 21:40:27,123:INFO:Total runtime is 3.0954678853352863e-06 minutes
2025-01-21 21:40:27,125:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:27,126:INFO:Initializing create_model()
2025-01-21 21:40:27,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:27,126:INFO:Checking exceptions
2025-01-21 21:40:27,126:INFO:Importing libraries
2025-01-21 21:40:27,126:INFO:Copying training dataset
2025-01-21 21:40:27,132:INFO:Defining folds
2025-01-21 21:40:27,132:INFO:Declaring metric variables
2025-01-21 21:40:27,134:INFO:Importing untrained model
2025-01-21 21:40:27,136:INFO:Linear Regression Imported successfully
2025-01-21 21:40:27,141:INFO:Starting cross validation
2025-01-21 21:40:27,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:27,367:INFO:Calculating mean and std
2025-01-21 21:40:27,367:INFO:Creating metrics dataframe
2025-01-21 21:40:27,369:INFO:Uploading results into container
2025-01-21 21:40:27,369:INFO:Uploading model into container now
2025-01-21 21:40:27,370:INFO:_master_model_container: 1
2025-01-21 21:40:27,370:INFO:_display_container: 2
2025-01-21 21:40:27,370:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:40:27,370:INFO:create_model() successfully completed......................................
2025-01-21 21:40:27,562:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:27,562:INFO:Creating metrics dataframe
2025-01-21 21:40:27,567:INFO:Initializing Lasso Regression
2025-01-21 21:40:27,567:INFO:Total runtime is 0.007403779029846192 minutes
2025-01-21 21:40:27,569:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:27,569:INFO:Initializing create_model()
2025-01-21 21:40:27,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:27,569:INFO:Checking exceptions
2025-01-21 21:40:27,570:INFO:Importing libraries
2025-01-21 21:40:27,570:INFO:Copying training dataset
2025-01-21 21:40:27,573:INFO:Defining folds
2025-01-21 21:40:27,573:INFO:Declaring metric variables
2025-01-21 21:40:27,576:INFO:Importing untrained model
2025-01-21 21:40:27,578:INFO:Lasso Regression Imported successfully
2025-01-21 21:40:27,583:INFO:Starting cross validation
2025-01-21 21:40:27,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:27,801:INFO:Calculating mean and std
2025-01-21 21:40:27,802:INFO:Creating metrics dataframe
2025-01-21 21:40:27,804:INFO:Uploading results into container
2025-01-21 21:40:27,804:INFO:Uploading model into container now
2025-01-21 21:40:27,805:INFO:_master_model_container: 2
2025-01-21 21:40:27,805:INFO:_display_container: 2
2025-01-21 21:40:27,805:INFO:Lasso(random_state=123)
2025-01-21 21:40:27,805:INFO:create_model() successfully completed......................................
2025-01-21 21:40:27,942:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:27,943:INFO:Creating metrics dataframe
2025-01-21 21:40:27,948:INFO:Initializing Ridge Regression
2025-01-21 21:40:27,948:INFO:Total runtime is 0.013754514853159587 minutes
2025-01-21 21:40:27,950:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:27,951:INFO:Initializing create_model()
2025-01-21 21:40:27,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:27,951:INFO:Checking exceptions
2025-01-21 21:40:27,951:INFO:Importing libraries
2025-01-21 21:40:27,951:INFO:Copying training dataset
2025-01-21 21:40:27,954:INFO:Defining folds
2025-01-21 21:40:27,954:INFO:Declaring metric variables
2025-01-21 21:40:27,957:INFO:Importing untrained model
2025-01-21 21:40:27,959:INFO:Ridge Regression Imported successfully
2025-01-21 21:40:27,963:INFO:Starting cross validation
2025-01-21 21:40:27,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:28,090:INFO:Calculating mean and std
2025-01-21 21:40:28,090:INFO:Creating metrics dataframe
2025-01-21 21:40:28,091:INFO:Uploading results into container
2025-01-21 21:40:28,092:INFO:Uploading model into container now
2025-01-21 21:40:28,092:INFO:_master_model_container: 3
2025-01-21 21:40:28,092:INFO:_display_container: 2
2025-01-21 21:40:28,092:INFO:Ridge(random_state=123)
2025-01-21 21:40:28,092:INFO:create_model() successfully completed......................................
2025-01-21 21:40:28,185:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:28,185:INFO:Creating metrics dataframe
2025-01-21 21:40:28,189:INFO:Initializing Elastic Net
2025-01-21 21:40:28,190:INFO:Total runtime is 0.01778219938278198 minutes
2025-01-21 21:40:28,192:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:28,192:INFO:Initializing create_model()
2025-01-21 21:40:28,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:28,192:INFO:Checking exceptions
2025-01-21 21:40:28,192:INFO:Importing libraries
2025-01-21 21:40:28,192:INFO:Copying training dataset
2025-01-21 21:40:28,196:INFO:Defining folds
2025-01-21 21:40:28,196:INFO:Declaring metric variables
2025-01-21 21:40:28,198:INFO:Importing untrained model
2025-01-21 21:40:28,200:INFO:Elastic Net Imported successfully
2025-01-21 21:40:28,204:INFO:Starting cross validation
2025-01-21 21:40:28,205:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:28,354:INFO:Calculating mean and std
2025-01-21 21:40:28,355:INFO:Creating metrics dataframe
2025-01-21 21:40:28,357:INFO:Uploading results into container
2025-01-21 21:40:28,357:INFO:Uploading model into container now
2025-01-21 21:40:28,357:INFO:_master_model_container: 4
2025-01-21 21:40:28,358:INFO:_display_container: 2
2025-01-21 21:40:28,358:INFO:ElasticNet(random_state=123)
2025-01-21 21:40:28,358:INFO:create_model() successfully completed......................................
2025-01-21 21:40:28,455:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:28,455:INFO:Creating metrics dataframe
2025-01-21 21:40:28,460:INFO:Initializing Least Angle Regression
2025-01-21 21:40:28,460:INFO:Total runtime is 0.022296194235483804 minutes
2025-01-21 21:40:28,462:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:28,463:INFO:Initializing create_model()
2025-01-21 21:40:28,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:28,463:INFO:Checking exceptions
2025-01-21 21:40:28,463:INFO:Importing libraries
2025-01-21 21:40:28,463:INFO:Copying training dataset
2025-01-21 21:40:28,467:INFO:Defining folds
2025-01-21 21:40:28,467:INFO:Declaring metric variables
2025-01-21 21:40:28,469:INFO:Importing untrained model
2025-01-21 21:40:28,471:INFO:Least Angle Regression Imported successfully
2025-01-21 21:40:28,476:INFO:Starting cross validation
2025-01-21 21:40:28,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:28,526:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.654e-06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,526:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.027e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,526:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.795e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.880e+06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.413e-07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.595e+06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.124e+06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,527:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.246e+06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.492e+05, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.640e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.192e+03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,528:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.184e-06, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,563:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.204e-06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,564:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.615e-06, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,565:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.431e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,565:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.813e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.766e+06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.848e+06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.916e+04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,566:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.541e+04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,567:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.158e+10, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,591:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.270e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,591:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.766e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,592:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.573e+06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,592:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.045e+06, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,592:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.868e+06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,593:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.201e+05, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,593:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.030e+04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,593:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.527e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,619:INFO:Calculating mean and std
2025-01-21 21:40:28,620:INFO:Creating metrics dataframe
2025-01-21 21:40:28,621:INFO:Uploading results into container
2025-01-21 21:40:28,622:INFO:Uploading model into container now
2025-01-21 21:40:28,622:INFO:_master_model_container: 5
2025-01-21 21:40:28,622:INFO:_display_container: 2
2025-01-21 21:40:28,622:INFO:Lars(random_state=123)
2025-01-21 21:40:28,623:INFO:create_model() successfully completed......................................
2025-01-21 21:40:28,727:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:28,727:INFO:Creating metrics dataframe
2025-01-21 21:40:28,732:INFO:Initializing Lasso Least Angle Regression
2025-01-21 21:40:28,733:INFO:Total runtime is 0.026832063992818195 minutes
2025-01-21 21:40:28,735:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:28,735:INFO:Initializing create_model()
2025-01-21 21:40:28,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:28,735:INFO:Checking exceptions
2025-01-21 21:40:28,735:INFO:Importing libraries
2025-01-21 21:40:28,735:INFO:Copying training dataset
2025-01-21 21:40:28,740:INFO:Defining folds
2025-01-21 21:40:28,740:INFO:Declaring metric variables
2025-01-21 21:40:28,743:INFO:Importing untrained model
2025-01-21 21:40:28,745:INFO:Lasso Least Angle Regression Imported successfully
2025-01-21 21:40:28,750:INFO:Starting cross validation
2025-01-21 21:40:28,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:28,797:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.027e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,797:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.795e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,797:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 4 iterations, alpha=3.112e+07, previous alpha=1.320e+07, with an active set of 3 regressors.
  warnings.warn(

2025-01-21 21:40:28,842:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.431e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,843:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.813e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,843:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.766e+06, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,844:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=2.279e+07, previous alpha=2.473e+06, with an active set of 5 regressors.
  warnings.warn(

2025-01-21 21:40:28,879:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.270e+07, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,880:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.766e+07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:28,880:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 4 iterations, alpha=3.148e+07, previous alpha=1.199e+07, with an active set of 3 regressors.
  warnings.warn(

2025-01-21 21:40:28,887:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 3 iterations, alpha=6.968e+07, previous alpha=6.968e+07, with an active set of 2 regressors.
  warnings.warn(

2025-01-21 21:40:28,917:INFO:Calculating mean and std
2025-01-21 21:40:28,918:INFO:Creating metrics dataframe
2025-01-21 21:40:28,920:INFO:Uploading results into container
2025-01-21 21:40:28,920:INFO:Uploading model into container now
2025-01-21 21:40:28,921:INFO:_master_model_container: 6
2025-01-21 21:40:28,921:INFO:_display_container: 2
2025-01-21 21:40:28,921:INFO:LassoLars(random_state=123)
2025-01-21 21:40:28,922:INFO:create_model() successfully completed......................................
2025-01-21 21:40:29,027:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:29,027:INFO:Creating metrics dataframe
2025-01-21 21:40:29,033:INFO:Initializing Orthogonal Matching Pursuit
2025-01-21 21:40:29,033:INFO:Total runtime is 0.031837864716847734 minutes
2025-01-21 21:40:29,035:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:29,036:INFO:Initializing create_model()
2025-01-21 21:40:29,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:29,036:INFO:Checking exceptions
2025-01-21 21:40:29,036:INFO:Importing libraries
2025-01-21 21:40:29,036:INFO:Copying training dataset
2025-01-21 21:40:29,041:INFO:Defining folds
2025-01-21 21:40:29,041:INFO:Declaring metric variables
2025-01-21 21:40:29,044:INFO:Importing untrained model
2025-01-21 21:40:29,046:INFO:Orthogonal Matching Pursuit Imported successfully
2025-01-21 21:40:29,051:INFO:Starting cross validation
2025-01-21 21:40:29,052:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:29,194:INFO:Calculating mean and std
2025-01-21 21:40:29,194:INFO:Creating metrics dataframe
2025-01-21 21:40:29,196:INFO:Uploading results into container
2025-01-21 21:40:29,196:INFO:Uploading model into container now
2025-01-21 21:40:29,197:INFO:_master_model_container: 7
2025-01-21 21:40:29,197:INFO:_display_container: 2
2025-01-21 21:40:29,197:INFO:OrthogonalMatchingPursuit()
2025-01-21 21:40:29,197:INFO:create_model() successfully completed......................................
2025-01-21 21:40:29,294:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:29,295:INFO:Creating metrics dataframe
2025-01-21 21:40:29,301:INFO:Initializing Bayesian Ridge
2025-01-21 21:40:29,301:INFO:Total runtime is 0.0363040804862976 minutes
2025-01-21 21:40:29,303:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:29,303:INFO:Initializing create_model()
2025-01-21 21:40:29,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:29,303:INFO:Checking exceptions
2025-01-21 21:40:29,303:INFO:Importing libraries
2025-01-21 21:40:29,303:INFO:Copying training dataset
2025-01-21 21:40:29,307:INFO:Defining folds
2025-01-21 21:40:29,307:INFO:Declaring metric variables
2025-01-21 21:40:29,310:INFO:Importing untrained model
2025-01-21 21:40:29,312:INFO:Bayesian Ridge Imported successfully
2025-01-21 21:40:29,316:INFO:Starting cross validation
2025-01-21 21:40:29,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:29,477:INFO:Calculating mean and std
2025-01-21 21:40:29,478:INFO:Creating metrics dataframe
2025-01-21 21:40:29,479:INFO:Uploading results into container
2025-01-21 21:40:29,480:INFO:Uploading model into container now
2025-01-21 21:40:29,480:INFO:_master_model_container: 8
2025-01-21 21:40:29,480:INFO:_display_container: 2
2025-01-21 21:40:29,481:INFO:BayesianRidge()
2025-01-21 21:40:29,481:INFO:create_model() successfully completed......................................
2025-01-21 21:40:29,579:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:29,579:INFO:Creating metrics dataframe
2025-01-21 21:40:29,586:INFO:Initializing Passive Aggressive Regressor
2025-01-21 21:40:29,586:INFO:Total runtime is 0.04105103413263956 minutes
2025-01-21 21:40:29,588:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:29,588:INFO:Initializing create_model()
2025-01-21 21:40:29,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:29,588:INFO:Checking exceptions
2025-01-21 21:40:29,589:INFO:Importing libraries
2025-01-21 21:40:29,589:INFO:Copying training dataset
2025-01-21 21:40:29,593:INFO:Defining folds
2025-01-21 21:40:29,593:INFO:Declaring metric variables
2025-01-21 21:40:29,618:INFO:Importing untrained model
2025-01-21 21:40:29,622:INFO:Passive Aggressive Regressor Imported successfully
2025-01-21 21:40:29,630:INFO:Starting cross validation
2025-01-21 21:40:29,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:29,942:INFO:Calculating mean and std
2025-01-21 21:40:29,943:INFO:Creating metrics dataframe
2025-01-21 21:40:29,945:INFO:Uploading results into container
2025-01-21 21:40:29,946:INFO:Uploading model into container now
2025-01-21 21:40:29,946:INFO:_master_model_container: 9
2025-01-21 21:40:29,947:INFO:_display_container: 2
2025-01-21 21:40:29,947:INFO:PassiveAggressiveRegressor(random_state=123)
2025-01-21 21:40:29,947:INFO:create_model() successfully completed......................................
2025-01-21 21:40:30,058:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:30,059:INFO:Creating metrics dataframe
2025-01-21 21:40:30,065:INFO:Initializing Huber Regressor
2025-01-21 21:40:30,065:INFO:Total runtime is 0.04904123147328694 minutes
2025-01-21 21:40:30,067:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:30,067:INFO:Initializing create_model()
2025-01-21 21:40:30,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:30,068:INFO:Checking exceptions
2025-01-21 21:40:30,068:INFO:Importing libraries
2025-01-21 21:40:30,068:INFO:Copying training dataset
2025-01-21 21:40:30,072:INFO:Defining folds
2025-01-21 21:40:30,072:INFO:Declaring metric variables
2025-01-21 21:40:30,074:INFO:Importing untrained model
2025-01-21 21:40:30,076:INFO:Huber Regressor Imported successfully
2025-01-21 21:40:30,081:INFO:Starting cross validation
2025-01-21 21:40:30,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:30,170:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,179:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,183:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,189:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,211:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,215:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,217:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,236:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,280:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-21 21:40:30,300:INFO:Calculating mean and std
2025-01-21 21:40:30,301:INFO:Creating metrics dataframe
2025-01-21 21:40:30,303:INFO:Uploading results into container
2025-01-21 21:40:30,303:INFO:Uploading model into container now
2025-01-21 21:40:30,304:INFO:_master_model_container: 10
2025-01-21 21:40:30,304:INFO:_display_container: 2
2025-01-21 21:40:30,304:INFO:HuberRegressor()
2025-01-21 21:40:30,305:INFO:create_model() successfully completed......................................
2025-01-21 21:40:30,405:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:30,405:INFO:Creating metrics dataframe
2025-01-21 21:40:30,412:INFO:Initializing K Neighbors Regressor
2025-01-21 21:40:30,412:INFO:Total runtime is 0.05482356548309326 minutes
2025-01-21 21:40:30,414:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:30,415:INFO:Initializing create_model()
2025-01-21 21:40:30,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:30,415:INFO:Checking exceptions
2025-01-21 21:40:30,415:INFO:Importing libraries
2025-01-21 21:40:30,415:INFO:Copying training dataset
2025-01-21 21:40:30,419:INFO:Defining folds
2025-01-21 21:40:30,419:INFO:Declaring metric variables
2025-01-21 21:40:30,422:INFO:Importing untrained model
2025-01-21 21:40:30,424:INFO:K Neighbors Regressor Imported successfully
2025-01-21 21:40:30,430:INFO:Starting cross validation
2025-01-21 21:40:30,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:30,622:INFO:Calculating mean and std
2025-01-21 21:40:30,623:INFO:Creating metrics dataframe
2025-01-21 21:40:30,625:INFO:Uploading results into container
2025-01-21 21:40:30,625:INFO:Uploading model into container now
2025-01-21 21:40:30,626:INFO:_master_model_container: 11
2025-01-21 21:40:30,626:INFO:_display_container: 2
2025-01-21 21:40:30,626:INFO:KNeighborsRegressor(n_jobs=-1)
2025-01-21 21:40:30,626:INFO:create_model() successfully completed......................................
2025-01-21 21:40:30,732:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:30,732:INFO:Creating metrics dataframe
2025-01-21 21:40:30,739:INFO:Initializing Decision Tree Regressor
2025-01-21 21:40:30,739:INFO:Total runtime is 0.060273234049479166 minutes
2025-01-21 21:40:30,741:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:30,742:INFO:Initializing create_model()
2025-01-21 21:40:30,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:30,742:INFO:Checking exceptions
2025-01-21 21:40:30,742:INFO:Importing libraries
2025-01-21 21:40:30,742:INFO:Copying training dataset
2025-01-21 21:40:30,746:INFO:Defining folds
2025-01-21 21:40:30,746:INFO:Declaring metric variables
2025-01-21 21:40:30,749:INFO:Importing untrained model
2025-01-21 21:40:30,752:INFO:Decision Tree Regressor Imported successfully
2025-01-21 21:40:30,756:INFO:Starting cross validation
2025-01-21 21:40:30,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:30,992:INFO:Calculating mean and std
2025-01-21 21:40:30,993:INFO:Creating metrics dataframe
2025-01-21 21:40:30,994:INFO:Uploading results into container
2025-01-21 21:40:30,995:INFO:Uploading model into container now
2025-01-21 21:40:30,995:INFO:_master_model_container: 12
2025-01-21 21:40:30,995:INFO:_display_container: 2
2025-01-21 21:40:30,996:INFO:DecisionTreeRegressor(random_state=123)
2025-01-21 21:40:30,996:INFO:create_model() successfully completed......................................
2025-01-21 21:40:31,094:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:31,094:INFO:Creating metrics dataframe
2025-01-21 21:40:31,101:INFO:Initializing Random Forest Regressor
2025-01-21 21:40:31,101:INFO:Total runtime is 0.06630514860153199 minutes
2025-01-21 21:40:31,103:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:31,104:INFO:Initializing create_model()
2025-01-21 21:40:31,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:31,104:INFO:Checking exceptions
2025-01-21 21:40:31,104:INFO:Importing libraries
2025-01-21 21:40:31,104:INFO:Copying training dataset
2025-01-21 21:40:31,108:INFO:Defining folds
2025-01-21 21:40:31,108:INFO:Declaring metric variables
2025-01-21 21:40:31,111:INFO:Importing untrained model
2025-01-21 21:40:31,115:INFO:Random Forest Regressor Imported successfully
2025-01-21 21:40:31,121:INFO:Starting cross validation
2025-01-21 21:40:31,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:34,511:INFO:Calculating mean and std
2025-01-21 21:40:34,512:INFO:Creating metrics dataframe
2025-01-21 21:40:34,513:INFO:Uploading results into container
2025-01-21 21:40:34,514:INFO:Uploading model into container now
2025-01-21 21:40:34,514:INFO:_master_model_container: 13
2025-01-21 21:40:34,514:INFO:_display_container: 2
2025-01-21 21:40:34,515:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:40:34,515:INFO:create_model() successfully completed......................................
2025-01-21 21:40:34,616:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:34,616:INFO:Creating metrics dataframe
2025-01-21 21:40:34,624:INFO:Initializing Extra Trees Regressor
2025-01-21 21:40:34,624:INFO:Total runtime is 0.12502301534016927 minutes
2025-01-21 21:40:34,626:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:34,627:INFO:Initializing create_model()
2025-01-21 21:40:34,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:34,627:INFO:Checking exceptions
2025-01-21 21:40:34,628:INFO:Importing libraries
2025-01-21 21:40:34,628:INFO:Copying training dataset
2025-01-21 21:40:34,632:INFO:Defining folds
2025-01-21 21:40:34,633:INFO:Declaring metric variables
2025-01-21 21:40:34,635:INFO:Importing untrained model
2025-01-21 21:40:34,637:INFO:Extra Trees Regressor Imported successfully
2025-01-21 21:40:34,642:INFO:Starting cross validation
2025-01-21 21:40:34,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:36,103:INFO:Calculating mean and std
2025-01-21 21:40:36,104:INFO:Creating metrics dataframe
2025-01-21 21:40:36,106:INFO:Uploading results into container
2025-01-21 21:40:36,106:INFO:Uploading model into container now
2025-01-21 21:40:36,107:INFO:_master_model_container: 14
2025-01-21 21:40:36,107:INFO:_display_container: 2
2025-01-21 21:40:36,107:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:40:36,107:INFO:create_model() successfully completed......................................
2025-01-21 21:40:36,205:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:36,205:INFO:Creating metrics dataframe
2025-01-21 21:40:36,212:INFO:Initializing AdaBoost Regressor
2025-01-21 21:40:36,212:INFO:Total runtime is 0.1514970342318217 minutes
2025-01-21 21:40:36,215:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:36,215:INFO:Initializing create_model()
2025-01-21 21:40:36,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:36,215:INFO:Checking exceptions
2025-01-21 21:40:36,215:INFO:Importing libraries
2025-01-21 21:40:36,215:INFO:Copying training dataset
2025-01-21 21:40:36,219:INFO:Defining folds
2025-01-21 21:40:36,219:INFO:Declaring metric variables
2025-01-21 21:40:36,222:INFO:Importing untrained model
2025-01-21 21:40:36,224:INFO:AdaBoost Regressor Imported successfully
2025-01-21 21:40:36,228:INFO:Starting cross validation
2025-01-21 21:40:36,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:36,583:INFO:Calculating mean and std
2025-01-21 21:40:36,584:INFO:Creating metrics dataframe
2025-01-21 21:40:36,586:INFO:Uploading results into container
2025-01-21 21:40:36,587:INFO:Uploading model into container now
2025-01-21 21:40:36,588:INFO:_master_model_container: 15
2025-01-21 21:40:36,588:INFO:_display_container: 2
2025-01-21 21:40:36,588:INFO:AdaBoostRegressor(random_state=123)
2025-01-21 21:40:36,588:INFO:create_model() successfully completed......................................
2025-01-21 21:40:36,697:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:36,697:INFO:Creating metrics dataframe
2025-01-21 21:40:36,705:INFO:Initializing Gradient Boosting Regressor
2025-01-21 21:40:36,705:INFO:Total runtime is 0.1597102165222168 minutes
2025-01-21 21:40:36,708:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:36,708:INFO:Initializing create_model()
2025-01-21 21:40:36,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:36,708:INFO:Checking exceptions
2025-01-21 21:40:36,708:INFO:Importing libraries
2025-01-21 21:40:36,708:INFO:Copying training dataset
2025-01-21 21:40:36,712:INFO:Defining folds
2025-01-21 21:40:36,712:INFO:Declaring metric variables
2025-01-21 21:40:36,714:INFO:Importing untrained model
2025-01-21 21:40:36,717:INFO:Gradient Boosting Regressor Imported successfully
2025-01-21 21:40:36,722:INFO:Starting cross validation
2025-01-21 21:40:36,723:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:38,588:INFO:Calculating mean and std
2025-01-21 21:40:38,589:INFO:Creating metrics dataframe
2025-01-21 21:40:38,591:INFO:Uploading results into container
2025-01-21 21:40:38,591:INFO:Uploading model into container now
2025-01-21 21:40:38,591:INFO:_master_model_container: 16
2025-01-21 21:40:38,591:INFO:_display_container: 2
2025-01-21 21:40:38,592:INFO:GradientBoostingRegressor(random_state=123)
2025-01-21 21:40:38,592:INFO:create_model() successfully completed......................................
2025-01-21 21:40:38,682:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:38,682:INFO:Creating metrics dataframe
2025-01-21 21:40:38,690:INFO:Initializing Extreme Gradient Boosting
2025-01-21 21:40:38,690:INFO:Total runtime is 0.19278669754664104 minutes
2025-01-21 21:40:38,692:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:38,692:INFO:Initializing create_model()
2025-01-21 21:40:38,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:38,692:INFO:Checking exceptions
2025-01-21 21:40:38,692:INFO:Importing libraries
2025-01-21 21:40:38,692:INFO:Copying training dataset
2025-01-21 21:40:38,696:INFO:Defining folds
2025-01-21 21:40:38,696:INFO:Declaring metric variables
2025-01-21 21:40:38,698:INFO:Importing untrained model
2025-01-21 21:40:38,701:INFO:Extreme Gradient Boosting Imported successfully
2025-01-21 21:40:38,705:INFO:Starting cross validation
2025-01-21 21:40:38,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:39,122:INFO:Calculating mean and std
2025-01-21 21:40:39,123:INFO:Creating metrics dataframe
2025-01-21 21:40:39,125:INFO:Uploading results into container
2025-01-21 21:40:39,125:INFO:Uploading model into container now
2025-01-21 21:40:39,125:INFO:_master_model_container: 17
2025-01-21 21:40:39,126:INFO:_display_container: 2
2025-01-21 21:40:39,126:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2025-01-21 21:40:39,126:INFO:create_model() successfully completed......................................
2025-01-21 21:40:39,217:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:39,218:INFO:Creating metrics dataframe
2025-01-21 21:40:39,225:INFO:Initializing Light Gradient Boosting Machine
2025-01-21 21:40:39,225:INFO:Total runtime is 0.2017077962557475 minutes
2025-01-21 21:40:39,227:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:39,227:INFO:Initializing create_model()
2025-01-21 21:40:39,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:39,228:INFO:Checking exceptions
2025-01-21 21:40:39,228:INFO:Importing libraries
2025-01-21 21:40:39,228:INFO:Copying training dataset
2025-01-21 21:40:39,232:INFO:Defining folds
2025-01-21 21:40:39,232:INFO:Declaring metric variables
2025-01-21 21:40:39,235:INFO:Importing untrained model
2025-01-21 21:40:39,237:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-21 21:40:39,241:INFO:Starting cross validation
2025-01-21 21:40:39,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:42,466:INFO:Calculating mean and std
2025-01-21 21:40:42,467:INFO:Creating metrics dataframe
2025-01-21 21:40:42,468:INFO:Uploading results into container
2025-01-21 21:40:42,469:INFO:Uploading model into container now
2025-01-21 21:40:42,469:INFO:_master_model_container: 18
2025-01-21 21:40:42,469:INFO:_display_container: 2
2025-01-21 21:40:42,469:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:40:42,469:INFO:create_model() successfully completed......................................
2025-01-21 21:40:42,561:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:42,562:INFO:Creating metrics dataframe
2025-01-21 21:40:42,569:INFO:Initializing Dummy Regressor
2025-01-21 21:40:42,569:INFO:Total runtime is 0.2574470639228821 minutes
2025-01-21 21:40:42,571:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:42,572:INFO:Initializing create_model()
2025-01-21 21:40:42,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ba50190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:42,572:INFO:Checking exceptions
2025-01-21 21:40:42,572:INFO:Importing libraries
2025-01-21 21:40:42,572:INFO:Copying training dataset
2025-01-21 21:40:42,576:INFO:Defining folds
2025-01-21 21:40:42,576:INFO:Declaring metric variables
2025-01-21 21:40:42,578:INFO:Importing untrained model
2025-01-21 21:40:42,580:INFO:Dummy Regressor Imported successfully
2025-01-21 21:40:42,586:INFO:Starting cross validation
2025-01-21 21:40:42,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:42,718:INFO:Calculating mean and std
2025-01-21 21:40:42,719:INFO:Creating metrics dataframe
2025-01-21 21:40:42,720:INFO:Uploading results into container
2025-01-21 21:40:42,721:INFO:Uploading model into container now
2025-01-21 21:40:42,721:INFO:_master_model_container: 19
2025-01-21 21:40:42,721:INFO:_display_container: 2
2025-01-21 21:40:42,721:INFO:DummyRegressor()
2025-01-21 21:40:42,721:INFO:create_model() successfully completed......................................
2025-01-21 21:40:42,811:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:42,811:INFO:Creating metrics dataframe
2025-01-21 21:40:42,819:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-21 21:40:42,824:INFO:Initializing create_model()
2025-01-21 21:40:42,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1692d3760>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:42,825:INFO:Checking exceptions
2025-01-21 21:40:42,826:INFO:Importing libraries
2025-01-21 21:40:42,826:INFO:Copying training dataset
2025-01-21 21:40:42,829:INFO:Defining folds
2025-01-21 21:40:42,829:INFO:Declaring metric variables
2025-01-21 21:40:42,829:INFO:Importing untrained model
2025-01-21 21:40:42,829:INFO:Declaring custom model
2025-01-21 21:40:42,830:INFO:Linear Regression Imported successfully
2025-01-21 21:40:42,830:INFO:Cross validation set to False
2025-01-21 21:40:42,830:INFO:Fitting Model
2025-01-21 21:40:42,859:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:40:42,859:INFO:create_model() successfully completed......................................
2025-01-21 21:40:42,972:INFO:_master_model_container: 19
2025-01-21 21:40:42,972:INFO:_display_container: 2
2025-01-21 21:40:42,972:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:40:42,972:INFO:compare_models() successfully completed......................................
2025-01-21 21:40:50,292:INFO:PyCaret RegressionExperiment
2025-01-21 21:40:50,292:INFO:Logging name: reg-default-name
2025-01-21 21:40:50,292:INFO:ML Usecase: MLUsecase.REGRESSION
2025-01-21 21:40:50,292:INFO:version 3.3.1
2025-01-21 21:40:50,292:INFO:Initializing setup()
2025-01-21 21:40:50,292:INFO:self.USI: 9e0b
2025-01-21 21:40:50,293:INFO:self._variable_keys: {'n_jobs_param', '_ml_usecase', 'idx', 'y', 'target_param', 'fold_groups_param', 'X', 'logging_param', 'X_train', 'y_test', 'fold_generator', 'exp_id', 'html_param', 'transform_target_param', 'gpu_n_jobs_param', 'memory', '_available_plots', 'USI', 'log_plots_param', 'y_train', 'exp_name_log', 'data', 'X_test', 'seed', 'pipeline', 'fold_shuffle_param', 'gpu_param'}
2025-01-21 21:40:50,293:INFO:Checking environment
2025-01-21 21:40:50,293:INFO:python_version: 3.10.13
2025-01-21 21:40:50,293:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-21 21:40:50,293:INFO:machine: arm64
2025-01-21 21:40:50,293:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-21 21:40:50,293:INFO:Memory: svmem(total=8589934592, available=1790640128, percent=79.2, used=3140616192, free=63242240, active=1740636160, inactive=1725169664, wired=1399980032)
2025-01-21 21:40:50,293:INFO:Physical Core: 8
2025-01-21 21:40:50,294:INFO:Logical Core: 8
2025-01-21 21:40:50,294:INFO:Checking libraries
2025-01-21 21:40:50,294:INFO:System:
2025-01-21 21:40:50,294:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-21 21:40:50,294:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-21 21:40:50,294:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-21 21:40:50,294:INFO:PyCaret required dependencies:
2025-01-21 21:40:50,295:INFO:                 pip: 24.2
2025-01-21 21:40:50,295:INFO:          setuptools: 75.1.0
2025-01-21 21:40:50,295:INFO:             pycaret: 3.3.1
2025-01-21 21:40:50,295:INFO:             IPython: 8.27.0
2025-01-21 21:40:50,295:INFO:          ipywidgets: 8.1.2
2025-01-21 21:40:50,295:INFO:                tqdm: 4.66.5
2025-01-21 21:40:50,295:INFO:               numpy: 1.26.4
2025-01-21 21:40:50,295:INFO:              pandas: 2.1.4
2025-01-21 21:40:50,295:INFO:              jinja2: 3.1.4
2025-01-21 21:40:50,295:INFO:               scipy: 1.11.4
2025-01-21 21:40:50,295:INFO:              joblib: 1.3.2
2025-01-21 21:40:50,295:INFO:             sklearn: 1.4.2
2025-01-21 21:40:50,295:INFO:                pyod: 2.0.2
2025-01-21 21:40:50,295:INFO:            imblearn: 0.13.0
2025-01-21 21:40:50,295:INFO:   category_encoders: 2.7.0
2025-01-21 21:40:50,295:INFO:            lightgbm: 4.4.0
2025-01-21 21:40:50,295:INFO:               numba: 0.60.0
2025-01-21 21:40:50,295:INFO:            requests: 2.32.3
2025-01-21 21:40:50,295:INFO:          matplotlib: 3.9.2
2025-01-21 21:40:50,295:INFO:          scikitplot: 0.3.7
2025-01-21 21:40:50,295:INFO:         yellowbrick: 1.5
2025-01-21 21:40:50,295:INFO:              plotly: 5.24.1
2025-01-21 21:40:50,295:INFO:    plotly-resampler: Not installed
2025-01-21 21:40:50,295:INFO:             kaleido: 0.2.1
2025-01-21 21:40:50,295:INFO:           schemdraw: 0.15
2025-01-21 21:40:50,295:INFO:         statsmodels: 0.14.4
2025-01-21 21:40:50,295:INFO:              sktime: 0.26.0
2025-01-21 21:40:50,295:INFO:               tbats: 1.1.3
2025-01-21 21:40:50,295:INFO:            pmdarima: 2.0.4
2025-01-21 21:40:50,295:INFO:              psutil: 5.9.0
2025-01-21 21:40:50,295:INFO:          markupsafe: 2.1.3
2025-01-21 21:40:50,295:INFO:             pickle5: Not installed
2025-01-21 21:40:50,295:INFO:         cloudpickle: 3.1.0
2025-01-21 21:40:50,295:INFO:         deprecation: 2.1.0
2025-01-21 21:40:50,295:INFO:              xxhash: 3.5.0
2025-01-21 21:40:50,295:INFO:           wurlitzer: 3.1.1
2025-01-21 21:40:50,295:INFO:PyCaret optional dependencies:
2025-01-21 21:40:50,295:INFO:                shap: 0.46.0
2025-01-21 21:40:50,295:INFO:           interpret: Not installed
2025-01-21 21:40:50,295:INFO:                umap: 0.5.7
2025-01-21 21:40:50,295:INFO:     ydata_profiling: Not installed
2025-01-21 21:40:50,295:INFO:  explainerdashboard: Not installed
2025-01-21 21:40:50,295:INFO:             autoviz: Not installed
2025-01-21 21:40:50,295:INFO:           fairlearn: Not installed
2025-01-21 21:40:50,295:INFO:          deepchecks: Not installed
2025-01-21 21:40:50,296:INFO:             xgboost: 2.1.3
2025-01-21 21:40:50,296:INFO:            catboost: Not installed
2025-01-21 21:40:50,296:INFO:              kmodes: Not installed
2025-01-21 21:40:50,296:INFO:             mlxtend: Not installed
2025-01-21 21:40:50,296:INFO:       statsforecast: Not installed
2025-01-21 21:40:50,296:INFO:        tune_sklearn: Not installed
2025-01-21 21:40:50,296:INFO:                 ray: Not installed
2025-01-21 21:40:50,296:INFO:            hyperopt: Not installed
2025-01-21 21:40:50,296:INFO:              optuna: Not installed
2025-01-21 21:40:50,296:INFO:               skopt: Not installed
2025-01-21 21:40:50,296:INFO:              mlflow: 2.19.0
2025-01-21 21:40:50,296:INFO:              gradio: Not installed
2025-01-21 21:40:50,296:INFO:             fastapi: Not installed
2025-01-21 21:40:50,296:INFO:             uvicorn: Not installed
2025-01-21 21:40:50,296:INFO:              m2cgen: Not installed
2025-01-21 21:40:50,296:INFO:           evidently: Not installed
2025-01-21 21:40:50,296:INFO:               fugue: Not installed
2025-01-21 21:40:50,296:INFO:           streamlit: Not installed
2025-01-21 21:40:50,296:INFO:             prophet: Not installed
2025-01-21 21:40:50,296:INFO:None
2025-01-21 21:40:50,297:INFO:Set up data.
2025-01-21 21:40:50,303:INFO:Set up folding strategy.
2025-01-21 21:40:50,303:INFO:Set up train/test split.
2025-01-21 21:40:50,306:INFO:Set up index.
2025-01-21 21:40:50,307:INFO:Assigning column types.
2025-01-21 21:40:50,309:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-21 21:40:50,309:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,312:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,355:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,387:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:50,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:50,389:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,392:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,395:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,435:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,466:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:50,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:50,468:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-01-21 21:40:50,471:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,474:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,545:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:50,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:50,550:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,553:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,592:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,623:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:50,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:50,624:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-01-21 21:40:50,631:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,702:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,702:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:50,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:50,710:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,780:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:50,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:50,782:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-01-21 21:40:50,828:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,859:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:50,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:50,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-21 21:40:50,937:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:50,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:50,939:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-21 21:40:50,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:51,016:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:51,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:51,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-21 21:40:51,094:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:51,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:51,096:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-01-21 21:40:51,172:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:51,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:51,251:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:51,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:51,253:INFO:Preparing preprocessing pipeline...
2025-01-21 21:40:51,253:INFO:Set up simple imputation.
2025-01-21 21:40:51,255:INFO:Set up encoding of categorical features.
2025-01-21 21:40:51,255:INFO:Set up column name cleaning.
2025-01-21 21:40:51,304:INFO:Finished creating preprocessing pipeline.
2025-01-21 21:40:51,309:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-01-21 21:40:51,309:INFO:Creating final display dataframe.
2025-01-21 21:40:51,446:INFO:Setup _display_container:                     Description               Value
0                    Session id                 123
1                        Target  Hispanic or Latino
2                   Target type          Regression
3           Original data shape          (2900, 12)
4        Transformed data shape          (2900, 12)
5   Transformed train set shape          (2029, 12)
6    Transformed test set shape           (871, 12)
7              Numeric features                   9
8          Categorical features                   2
9                    Preprocess                True
10              Imputation type              simple
11           Numeric imputation                mean
12       Categorical imputation                mode
13     Maximum one-hot encoding                  25
14              Encoding method                None
15               Fold Generator               KFold
16                  Fold Number                  10
17                     CPU Jobs                  -1
18                      Use GPU               False
19               Log Experiment               False
20              Experiment Name    reg-default-name
21                          USI                9e0b
2025-01-21 21:40:51,528:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:51,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:51,607:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-21 21:40:51,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-21 21:40:51,609:INFO:setup() successfully completed in 1.32s...............
2025-01-21 21:40:51,613:INFO:Initializing compare_models()
2025-01-21 21:40:51,613:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-01-21 21:40:51,613:INFO:Checking exceptions
2025-01-21 21:40:51,615:INFO:Preparing display monitor
2025-01-21 21:40:51,632:INFO:Initializing Linear Regression
2025-01-21 21:40:51,632:INFO:Total runtime is 2.666314442952474e-06 minutes
2025-01-21 21:40:51,634:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:51,635:INFO:Initializing create_model()
2025-01-21 21:40:51,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:51,635:INFO:Checking exceptions
2025-01-21 21:40:51,635:INFO:Importing libraries
2025-01-21 21:40:51,635:INFO:Copying training dataset
2025-01-21 21:40:51,642:INFO:Defining folds
2025-01-21 21:40:51,642:INFO:Declaring metric variables
2025-01-21 21:40:51,644:INFO:Importing untrained model
2025-01-21 21:40:51,646:INFO:Linear Regression Imported successfully
2025-01-21 21:40:51,651:INFO:Starting cross validation
2025-01-21 21:40:51,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:51,798:INFO:Calculating mean and std
2025-01-21 21:40:51,798:INFO:Creating metrics dataframe
2025-01-21 21:40:51,800:INFO:Uploading results into container
2025-01-21 21:40:51,800:INFO:Uploading model into container now
2025-01-21 21:40:51,800:INFO:_master_model_container: 1
2025-01-21 21:40:51,800:INFO:_display_container: 2
2025-01-21 21:40:51,801:INFO:LinearRegression(n_jobs=-1)
2025-01-21 21:40:51,801:INFO:create_model() successfully completed......................................
2025-01-21 21:40:51,932:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:51,933:INFO:Creating metrics dataframe
2025-01-21 21:40:51,937:INFO:Initializing Lasso Regression
2025-01-21 21:40:51,937:INFO:Total runtime is 0.0050869981447855634 minutes
2025-01-21 21:40:51,940:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:51,940:INFO:Initializing create_model()
2025-01-21 21:40:51,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:51,940:INFO:Checking exceptions
2025-01-21 21:40:51,940:INFO:Importing libraries
2025-01-21 21:40:51,940:INFO:Copying training dataset
2025-01-21 21:40:51,945:INFO:Defining folds
2025-01-21 21:40:51,945:INFO:Declaring metric variables
2025-01-21 21:40:51,947:INFO:Importing untrained model
2025-01-21 21:40:51,949:INFO:Lasso Regression Imported successfully
2025-01-21 21:40:51,954:INFO:Starting cross validation
2025-01-21 21:40:51,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:52,034:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.997e+11, tolerance: 3.728e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,047:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.764e+11, tolerance: 3.510e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,050:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.995e+11, tolerance: 3.641e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,051:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.509e+11, tolerance: 3.570e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,062:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.009e+11, tolerance: 3.548e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,068:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.669e+11, tolerance: 1.447e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,093:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.155e+11, tolerance: 3.606e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,102:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.576e+11, tolerance: 3.489e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,168:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.028e+11, tolerance: 3.617e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,186:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.862e+11, tolerance: 3.618e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,225:INFO:Calculating mean and std
2025-01-21 21:40:52,226:INFO:Creating metrics dataframe
2025-01-21 21:40:52,228:INFO:Uploading results into container
2025-01-21 21:40:52,228:INFO:Uploading model into container now
2025-01-21 21:40:52,229:INFO:_master_model_container: 2
2025-01-21 21:40:52,229:INFO:_display_container: 2
2025-01-21 21:40:52,229:INFO:Lasso(random_state=123)
2025-01-21 21:40:52,229:INFO:create_model() successfully completed......................................
2025-01-21 21:40:52,373:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:52,373:INFO:Creating metrics dataframe
2025-01-21 21:40:52,379:INFO:Initializing Ridge Regression
2025-01-21 21:40:52,379:INFO:Total runtime is 0.012444730599721274 minutes
2025-01-21 21:40:52,382:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:52,382:INFO:Initializing create_model()
2025-01-21 21:40:52,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:52,382:INFO:Checking exceptions
2025-01-21 21:40:52,382:INFO:Importing libraries
2025-01-21 21:40:52,382:INFO:Copying training dataset
2025-01-21 21:40:52,410:INFO:Defining folds
2025-01-21 21:40:52,410:INFO:Declaring metric variables
2025-01-21 21:40:52,414:INFO:Importing untrained model
2025-01-21 21:40:52,418:INFO:Ridge Regression Imported successfully
2025-01-21 21:40:52,426:INFO:Starting cross validation
2025-01-21 21:40:52,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:52,568:INFO:Calculating mean and std
2025-01-21 21:40:52,568:INFO:Creating metrics dataframe
2025-01-21 21:40:52,570:INFO:Uploading results into container
2025-01-21 21:40:52,570:INFO:Uploading model into container now
2025-01-21 21:40:52,570:INFO:_master_model_container: 3
2025-01-21 21:40:52,570:INFO:_display_container: 2
2025-01-21 21:40:52,571:INFO:Ridge(random_state=123)
2025-01-21 21:40:52,571:INFO:create_model() successfully completed......................................
2025-01-21 21:40:52,668:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:52,668:INFO:Creating metrics dataframe
2025-01-21 21:40:52,673:INFO:Initializing Elastic Net
2025-01-21 21:40:52,673:INFO:Total runtime is 0.01734762986501058 minutes
2025-01-21 21:40:52,676:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:52,676:INFO:Initializing create_model()
2025-01-21 21:40:52,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:52,676:INFO:Checking exceptions
2025-01-21 21:40:52,676:INFO:Importing libraries
2025-01-21 21:40:52,676:INFO:Copying training dataset
2025-01-21 21:40:52,680:INFO:Defining folds
2025-01-21 21:40:52,681:INFO:Declaring metric variables
2025-01-21 21:40:52,683:INFO:Importing untrained model
2025-01-21 21:40:52,686:INFO:Elastic Net Imported successfully
2025-01-21 21:40:52,691:INFO:Starting cross validation
2025-01-21 21:40:52,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:52,776:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.509e+11, tolerance: 3.570e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,777:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.995e+11, tolerance: 3.641e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,778:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.997e+11, tolerance: 3.728e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,781:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.764e+11, tolerance: 3.510e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,788:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.576e+11, tolerance: 3.489e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,791:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.669e+11, tolerance: 1.447e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,806:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.009e+11, tolerance: 3.548e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,816:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.155e+11, tolerance: 3.606e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,858:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.028e+11, tolerance: 3.617e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,865:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.862e+11, tolerance: 3.618e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-21 21:40:52,890:INFO:Calculating mean and std
2025-01-21 21:40:52,891:INFO:Creating metrics dataframe
2025-01-21 21:40:52,893:INFO:Uploading results into container
2025-01-21 21:40:52,894:INFO:Uploading model into container now
2025-01-21 21:40:52,894:INFO:_master_model_container: 4
2025-01-21 21:40:52,894:INFO:_display_container: 2
2025-01-21 21:40:52,895:INFO:ElasticNet(random_state=123)
2025-01-21 21:40:52,895:INFO:create_model() successfully completed......................................
2025-01-21 21:40:53,001:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:53,001:INFO:Creating metrics dataframe
2025-01-21 21:40:53,006:INFO:Initializing Least Angle Regression
2025-01-21 21:40:53,006:INFO:Total runtime is 0.0229035496711731 minutes
2025-01-21 21:40:53,009:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:53,009:INFO:Initializing create_model()
2025-01-21 21:40:53,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:53,009:INFO:Checking exceptions
2025-01-21 21:40:53,009:INFO:Importing libraries
2025-01-21 21:40:53,009:INFO:Copying training dataset
2025-01-21 21:40:53,013:INFO:Defining folds
2025-01-21 21:40:53,014:INFO:Declaring metric variables
2025-01-21 21:40:53,016:INFO:Importing untrained model
2025-01-21 21:40:53,018:INFO:Least Angle Regression Imported successfully
2025-01-21 21:40:53,023:INFO:Starting cross validation
2025-01-21 21:40:53,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:53,073:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.261e+09, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,074:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.854e+08, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,074:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.085e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,074:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.478e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,075:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.317e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,082:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.749e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,083:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.536e-06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,098:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.541e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,099:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.304e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,099:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.600e+07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,099:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.223e+06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,110:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.374e-06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,126:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.158e+04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,126:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.973e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,132:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.264e+09, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,132:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.880e+08, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,133:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.914e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,133:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.046e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,133:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.043e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,165:INFO:Calculating mean and std
2025-01-21 21:40:53,166:INFO:Creating metrics dataframe
2025-01-21 21:40:53,168:INFO:Uploading results into container
2025-01-21 21:40:53,168:INFO:Uploading model into container now
2025-01-21 21:40:53,169:INFO:_master_model_container: 5
2025-01-21 21:40:53,169:INFO:_display_container: 2
2025-01-21 21:40:53,169:INFO:Lars(random_state=123)
2025-01-21 21:40:53,169:INFO:create_model() successfully completed......................................
2025-01-21 21:40:53,270:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:53,270:INFO:Creating metrics dataframe
2025-01-21 21:40:53,276:INFO:Initializing Lasso Least Angle Regression
2025-01-21 21:40:53,276:INFO:Total runtime is 0.02739526430765788 minutes
2025-01-21 21:40:53,278:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:53,279:INFO:Initializing create_model()
2025-01-21 21:40:53,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:53,279:INFO:Checking exceptions
2025-01-21 21:40:53,279:INFO:Importing libraries
2025-01-21 21:40:53,279:INFO:Copying training dataset
2025-01-21 21:40:53,284:INFO:Defining folds
2025-01-21 21:40:53,284:INFO:Declaring metric variables
2025-01-21 21:40:53,287:INFO:Importing untrained model
2025-01-21 21:40:53,290:INFO:Lasso Least Angle Regression Imported successfully
2025-01-21 21:40:53,296:INFO:Starting cross validation
2025-01-21 21:40:53,298:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:53,358:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.261e+09, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,358:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.854e+08, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,359:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 5 iterations, alpha=4.752e+08, previous alpha=2.744e+08, with an active set of 4 regressors.
  warnings.warn(

2025-01-21 21:40:53,380:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 2 iterations, alpha=7.161e+08, previous alpha=5.589e+08, with an active set of 3 regressors.
  warnings.warn(

2025-01-21 21:40:53,435:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.264e+09, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.880e+08, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-21 21:40:53,436:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 5 iterations, alpha=4.171e+08, previous alpha=2.348e+08, with an active set of 4 regressors.
  warnings.warn(

2025-01-21 21:40:53,464:INFO:Calculating mean and std
2025-01-21 21:40:53,465:INFO:Creating metrics dataframe
2025-01-21 21:40:53,467:INFO:Uploading results into container
2025-01-21 21:40:53,467:INFO:Uploading model into container now
2025-01-21 21:40:53,468:INFO:_master_model_container: 6
2025-01-21 21:40:53,468:INFO:_display_container: 2
2025-01-21 21:40:53,468:INFO:LassoLars(random_state=123)
2025-01-21 21:40:53,468:INFO:create_model() successfully completed......................................
2025-01-21 21:40:53,563:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:53,563:INFO:Creating metrics dataframe
2025-01-21 21:40:53,569:INFO:Initializing Orthogonal Matching Pursuit
2025-01-21 21:40:53,569:INFO:Total runtime is 0.03228748242060344 minutes
2025-01-21 21:40:53,572:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:53,572:INFO:Initializing create_model()
2025-01-21 21:40:53,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:53,572:INFO:Checking exceptions
2025-01-21 21:40:53,572:INFO:Importing libraries
2025-01-21 21:40:53,572:INFO:Copying training dataset
2025-01-21 21:40:53,577:INFO:Defining folds
2025-01-21 21:40:53,577:INFO:Declaring metric variables
2025-01-21 21:40:53,579:INFO:Importing untrained model
2025-01-21 21:40:53,582:INFO:Orthogonal Matching Pursuit Imported successfully
2025-01-21 21:40:53,589:INFO:Starting cross validation
2025-01-21 21:40:53,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:53,722:INFO:Calculating mean and std
2025-01-21 21:40:53,723:INFO:Creating metrics dataframe
2025-01-21 21:40:53,724:INFO:Uploading results into container
2025-01-21 21:40:53,724:INFO:Uploading model into container now
2025-01-21 21:40:53,725:INFO:_master_model_container: 7
2025-01-21 21:40:53,725:INFO:_display_container: 2
2025-01-21 21:40:53,725:INFO:OrthogonalMatchingPursuit()
2025-01-21 21:40:53,725:INFO:create_model() successfully completed......................................
2025-01-21 21:40:53,820:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:53,820:INFO:Creating metrics dataframe
2025-01-21 21:40:53,826:INFO:Initializing Bayesian Ridge
2025-01-21 21:40:53,826:INFO:Total runtime is 0.036569333076477056 minutes
2025-01-21 21:40:53,829:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:53,829:INFO:Initializing create_model()
2025-01-21 21:40:53,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:53,829:INFO:Checking exceptions
2025-01-21 21:40:53,829:INFO:Importing libraries
2025-01-21 21:40:53,829:INFO:Copying training dataset
2025-01-21 21:40:53,834:INFO:Defining folds
2025-01-21 21:40:53,834:INFO:Declaring metric variables
2025-01-21 21:40:53,836:INFO:Importing untrained model
2025-01-21 21:40:53,839:INFO:Bayesian Ridge Imported successfully
2025-01-21 21:40:53,844:INFO:Starting cross validation
2025-01-21 21:40:53,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:53,985:INFO:Calculating mean and std
2025-01-21 21:40:53,986:INFO:Creating metrics dataframe
2025-01-21 21:40:53,988:INFO:Uploading results into container
2025-01-21 21:40:53,988:INFO:Uploading model into container now
2025-01-21 21:40:53,989:INFO:_master_model_container: 8
2025-01-21 21:40:53,989:INFO:_display_container: 2
2025-01-21 21:40:53,989:INFO:BayesianRidge()
2025-01-21 21:40:53,989:INFO:create_model() successfully completed......................................
2025-01-21 21:40:54,087:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:54,088:INFO:Creating metrics dataframe
2025-01-21 21:40:54,094:INFO:Initializing Passive Aggressive Regressor
2025-01-21 21:40:54,094:INFO:Total runtime is 0.04103748401006063 minutes
2025-01-21 21:40:54,097:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:54,097:INFO:Initializing create_model()
2025-01-21 21:40:54,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:54,097:INFO:Checking exceptions
2025-01-21 21:40:54,098:INFO:Importing libraries
2025-01-21 21:40:54,098:INFO:Copying training dataset
2025-01-21 21:40:54,102:INFO:Defining folds
2025-01-21 21:40:54,102:INFO:Declaring metric variables
2025-01-21 21:40:54,108:INFO:Importing untrained model
2025-01-21 21:40:54,134:INFO:Passive Aggressive Regressor Imported successfully
2025-01-21 21:40:54,145:INFO:Starting cross validation
2025-01-21 21:40:54,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:54,344:INFO:Calculating mean and std
2025-01-21 21:40:54,346:INFO:Creating metrics dataframe
2025-01-21 21:40:54,348:INFO:Uploading results into container
2025-01-21 21:40:54,348:INFO:Uploading model into container now
2025-01-21 21:40:54,349:INFO:_master_model_container: 9
2025-01-21 21:40:54,349:INFO:_display_container: 2
2025-01-21 21:40:54,350:INFO:PassiveAggressiveRegressor(random_state=123)
2025-01-21 21:40:54,350:INFO:create_model() successfully completed......................................
2025-01-21 21:40:54,462:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:54,462:INFO:Creating metrics dataframe
2025-01-21 21:40:54,468:INFO:Initializing Huber Regressor
2025-01-21 21:40:54,469:INFO:Total runtime is 0.04727233250935873 minutes
2025-01-21 21:40:54,471:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:54,471:INFO:Initializing create_model()
2025-01-21 21:40:54,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:54,471:INFO:Checking exceptions
2025-01-21 21:40:54,471:INFO:Importing libraries
2025-01-21 21:40:54,471:INFO:Copying training dataset
2025-01-21 21:40:54,476:INFO:Defining folds
2025-01-21 21:40:54,476:INFO:Declaring metric variables
2025-01-21 21:40:54,479:INFO:Importing untrained model
2025-01-21 21:40:54,483:INFO:Huber Regressor Imported successfully
2025-01-21 21:40:54,487:INFO:Starting cross validation
2025-01-21 21:40:54,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:54,692:INFO:Calculating mean and std
2025-01-21 21:40:54,693:INFO:Creating metrics dataframe
2025-01-21 21:40:54,695:INFO:Uploading results into container
2025-01-21 21:40:54,695:INFO:Uploading model into container now
2025-01-21 21:40:54,695:INFO:_master_model_container: 10
2025-01-21 21:40:54,695:INFO:_display_container: 2
2025-01-21 21:40:54,696:INFO:HuberRegressor()
2025-01-21 21:40:54,696:INFO:create_model() successfully completed......................................
2025-01-21 21:40:54,795:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:54,795:INFO:Creating metrics dataframe
2025-01-21 21:40:54,802:INFO:Initializing K Neighbors Regressor
2025-01-21 21:40:54,802:INFO:Total runtime is 0.052836632728576666 minutes
2025-01-21 21:40:54,805:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:54,805:INFO:Initializing create_model()
2025-01-21 21:40:54,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:54,805:INFO:Checking exceptions
2025-01-21 21:40:54,805:INFO:Importing libraries
2025-01-21 21:40:54,805:INFO:Copying training dataset
2025-01-21 21:40:54,809:INFO:Defining folds
2025-01-21 21:40:54,810:INFO:Declaring metric variables
2025-01-21 21:40:54,812:INFO:Importing untrained model
2025-01-21 21:40:54,814:INFO:K Neighbors Regressor Imported successfully
2025-01-21 21:40:54,819:INFO:Starting cross validation
2025-01-21 21:40:54,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:54,978:INFO:Calculating mean and std
2025-01-21 21:40:54,978:INFO:Creating metrics dataframe
2025-01-21 21:40:54,980:INFO:Uploading results into container
2025-01-21 21:40:54,980:INFO:Uploading model into container now
2025-01-21 21:40:54,980:INFO:_master_model_container: 11
2025-01-21 21:40:54,980:INFO:_display_container: 2
2025-01-21 21:40:54,981:INFO:KNeighborsRegressor(n_jobs=-1)
2025-01-21 21:40:54,981:INFO:create_model() successfully completed......................................
2025-01-21 21:40:55,073:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:55,073:INFO:Creating metrics dataframe
2025-01-21 21:40:55,080:INFO:Initializing Decision Tree Regressor
2025-01-21 21:40:55,080:INFO:Total runtime is 0.05745911598205567 minutes
2025-01-21 21:40:55,082:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:55,082:INFO:Initializing create_model()
2025-01-21 21:40:55,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:55,082:INFO:Checking exceptions
2025-01-21 21:40:55,082:INFO:Importing libraries
2025-01-21 21:40:55,082:INFO:Copying training dataset
2025-01-21 21:40:55,086:INFO:Defining folds
2025-01-21 21:40:55,086:INFO:Declaring metric variables
2025-01-21 21:40:55,088:INFO:Importing untrained model
2025-01-21 21:40:55,090:INFO:Decision Tree Regressor Imported successfully
2025-01-21 21:40:55,095:INFO:Starting cross validation
2025-01-21 21:40:55,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:55,296:INFO:Calculating mean and std
2025-01-21 21:40:55,297:INFO:Creating metrics dataframe
2025-01-21 21:40:55,299:INFO:Uploading results into container
2025-01-21 21:40:55,299:INFO:Uploading model into container now
2025-01-21 21:40:55,300:INFO:_master_model_container: 12
2025-01-21 21:40:55,300:INFO:_display_container: 2
2025-01-21 21:40:55,300:INFO:DecisionTreeRegressor(random_state=123)
2025-01-21 21:40:55,300:INFO:create_model() successfully completed......................................
2025-01-21 21:40:55,396:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:55,396:INFO:Creating metrics dataframe
2025-01-21 21:40:55,403:INFO:Initializing Random Forest Regressor
2025-01-21 21:40:55,403:INFO:Total runtime is 0.0628514329592387 minutes
2025-01-21 21:40:55,406:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:55,406:INFO:Initializing create_model()
2025-01-21 21:40:55,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:55,406:INFO:Checking exceptions
2025-01-21 21:40:55,406:INFO:Importing libraries
2025-01-21 21:40:55,406:INFO:Copying training dataset
2025-01-21 21:40:55,410:INFO:Defining folds
2025-01-21 21:40:55,410:INFO:Declaring metric variables
2025-01-21 21:40:55,413:INFO:Importing untrained model
2025-01-21 21:40:55,415:INFO:Random Forest Regressor Imported successfully
2025-01-21 21:40:55,421:INFO:Starting cross validation
2025-01-21 21:40:55,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:40:59,789:INFO:Calculating mean and std
2025-01-21 21:40:59,791:INFO:Creating metrics dataframe
2025-01-21 21:40:59,792:INFO:Uploading results into container
2025-01-21 21:40:59,793:INFO:Uploading model into container now
2025-01-21 21:40:59,793:INFO:_master_model_container: 13
2025-01-21 21:40:59,793:INFO:_display_container: 2
2025-01-21 21:40:59,794:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:40:59,794:INFO:create_model() successfully completed......................................
2025-01-21 21:40:59,891:INFO:SubProcess create_model() end ==================================
2025-01-21 21:40:59,891:INFO:Creating metrics dataframe
2025-01-21 21:40:59,898:INFO:Initializing Extra Trees Regressor
2025-01-21 21:40:59,898:INFO:Total runtime is 0.137757949034373 minutes
2025-01-21 21:40:59,900:INFO:SubProcess create_model() called ==================================
2025-01-21 21:40:59,900:INFO:Initializing create_model()
2025-01-21 21:40:59,900:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:40:59,900:INFO:Checking exceptions
2025-01-21 21:40:59,900:INFO:Importing libraries
2025-01-21 21:40:59,900:INFO:Copying training dataset
2025-01-21 21:40:59,904:INFO:Defining folds
2025-01-21 21:40:59,904:INFO:Declaring metric variables
2025-01-21 21:40:59,906:INFO:Importing untrained model
2025-01-21 21:40:59,922:INFO:Extra Trees Regressor Imported successfully
2025-01-21 21:40:59,935:INFO:Starting cross validation
2025-01-21 21:40:59,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:41:01,393:INFO:Calculating mean and std
2025-01-21 21:41:01,394:INFO:Creating metrics dataframe
2025-01-21 21:41:01,396:INFO:Uploading results into container
2025-01-21 21:41:01,396:INFO:Uploading model into container now
2025-01-21 21:41:01,397:INFO:_master_model_container: 14
2025-01-21 21:41:01,397:INFO:_display_container: 2
2025-01-21 21:41:01,398:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:41:01,398:INFO:create_model() successfully completed......................................
2025-01-21 21:41:01,499:INFO:SubProcess create_model() end ==================================
2025-01-21 21:41:01,499:INFO:Creating metrics dataframe
2025-01-21 21:41:01,506:INFO:Initializing AdaBoost Regressor
2025-01-21 21:41:01,507:INFO:Total runtime is 0.16457113424936934 minutes
2025-01-21 21:41:01,509:INFO:SubProcess create_model() called ==================================
2025-01-21 21:41:01,509:INFO:Initializing create_model()
2025-01-21 21:41:01,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:41:01,509:INFO:Checking exceptions
2025-01-21 21:41:01,509:INFO:Importing libraries
2025-01-21 21:41:01,509:INFO:Copying training dataset
2025-01-21 21:41:01,513:INFO:Defining folds
2025-01-21 21:41:01,513:INFO:Declaring metric variables
2025-01-21 21:41:01,515:INFO:Importing untrained model
2025-01-21 21:41:01,518:INFO:AdaBoost Regressor Imported successfully
2025-01-21 21:41:01,523:INFO:Starting cross validation
2025-01-21 21:41:01,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:41:02,175:INFO:Calculating mean and std
2025-01-21 21:41:02,176:INFO:Creating metrics dataframe
2025-01-21 21:41:02,177:INFO:Uploading results into container
2025-01-21 21:41:02,177:INFO:Uploading model into container now
2025-01-21 21:41:02,178:INFO:_master_model_container: 15
2025-01-21 21:41:02,178:INFO:_display_container: 2
2025-01-21 21:41:02,178:INFO:AdaBoostRegressor(random_state=123)
2025-01-21 21:41:02,178:INFO:create_model() successfully completed......................................
2025-01-21 21:41:02,268:INFO:SubProcess create_model() end ==================================
2025-01-21 21:41:02,268:INFO:Creating metrics dataframe
2025-01-21 21:41:02,275:INFO:Initializing Gradient Boosting Regressor
2025-01-21 21:41:02,275:INFO:Total runtime is 0.1773834347724915 minutes
2025-01-21 21:41:02,277:INFO:SubProcess create_model() called ==================================
2025-01-21 21:41:02,277:INFO:Initializing create_model()
2025-01-21 21:41:02,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:41:02,278:INFO:Checking exceptions
2025-01-21 21:41:02,278:INFO:Importing libraries
2025-01-21 21:41:02,278:INFO:Copying training dataset
2025-01-21 21:41:02,281:INFO:Defining folds
2025-01-21 21:41:02,281:INFO:Declaring metric variables
2025-01-21 21:41:02,283:INFO:Importing untrained model
2025-01-21 21:41:02,286:INFO:Gradient Boosting Regressor Imported successfully
2025-01-21 21:41:02,290:INFO:Starting cross validation
2025-01-21 21:41:02,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:41:04,175:INFO:Calculating mean and std
2025-01-21 21:41:04,176:INFO:Creating metrics dataframe
2025-01-21 21:41:04,177:INFO:Uploading results into container
2025-01-21 21:41:04,178:INFO:Uploading model into container now
2025-01-21 21:41:04,178:INFO:_master_model_container: 16
2025-01-21 21:41:04,178:INFO:_display_container: 2
2025-01-21 21:41:04,179:INFO:GradientBoostingRegressor(random_state=123)
2025-01-21 21:41:04,179:INFO:create_model() successfully completed......................................
2025-01-21 21:41:04,269:INFO:SubProcess create_model() end ==================================
2025-01-21 21:41:04,269:INFO:Creating metrics dataframe
2025-01-21 21:41:04,276:INFO:Initializing Extreme Gradient Boosting
2025-01-21 21:41:04,276:INFO:Total runtime is 0.21073191563288374 minutes
2025-01-21 21:41:04,278:INFO:SubProcess create_model() called ==================================
2025-01-21 21:41:04,278:INFO:Initializing create_model()
2025-01-21 21:41:04,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:41:04,278:INFO:Checking exceptions
2025-01-21 21:41:04,278:INFO:Importing libraries
2025-01-21 21:41:04,278:INFO:Copying training dataset
2025-01-21 21:41:04,282:INFO:Defining folds
2025-01-21 21:41:04,282:INFO:Declaring metric variables
2025-01-21 21:41:04,284:INFO:Importing untrained model
2025-01-21 21:41:04,287:INFO:Extreme Gradient Boosting Imported successfully
2025-01-21 21:41:04,292:INFO:Starting cross validation
2025-01-21 21:41:04,294:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:41:04,792:INFO:Calculating mean and std
2025-01-21 21:41:04,793:INFO:Creating metrics dataframe
2025-01-21 21:41:04,794:INFO:Uploading results into container
2025-01-21 21:41:04,795:INFO:Uploading model into container now
2025-01-21 21:41:04,795:INFO:_master_model_container: 17
2025-01-21 21:41:04,795:INFO:_display_container: 2
2025-01-21 21:41:04,796:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2025-01-21 21:41:04,796:INFO:create_model() successfully completed......................................
2025-01-21 21:41:04,887:INFO:SubProcess create_model() end ==================================
2025-01-21 21:41:04,887:INFO:Creating metrics dataframe
2025-01-21 21:41:04,894:INFO:Initializing Light Gradient Boosting Machine
2025-01-21 21:41:04,894:INFO:Total runtime is 0.2210372646649679 minutes
2025-01-21 21:41:04,896:INFO:SubProcess create_model() called ==================================
2025-01-21 21:41:04,897:INFO:Initializing create_model()
2025-01-21 21:41:04,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:41:04,897:INFO:Checking exceptions
2025-01-21 21:41:04,897:INFO:Importing libraries
2025-01-21 21:41:04,897:INFO:Copying training dataset
2025-01-21 21:41:04,901:INFO:Defining folds
2025-01-21 21:41:04,901:INFO:Declaring metric variables
2025-01-21 21:41:04,903:INFO:Importing untrained model
2025-01-21 21:41:04,905:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-21 21:41:04,910:INFO:Starting cross validation
2025-01-21 21:41:04,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:41:08,051:INFO:Calculating mean and std
2025-01-21 21:41:08,052:INFO:Creating metrics dataframe
2025-01-21 21:41:08,053:INFO:Uploading results into container
2025-01-21 21:41:08,053:INFO:Uploading model into container now
2025-01-21 21:41:08,054:INFO:_master_model_container: 18
2025-01-21 21:41:08,054:INFO:_display_container: 2
2025-01-21 21:41:08,054:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-01-21 21:41:08,054:INFO:create_model() successfully completed......................................
2025-01-21 21:41:08,144:INFO:SubProcess create_model() end ==================================
2025-01-21 21:41:08,144:INFO:Creating metrics dataframe
2025-01-21 21:41:08,152:INFO:Initializing Dummy Regressor
2025-01-21 21:41:08,152:INFO:Total runtime is 0.27532335122426355 minutes
2025-01-21 21:41:08,154:INFO:SubProcess create_model() called ==================================
2025-01-21 21:41:08,154:INFO:Initializing create_model()
2025-01-21 21:41:08,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16ad94a60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:41:08,154:INFO:Checking exceptions
2025-01-21 21:41:08,154:INFO:Importing libraries
2025-01-21 21:41:08,154:INFO:Copying training dataset
2025-01-21 21:41:08,158:INFO:Defining folds
2025-01-21 21:41:08,158:INFO:Declaring metric variables
2025-01-21 21:41:08,160:INFO:Importing untrained model
2025-01-21 21:41:08,162:INFO:Dummy Regressor Imported successfully
2025-01-21 21:41:08,166:INFO:Starting cross validation
2025-01-21 21:41:08,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-21 21:41:08,297:INFO:Calculating mean and std
2025-01-21 21:41:08,298:INFO:Creating metrics dataframe
2025-01-21 21:41:08,299:INFO:Uploading results into container
2025-01-21 21:41:08,299:INFO:Uploading model into container now
2025-01-21 21:41:08,300:INFO:_master_model_container: 19
2025-01-21 21:41:08,300:INFO:_display_container: 2
2025-01-21 21:41:08,300:INFO:DummyRegressor()
2025-01-21 21:41:08,300:INFO:create_model() successfully completed......................................
2025-01-21 21:41:08,390:INFO:SubProcess create_model() end ==================================
2025-01-21 21:41:08,390:INFO:Creating metrics dataframe
2025-01-21 21:41:08,398:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-21 21:41:08,403:INFO:Initializing create_model()
2025-01-21 21:41:08,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16ae19d20>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-21 21:41:08,403:INFO:Checking exceptions
2025-01-21 21:41:08,404:INFO:Importing libraries
2025-01-21 21:41:08,404:INFO:Copying training dataset
2025-01-21 21:41:08,408:INFO:Defining folds
2025-01-21 21:41:08,408:INFO:Declaring metric variables
2025-01-21 21:41:08,408:INFO:Importing untrained model
2025-01-21 21:41:08,408:INFO:Declaring custom model
2025-01-21 21:41:08,408:INFO:Huber Regressor Imported successfully
2025-01-21 21:41:08,409:INFO:Cross validation set to False
2025-01-21 21:41:08,409:INFO:Fitting Model
2025-01-21 21:41:08,466:INFO:HuberRegressor()
2025-01-21 21:41:08,466:INFO:create_model() successfully completed......................................
2025-01-21 21:41:08,573:INFO:_master_model_container: 19
2025-01-21 21:41:08,573:INFO:_display_container: 2
2025-01-21 21:41:08,573:INFO:HuberRegressor()
2025-01-21 21:41:08,573:INFO:compare_models() successfully completed......................................
2025-01-22 20:14:32,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-22 20:14:32,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-22 20:14:32,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-22 20:14:32,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-01-22 20:14:33,379:INFO:PyCaret RegressionExperiment
2025-01-22 20:14:33,379:INFO:Logging name: reg-default-name
2025-01-22 20:14:33,379:INFO:ML Usecase: MLUsecase.REGRESSION
2025-01-22 20:14:33,379:INFO:version 3.3.1
2025-01-22 20:14:33,379:INFO:Initializing setup()
2025-01-22 20:14:33,379:INFO:self.USI: 524b
2025-01-22 20:14:33,379:INFO:self._variable_keys: {'pipeline', 'html_param', 'fold_groups_param', 'logging_param', 'idx', 'target_param', 'y', 'X', 'gpu_n_jobs_param', 'X_test', 'log_plots_param', '_ml_usecase', '_available_plots', 'USI', 'transform_target_param', 'n_jobs_param', 'X_train', 'y_train', 'exp_name_log', 'fold_shuffle_param', 'seed', 'memory', 'y_test', 'exp_id', 'gpu_param', 'data', 'fold_generator'}
2025-01-22 20:14:33,379:INFO:Checking environment
2025-01-22 20:14:33,379:INFO:python_version: 3.10.13
2025-01-22 20:14:33,379:INFO:python_build: ('main', 'Dec 23 2023 15:35:25')
2025-01-22 20:14:33,379:INFO:machine: arm64
2025-01-22 20:14:33,379:INFO:platform: macOS-15.2-arm64-arm-64bit
2025-01-22 20:14:33,379:INFO:Memory: svmem(total=8589934592, available=2122334208, percent=75.3, used=3533209600, free=62717952, active=2077769728, inactive=1975517184, wired=1455439872)
2025-01-22 20:14:33,379:INFO:Physical Core: 8
2025-01-22 20:14:33,379:INFO:Logical Core: 8
2025-01-22 20:14:33,379:INFO:Checking libraries
2025-01-22 20:14:33,379:INFO:System:
2025-01-22 20:14:33,379:INFO:    python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:35:25) [Clang 16.0.6 ]
2025-01-22 20:14:33,380:INFO:executable: /opt/miniconda3/envs/P1/bin/python
2025-01-22 20:14:33,380:INFO:   machine: macOS-15.2-arm64-arm-64bit
2025-01-22 20:14:33,380:INFO:PyCaret required dependencies:
2025-01-22 20:14:33,441:INFO:                 pip: 24.2
2025-01-22 20:14:33,441:INFO:          setuptools: 75.1.0
2025-01-22 20:14:33,441:INFO:             pycaret: 3.3.1
2025-01-22 20:14:33,441:INFO:             IPython: 8.27.0
2025-01-22 20:14:33,441:INFO:          ipywidgets: 8.1.2
2025-01-22 20:14:33,441:INFO:                tqdm: 4.66.5
2025-01-22 20:14:33,441:INFO:               numpy: 1.26.4
2025-01-22 20:14:33,441:INFO:              pandas: 2.1.4
2025-01-22 20:14:33,441:INFO:              jinja2: 3.1.4
2025-01-22 20:14:33,441:INFO:               scipy: 1.11.4
2025-01-22 20:14:33,441:INFO:              joblib: 1.3.2
2025-01-22 20:14:33,441:INFO:             sklearn: 1.4.2
2025-01-22 20:14:33,441:INFO:                pyod: 2.0.2
2025-01-22 20:14:33,441:INFO:            imblearn: 0.13.0
2025-01-22 20:14:33,441:INFO:   category_encoders: 2.7.0
2025-01-22 20:14:33,441:INFO:            lightgbm: 4.4.0
2025-01-22 20:14:33,441:INFO:               numba: 0.60.0
2025-01-22 20:14:33,441:INFO:            requests: 2.32.3
2025-01-22 20:14:33,441:INFO:          matplotlib: 3.9.2
2025-01-22 20:14:33,441:INFO:          scikitplot: 0.3.7
2025-01-22 20:14:33,441:INFO:         yellowbrick: 1.5
2025-01-22 20:14:33,441:INFO:              plotly: 5.24.1
2025-01-22 20:14:33,441:INFO:    plotly-resampler: Not installed
2025-01-22 20:14:33,441:INFO:             kaleido: 0.2.1
2025-01-22 20:14:33,441:INFO:           schemdraw: 0.15
2025-01-22 20:14:33,441:INFO:         statsmodels: 0.14.4
2025-01-22 20:14:33,441:INFO:              sktime: 0.26.0
2025-01-22 20:14:33,441:INFO:               tbats: 1.1.3
2025-01-22 20:14:33,441:INFO:            pmdarima: 2.0.4
2025-01-22 20:14:33,441:INFO:              psutil: 5.9.0
2025-01-22 20:14:33,441:INFO:          markupsafe: 2.1.3
2025-01-22 20:14:33,441:INFO:             pickle5: Not installed
2025-01-22 20:14:33,441:INFO:         cloudpickle: 3.1.0
2025-01-22 20:14:33,441:INFO:         deprecation: 2.1.0
2025-01-22 20:14:33,441:INFO:              xxhash: 3.5.0
2025-01-22 20:14:33,441:INFO:           wurlitzer: 3.1.1
2025-01-22 20:14:33,441:INFO:PyCaret optional dependencies:
2025-01-22 20:14:33,478:INFO:                shap: 0.46.0
2025-01-22 20:14:33,478:INFO:           interpret: Not installed
2025-01-22 20:14:33,478:INFO:                umap: 0.5.7
2025-01-22 20:14:33,478:INFO:     ydata_profiling: Not installed
2025-01-22 20:14:33,478:INFO:  explainerdashboard: Not installed
2025-01-22 20:14:33,478:INFO:             autoviz: Not installed
2025-01-22 20:14:33,478:INFO:           fairlearn: Not installed
2025-01-22 20:14:33,478:INFO:          deepchecks: Not installed
2025-01-22 20:14:33,478:INFO:             xgboost: 2.1.3
2025-01-22 20:14:33,478:INFO:            catboost: Not installed
2025-01-22 20:14:33,478:INFO:              kmodes: Not installed
2025-01-22 20:14:33,478:INFO:             mlxtend: Not installed
2025-01-22 20:14:33,478:INFO:       statsforecast: Not installed
2025-01-22 20:14:33,478:INFO:        tune_sklearn: Not installed
2025-01-22 20:14:33,478:INFO:                 ray: Not installed
2025-01-22 20:14:33,478:INFO:            hyperopt: Not installed
2025-01-22 20:14:33,478:INFO:              optuna: Not installed
2025-01-22 20:14:33,478:INFO:               skopt: Not installed
2025-01-22 20:14:33,478:INFO:              mlflow: 2.19.0
2025-01-22 20:14:33,478:INFO:              gradio: Not installed
2025-01-22 20:14:33,478:INFO:             fastapi: Not installed
2025-01-22 20:14:33,478:INFO:             uvicorn: Not installed
2025-01-22 20:14:33,478:INFO:              m2cgen: Not installed
2025-01-22 20:14:33,478:INFO:           evidently: Not installed
2025-01-22 20:14:33,478:INFO:               fugue: Not installed
2025-01-22 20:14:33,478:INFO:           streamlit: Not installed
2025-01-22 20:14:33,478:INFO:             prophet: Not installed
2025-01-22 20:14:33,478:INFO:None
2025-01-22 20:14:33,478:INFO:Set up data.
2025-01-22 20:14:33,485:INFO:Set up folding strategy.
2025-01-22 20:14:33,485:INFO:Set up train/test split.
2025-01-22 20:14:33,501:INFO:Set up index.
2025-01-22 20:14:33,501:INFO:Assigning column types.
2025-01-22 20:14:33,504:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-01-22 20:14:33,504:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,507:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,510:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,551:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,582:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:33,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:33,584:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,587:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,590:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,662:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:33,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:33,664:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-01-22 20:14:33,667:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,670:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,711:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,742:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,742:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:33,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:33,747:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,750:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,914:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:33,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:33,916:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-01-22 20:14:33,922:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-22 20:14:33,993:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:33,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,072:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,074:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-01-22 20:14:34,120:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,152:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,201:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,232:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,234:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-01-22 20:14:34,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,311:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-01-22 20:14:34,391:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,393:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-01-22 20:14:34,470:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,551:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,555:INFO:Preparing preprocessing pipeline...
2025-01-22 20:14:34,555:INFO:Set up simple imputation.
2025-01-22 20:14:34,557:INFO:Set up encoding of categorical features.
2025-01-22 20:14:34,558:INFO:Set up column name cleaning.
2025-01-22 20:14:34,616:INFO:Finished creating preprocessing pipeline.
2025-01-22 20:14:34,622:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-01-22 20:14:34,622:INFO:Creating final display dataframe.
2025-01-22 20:14:34,767:INFO:Setup _display_container:                     Description               Value
0                    Session id                 123
1                        Target  Hispanic or Latino
2                   Target type          Regression
3           Original data shape          (2900, 12)
4        Transformed data shape          (2900, 12)
5   Transformed train set shape          (2029, 12)
6    Transformed test set shape           (871, 12)
7              Numeric features                   9
8          Categorical features                   2
9                    Preprocess                True
10              Imputation type              simple
11           Numeric imputation                mean
12       Categorical imputation                mode
13     Maximum one-hot encoding                  25
14              Encoding method                None
15               Fold Generator               KFold
16                  Fold Number                  10
17                     CPU Jobs                  -1
18                      Use GPU               False
19               Log Experiment               False
20              Experiment Name    reg-default-name
21                          USI                524b
2025-01-22 20:14:34,850:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,930:INFO:Soft dependency imported: xgboost: 2.1.3
2025-01-22 20:14:34,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-01-22 20:14:34,932:INFO:setup() successfully completed in 1.56s...............
2025-01-22 20:14:34,935:INFO:Initializing compare_models()
2025-01-22 20:14:34,936:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-01-22 20:14:34,936:INFO:Checking exceptions
2025-01-22 20:14:34,938:INFO:Preparing display monitor
2025-01-22 20:14:34,984:INFO:Initializing Linear Regression
2025-01-22 20:14:34,985:INFO:Total runtime is 8.479754130045574e-06 minutes
2025-01-22 20:14:34,987:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:34,988:INFO:Initializing create_model()
2025-01-22 20:14:34,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:34,988:INFO:Checking exceptions
2025-01-22 20:14:34,988:INFO:Importing libraries
2025-01-22 20:14:34,988:INFO:Copying training dataset
2025-01-22 20:14:34,994:INFO:Defining folds
2025-01-22 20:14:34,994:INFO:Declaring metric variables
2025-01-22 20:14:34,996:INFO:Importing untrained model
2025-01-22 20:14:34,999:INFO:Linear Regression Imported successfully
2025-01-22 20:14:35,004:INFO:Starting cross validation
2025-01-22 20:14:35,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:39,213:INFO:Calculating mean and std
2025-01-22 20:14:39,215:INFO:Creating metrics dataframe
2025-01-22 20:14:39,218:INFO:Uploading results into container
2025-01-22 20:14:39,219:INFO:Uploading model into container now
2025-01-22 20:14:39,219:INFO:_master_model_container: 1
2025-01-22 20:14:39,219:INFO:_display_container: 2
2025-01-22 20:14:39,220:INFO:LinearRegression(n_jobs=-1)
2025-01-22 20:14:39,220:INFO:create_model() successfully completed......................................
2025-01-22 20:14:39,361:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:39,361:INFO:Creating metrics dataframe
2025-01-22 20:14:39,365:INFO:Initializing Lasso Regression
2025-01-22 20:14:39,365:INFO:Total runtime is 0.07301908334096273 minutes
2025-01-22 20:14:39,367:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:39,368:INFO:Initializing create_model()
2025-01-22 20:14:39,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:39,368:INFO:Checking exceptions
2025-01-22 20:14:39,368:INFO:Importing libraries
2025-01-22 20:14:39,368:INFO:Copying training dataset
2025-01-22 20:14:39,372:INFO:Defining folds
2025-01-22 20:14:39,372:INFO:Declaring metric variables
2025-01-22 20:14:39,374:INFO:Importing untrained model
2025-01-22 20:14:39,376:INFO:Lasso Regression Imported successfully
2025-01-22 20:14:39,381:INFO:Starting cross validation
2025-01-22 20:14:39,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:39,448:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.997e+11, tolerance: 3.728e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,457:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.995e+11, tolerance: 3.641e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,463:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.509e+11, tolerance: 3.570e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,468:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.764e+11, tolerance: 3.510e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,480:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.669e+11, tolerance: 1.447e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,502:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.009e+11, tolerance: 3.548e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,511:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.576e+11, tolerance: 3.489e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,522:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.155e+11, tolerance: 3.606e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,526:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.028e+11, tolerance: 3.617e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,532:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.862e+11, tolerance: 3.618e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,546:INFO:Calculating mean and std
2025-01-22 20:14:39,547:INFO:Creating metrics dataframe
2025-01-22 20:14:39,548:INFO:Uploading results into container
2025-01-22 20:14:39,549:INFO:Uploading model into container now
2025-01-22 20:14:39,549:INFO:_master_model_container: 2
2025-01-22 20:14:39,549:INFO:_display_container: 2
2025-01-22 20:14:39,549:INFO:Lasso(random_state=123)
2025-01-22 20:14:39,549:INFO:create_model() successfully completed......................................
2025-01-22 20:14:39,627:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:39,627:INFO:Creating metrics dataframe
2025-01-22 20:14:39,632:INFO:Initializing Ridge Regression
2025-01-22 20:14:39,632:INFO:Total runtime is 0.07746021350224813 minutes
2025-01-22 20:14:39,634:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:39,634:INFO:Initializing create_model()
2025-01-22 20:14:39,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:39,634:INFO:Checking exceptions
2025-01-22 20:14:39,634:INFO:Importing libraries
2025-01-22 20:14:39,634:INFO:Copying training dataset
2025-01-22 20:14:39,638:INFO:Defining folds
2025-01-22 20:14:39,638:INFO:Declaring metric variables
2025-01-22 20:14:39,640:INFO:Importing untrained model
2025-01-22 20:14:39,642:INFO:Ridge Regression Imported successfully
2025-01-22 20:14:39,648:INFO:Starting cross validation
2025-01-22 20:14:39,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:39,776:INFO:Calculating mean and std
2025-01-22 20:14:39,777:INFO:Creating metrics dataframe
2025-01-22 20:14:39,779:INFO:Uploading results into container
2025-01-22 20:14:39,779:INFO:Uploading model into container now
2025-01-22 20:14:39,779:INFO:_master_model_container: 3
2025-01-22 20:14:39,779:INFO:_display_container: 2
2025-01-22 20:14:39,779:INFO:Ridge(random_state=123)
2025-01-22 20:14:39,779:INFO:create_model() successfully completed......................................
2025-01-22 20:14:39,856:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:39,856:INFO:Creating metrics dataframe
2025-01-22 20:14:39,861:INFO:Initializing Elastic Net
2025-01-22 20:14:39,861:INFO:Total runtime is 0.08127991755803426 minutes
2025-01-22 20:14:39,863:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:39,863:INFO:Initializing create_model()
2025-01-22 20:14:39,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:39,863:INFO:Checking exceptions
2025-01-22 20:14:39,863:INFO:Importing libraries
2025-01-22 20:14:39,863:INFO:Copying training dataset
2025-01-22 20:14:39,867:INFO:Defining folds
2025-01-22 20:14:39,867:INFO:Declaring metric variables
2025-01-22 20:14:39,869:INFO:Importing untrained model
2025-01-22 20:14:39,871:INFO:Elastic Net Imported successfully
2025-01-22 20:14:39,876:INFO:Starting cross validation
2025-01-22 20:14:39,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:39,938:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.997e+11, tolerance: 3.728e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,945:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.995e+11, tolerance: 3.641e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,949:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.509e+11, tolerance: 3.570e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,953:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.764e+11, tolerance: 3.510e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,962:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.669e+11, tolerance: 1.447e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,968:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.009e+11, tolerance: 3.548e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,988:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.576e+11, tolerance: 3.489e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:39,995:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.155e+11, tolerance: 3.606e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:40,015:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.028e+11, tolerance: 3.617e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:40,032:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.862e+11, tolerance: 3.618e+09
  model = cd_fast.enet_coordinate_descent(

2025-01-22 20:14:40,063:INFO:Calculating mean and std
2025-01-22 20:14:40,064:INFO:Creating metrics dataframe
2025-01-22 20:14:40,066:INFO:Uploading results into container
2025-01-22 20:14:40,066:INFO:Uploading model into container now
2025-01-22 20:14:40,067:INFO:_master_model_container: 4
2025-01-22 20:14:40,067:INFO:_display_container: 2
2025-01-22 20:14:40,067:INFO:ElasticNet(random_state=123)
2025-01-22 20:14:40,067:INFO:create_model() successfully completed......................................
2025-01-22 20:14:40,164:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:40,164:INFO:Creating metrics dataframe
2025-01-22 20:14:40,170:INFO:Initializing Least Angle Regression
2025-01-22 20:14:40,170:INFO:Total runtime is 0.0864371657371521 minutes
2025-01-22 20:14:40,173:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:40,173:INFO:Initializing create_model()
2025-01-22 20:14:40,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:40,173:INFO:Checking exceptions
2025-01-22 20:14:40,173:INFO:Importing libraries
2025-01-22 20:14:40,173:INFO:Copying training dataset
2025-01-22 20:14:40,177:INFO:Defining folds
2025-01-22 20:14:40,178:INFO:Declaring metric variables
2025-01-22 20:14:40,180:INFO:Importing untrained model
2025-01-22 20:14:40,183:INFO:Least Angle Regression Imported successfully
2025-01-22 20:14:40,188:INFO:Starting cross validation
2025-01-22 20:14:40,189:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:40,239:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.261e+09, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,239:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.854e+08, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,240:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.085e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,240:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.478e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,240:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.317e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,248:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.749e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,251:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.536e-06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.541e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,265:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.304e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.600e+07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,266:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.223e+06, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,274:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.374e-06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,286:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.158e+04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,286:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.973e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,297:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.264e+09, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,297:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.880e+08, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,298:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.914e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,298:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.046e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,298:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.043e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,342:INFO:Calculating mean and std
2025-01-22 20:14:40,343:INFO:Creating metrics dataframe
2025-01-22 20:14:40,345:INFO:Uploading results into container
2025-01-22 20:14:40,345:INFO:Uploading model into container now
2025-01-22 20:14:40,346:INFO:_master_model_container: 5
2025-01-22 20:14:40,346:INFO:_display_container: 2
2025-01-22 20:14:40,346:INFO:Lars(random_state=123)
2025-01-22 20:14:40,346:INFO:create_model() successfully completed......................................
2025-01-22 20:14:40,427:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:40,427:INFO:Creating metrics dataframe
2025-01-22 20:14:40,433:INFO:Initializing Lasso Least Angle Regression
2025-01-22 20:14:40,433:INFO:Total runtime is 0.09082149664560954 minutes
2025-01-22 20:14:40,436:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:40,436:INFO:Initializing create_model()
2025-01-22 20:14:40,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:40,436:INFO:Checking exceptions
2025-01-22 20:14:40,436:INFO:Importing libraries
2025-01-22 20:14:40,437:INFO:Copying training dataset
2025-01-22 20:14:40,440:INFO:Defining folds
2025-01-22 20:14:40,440:INFO:Declaring metric variables
2025-01-22 20:14:40,442:INFO:Importing untrained model
2025-01-22 20:14:40,445:INFO:Lasso Least Angle Regression Imported successfully
2025-01-22 20:14:40,451:INFO:Starting cross validation
2025-01-22 20:14:40,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:40,499:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.261e+09, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,500:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.854e+08, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,500:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 5 iterations, alpha=4.752e+08, previous alpha=2.744e+08, with an active set of 4 regressors.
  warnings.warn(

2025-01-22 20:14:40,533:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 2 iterations, alpha=7.161e+08, previous alpha=5.589e+08, with an active set of 3 regressors.
  warnings.warn(

2025-01-22 20:14:40,559:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.264e+09, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,559:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.880e+08, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-01-22 20:14:40,559:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 5 iterations, alpha=4.171e+08, previous alpha=2.348e+08, with an active set of 4 regressors.
  warnings.warn(

2025-01-22 20:14:40,574:INFO:Calculating mean and std
2025-01-22 20:14:40,575:INFO:Creating metrics dataframe
2025-01-22 20:14:40,577:INFO:Uploading results into container
2025-01-22 20:14:40,577:INFO:Uploading model into container now
2025-01-22 20:14:40,578:INFO:_master_model_container: 6
2025-01-22 20:14:40,578:INFO:_display_container: 2
2025-01-22 20:14:40,578:INFO:LassoLars(random_state=123)
2025-01-22 20:14:40,578:INFO:create_model() successfully completed......................................
2025-01-22 20:14:40,658:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:40,658:INFO:Creating metrics dataframe
2025-01-22 20:14:40,663:INFO:Initializing Orthogonal Matching Pursuit
2025-01-22 20:14:40,663:INFO:Total runtime is 0.094654381275177 minutes
2025-01-22 20:14:40,665:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:40,666:INFO:Initializing create_model()
2025-01-22 20:14:40,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:40,666:INFO:Checking exceptions
2025-01-22 20:14:40,666:INFO:Importing libraries
2025-01-22 20:14:40,666:INFO:Copying training dataset
2025-01-22 20:14:40,669:INFO:Defining folds
2025-01-22 20:14:40,669:INFO:Declaring metric variables
2025-01-22 20:14:40,671:INFO:Importing untrained model
2025-01-22 20:14:40,673:INFO:Orthogonal Matching Pursuit Imported successfully
2025-01-22 20:14:40,677:INFO:Starting cross validation
2025-01-22 20:14:40,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:40,808:INFO:Calculating mean and std
2025-01-22 20:14:40,809:INFO:Creating metrics dataframe
2025-01-22 20:14:40,810:INFO:Uploading results into container
2025-01-22 20:14:40,811:INFO:Uploading model into container now
2025-01-22 20:14:40,811:INFO:_master_model_container: 7
2025-01-22 20:14:40,811:INFO:_display_container: 2
2025-01-22 20:14:40,812:INFO:OrthogonalMatchingPursuit()
2025-01-22 20:14:40,812:INFO:create_model() successfully completed......................................
2025-01-22 20:14:40,891:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:40,891:INFO:Creating metrics dataframe
2025-01-22 20:14:40,896:INFO:Initializing Bayesian Ridge
2025-01-22 20:14:40,897:INFO:Total runtime is 0.09854079882303873 minutes
2025-01-22 20:14:40,899:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:40,899:INFO:Initializing create_model()
2025-01-22 20:14:40,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:40,899:INFO:Checking exceptions
2025-01-22 20:14:40,899:INFO:Importing libraries
2025-01-22 20:14:40,899:INFO:Copying training dataset
2025-01-22 20:14:40,902:INFO:Defining folds
2025-01-22 20:14:40,903:INFO:Declaring metric variables
2025-01-22 20:14:40,904:INFO:Importing untrained model
2025-01-22 20:14:40,906:INFO:Bayesian Ridge Imported successfully
2025-01-22 20:14:40,910:INFO:Starting cross validation
2025-01-22 20:14:40,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:41,038:INFO:Calculating mean and std
2025-01-22 20:14:41,039:INFO:Creating metrics dataframe
2025-01-22 20:14:41,040:INFO:Uploading results into container
2025-01-22 20:14:41,040:INFO:Uploading model into container now
2025-01-22 20:14:41,041:INFO:_master_model_container: 8
2025-01-22 20:14:41,041:INFO:_display_container: 2
2025-01-22 20:14:41,041:INFO:BayesianRidge()
2025-01-22 20:14:41,041:INFO:create_model() successfully completed......................................
2025-01-22 20:14:41,120:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:41,120:INFO:Creating metrics dataframe
2025-01-22 20:14:41,127:INFO:Initializing Passive Aggressive Regressor
2025-01-22 20:14:41,127:INFO:Total runtime is 0.1023758848508199 minutes
2025-01-22 20:14:41,129:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:41,129:INFO:Initializing create_model()
2025-01-22 20:14:41,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:41,129:INFO:Checking exceptions
2025-01-22 20:14:41,129:INFO:Importing libraries
2025-01-22 20:14:41,129:INFO:Copying training dataset
2025-01-22 20:14:41,133:INFO:Defining folds
2025-01-22 20:14:41,133:INFO:Declaring metric variables
2025-01-22 20:14:41,136:INFO:Importing untrained model
2025-01-22 20:14:41,138:INFO:Passive Aggressive Regressor Imported successfully
2025-01-22 20:14:41,145:INFO:Starting cross validation
2025-01-22 20:14:41,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:41,284:INFO:Calculating mean and std
2025-01-22 20:14:41,284:INFO:Creating metrics dataframe
2025-01-22 20:14:41,286:INFO:Uploading results into container
2025-01-22 20:14:41,286:INFO:Uploading model into container now
2025-01-22 20:14:41,287:INFO:_master_model_container: 9
2025-01-22 20:14:41,287:INFO:_display_container: 2
2025-01-22 20:14:41,287:INFO:PassiveAggressiveRegressor(random_state=123)
2025-01-22 20:14:41,287:INFO:create_model() successfully completed......................................
2025-01-22 20:14:41,367:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:41,367:INFO:Creating metrics dataframe
2025-01-22 20:14:41,374:INFO:Initializing Huber Regressor
2025-01-22 20:14:41,374:INFO:Total runtime is 0.1064990480740865 minutes
2025-01-22 20:14:41,376:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:41,377:INFO:Initializing create_model()
2025-01-22 20:14:41,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:41,377:INFO:Checking exceptions
2025-01-22 20:14:41,377:INFO:Importing libraries
2025-01-22 20:14:41,377:INFO:Copying training dataset
2025-01-22 20:14:41,381:INFO:Defining folds
2025-01-22 20:14:41,381:INFO:Declaring metric variables
2025-01-22 20:14:41,384:INFO:Importing untrained model
2025-01-22 20:14:41,386:INFO:Huber Regressor Imported successfully
2025-01-22 20:14:41,392:INFO:Starting cross validation
2025-01-22 20:14:41,393:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:41,680:INFO:Calculating mean and std
2025-01-22 20:14:41,681:INFO:Creating metrics dataframe
2025-01-22 20:14:41,683:INFO:Uploading results into container
2025-01-22 20:14:41,684:INFO:Uploading model into container now
2025-01-22 20:14:41,684:INFO:_master_model_container: 10
2025-01-22 20:14:41,685:INFO:_display_container: 2
2025-01-22 20:14:41,685:INFO:HuberRegressor()
2025-01-22 20:14:41,685:INFO:create_model() successfully completed......................................
2025-01-22 20:14:41,768:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:41,768:INFO:Creating metrics dataframe
2025-01-22 20:14:41,774:INFO:Initializing K Neighbors Regressor
2025-01-22 20:14:41,775:INFO:Total runtime is 0.11317584911982217 minutes
2025-01-22 20:14:41,777:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:41,777:INFO:Initializing create_model()
2025-01-22 20:14:41,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:41,777:INFO:Checking exceptions
2025-01-22 20:14:41,777:INFO:Importing libraries
2025-01-22 20:14:41,777:INFO:Copying training dataset
2025-01-22 20:14:41,782:INFO:Defining folds
2025-01-22 20:14:41,782:INFO:Declaring metric variables
2025-01-22 20:14:41,784:INFO:Importing untrained model
2025-01-22 20:14:41,786:INFO:K Neighbors Regressor Imported successfully
2025-01-22 20:14:41,791:INFO:Starting cross validation
2025-01-22 20:14:41,793:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:41,944:INFO:Calculating mean and std
2025-01-22 20:14:41,945:INFO:Creating metrics dataframe
2025-01-22 20:14:41,946:INFO:Uploading results into container
2025-01-22 20:14:41,947:INFO:Uploading model into container now
2025-01-22 20:14:41,947:INFO:_master_model_container: 11
2025-01-22 20:14:41,947:INFO:_display_container: 2
2025-01-22 20:14:41,947:INFO:KNeighborsRegressor(n_jobs=-1)
2025-01-22 20:14:41,947:INFO:create_model() successfully completed......................................
2025-01-22 20:14:42,021:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:42,022:INFO:Creating metrics dataframe
2025-01-22 20:14:42,028:INFO:Initializing Decision Tree Regressor
2025-01-22 20:14:42,028:INFO:Total runtime is 0.11740139722824096 minutes
2025-01-22 20:14:42,030:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:42,030:INFO:Initializing create_model()
2025-01-22 20:14:42,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:42,031:INFO:Checking exceptions
2025-01-22 20:14:42,031:INFO:Importing libraries
2025-01-22 20:14:42,031:INFO:Copying training dataset
2025-01-22 20:14:42,034:INFO:Defining folds
2025-01-22 20:14:42,034:INFO:Declaring metric variables
2025-01-22 20:14:42,036:INFO:Importing untrained model
2025-01-22 20:14:42,038:INFO:Decision Tree Regressor Imported successfully
2025-01-22 20:14:42,043:INFO:Starting cross validation
2025-01-22 20:14:42,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:42,229:INFO:Calculating mean and std
2025-01-22 20:14:42,230:INFO:Creating metrics dataframe
2025-01-22 20:14:42,232:INFO:Uploading results into container
2025-01-22 20:14:42,232:INFO:Uploading model into container now
2025-01-22 20:14:42,233:INFO:_master_model_container: 12
2025-01-22 20:14:42,233:INFO:_display_container: 2
2025-01-22 20:14:42,233:INFO:DecisionTreeRegressor(random_state=123)
2025-01-22 20:14:42,233:INFO:create_model() successfully completed......................................
2025-01-22 20:14:42,310:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:42,310:INFO:Creating metrics dataframe
2025-01-22 20:14:42,316:INFO:Initializing Random Forest Regressor
2025-01-22 20:14:42,316:INFO:Total runtime is 0.12220656474431354 minutes
2025-01-22 20:14:42,318:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:42,319:INFO:Initializing create_model()
2025-01-22 20:14:42,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:42,319:INFO:Checking exceptions
2025-01-22 20:14:42,319:INFO:Importing libraries
2025-01-22 20:14:42,319:INFO:Copying training dataset
2025-01-22 20:14:42,323:INFO:Defining folds
2025-01-22 20:14:42,323:INFO:Declaring metric variables
2025-01-22 20:14:42,324:INFO:Importing untrained model
2025-01-22 20:14:42,326:INFO:Random Forest Regressor Imported successfully
2025-01-22 20:14:42,330:INFO:Starting cross validation
2025-01-22 20:14:42,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:46,491:INFO:Calculating mean and std
2025-01-22 20:14:46,492:INFO:Creating metrics dataframe
2025-01-22 20:14:46,494:INFO:Uploading results into container
2025-01-22 20:14:46,494:INFO:Uploading model into container now
2025-01-22 20:14:46,494:INFO:_master_model_container: 13
2025-01-22 20:14:46,494:INFO:_display_container: 2
2025-01-22 20:14:46,495:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-01-22 20:14:46,495:INFO:create_model() successfully completed......................................
2025-01-22 20:14:46,572:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:46,572:INFO:Creating metrics dataframe
2025-01-22 20:14:46,579:INFO:Initializing Extra Trees Regressor
2025-01-22 20:14:46,579:INFO:Total runtime is 0.19325218200683592 minutes
2025-01-22 20:14:46,581:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:46,582:INFO:Initializing create_model()
2025-01-22 20:14:46,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:46,582:INFO:Checking exceptions
2025-01-22 20:14:46,582:INFO:Importing libraries
2025-01-22 20:14:46,582:INFO:Copying training dataset
2025-01-22 20:14:46,586:INFO:Defining folds
2025-01-22 20:14:46,586:INFO:Declaring metric variables
2025-01-22 20:14:46,588:INFO:Importing untrained model
2025-01-22 20:14:46,590:INFO:Extra Trees Regressor Imported successfully
2025-01-22 20:14:46,594:INFO:Starting cross validation
2025-01-22 20:14:46,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:47,926:INFO:Calculating mean and std
2025-01-22 20:14:47,927:INFO:Creating metrics dataframe
2025-01-22 20:14:47,929:INFO:Uploading results into container
2025-01-22 20:14:47,929:INFO:Uploading model into container now
2025-01-22 20:14:47,929:INFO:_master_model_container: 14
2025-01-22 20:14:47,930:INFO:_display_container: 2
2025-01-22 20:14:47,930:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-01-22 20:14:47,930:INFO:create_model() successfully completed......................................
2025-01-22 20:14:48,008:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:48,009:INFO:Creating metrics dataframe
2025-01-22 20:14:48,015:INFO:Initializing AdaBoost Regressor
2025-01-22 20:14:48,015:INFO:Total runtime is 0.2171898325284322 minutes
2025-01-22 20:14:48,017:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:48,018:INFO:Initializing create_model()
2025-01-22 20:14:48,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:48,018:INFO:Checking exceptions
2025-01-22 20:14:48,018:INFO:Importing libraries
2025-01-22 20:14:48,018:INFO:Copying training dataset
2025-01-22 20:14:48,021:INFO:Defining folds
2025-01-22 20:14:48,021:INFO:Declaring metric variables
2025-01-22 20:14:48,023:INFO:Importing untrained model
2025-01-22 20:14:48,025:INFO:AdaBoost Regressor Imported successfully
2025-01-22 20:14:48,030:INFO:Starting cross validation
2025-01-22 20:14:48,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:48,702:INFO:Calculating mean and std
2025-01-22 20:14:48,703:INFO:Creating metrics dataframe
2025-01-22 20:14:48,705:INFO:Uploading results into container
2025-01-22 20:14:48,705:INFO:Uploading model into container now
2025-01-22 20:14:48,705:INFO:_master_model_container: 15
2025-01-22 20:14:48,705:INFO:_display_container: 2
2025-01-22 20:14:48,705:INFO:AdaBoostRegressor(random_state=123)
2025-01-22 20:14:48,705:INFO:create_model() successfully completed......................................
2025-01-22 20:14:48,779:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:48,780:INFO:Creating metrics dataframe
2025-01-22 20:14:48,787:INFO:Initializing Gradient Boosting Regressor
2025-01-22 20:14:48,787:INFO:Total runtime is 0.23004633188247678 minutes
2025-01-22 20:14:48,789:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:48,789:INFO:Initializing create_model()
2025-01-22 20:14:48,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:48,789:INFO:Checking exceptions
2025-01-22 20:14:48,789:INFO:Importing libraries
2025-01-22 20:14:48,789:INFO:Copying training dataset
2025-01-22 20:14:48,793:INFO:Defining folds
2025-01-22 20:14:48,793:INFO:Declaring metric variables
2025-01-22 20:14:48,795:INFO:Importing untrained model
2025-01-22 20:14:48,811:INFO:Gradient Boosting Regressor Imported successfully
2025-01-22 20:14:48,850:INFO:Starting cross validation
2025-01-22 20:14:48,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:50,592:INFO:Calculating mean and std
2025-01-22 20:14:50,592:INFO:Creating metrics dataframe
2025-01-22 20:14:50,594:INFO:Uploading results into container
2025-01-22 20:14:50,594:INFO:Uploading model into container now
2025-01-22 20:14:50,595:INFO:_master_model_container: 16
2025-01-22 20:14:50,595:INFO:_display_container: 2
2025-01-22 20:14:50,595:INFO:GradientBoostingRegressor(random_state=123)
2025-01-22 20:14:50,595:INFO:create_model() successfully completed......................................
2025-01-22 20:14:50,669:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:50,669:INFO:Creating metrics dataframe
2025-01-22 20:14:50,677:INFO:Initializing Extreme Gradient Boosting
2025-01-22 20:14:50,677:INFO:Total runtime is 0.26154403289159134 minutes
2025-01-22 20:14:50,679:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:50,679:INFO:Initializing create_model()
2025-01-22 20:14:50,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:50,679:INFO:Checking exceptions
2025-01-22 20:14:50,679:INFO:Importing libraries
2025-01-22 20:14:50,679:INFO:Copying training dataset
2025-01-22 20:14:50,682:INFO:Defining folds
2025-01-22 20:14:50,682:INFO:Declaring metric variables
2025-01-22 20:14:50,684:INFO:Importing untrained model
2025-01-22 20:14:50,687:INFO:Extreme Gradient Boosting Imported successfully
2025-01-22 20:14:50,692:INFO:Starting cross validation
2025-01-22 20:14:50,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:51,152:INFO:Calculating mean and std
2025-01-22 20:14:51,153:INFO:Creating metrics dataframe
2025-01-22 20:14:51,154:INFO:Uploading results into container
2025-01-22 20:14:51,155:INFO:Uploading model into container now
2025-01-22 20:14:51,155:INFO:_master_model_container: 17
2025-01-22 20:14:51,155:INFO:_display_container: 2
2025-01-22 20:14:51,156:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2025-01-22 20:14:51,156:INFO:create_model() successfully completed......................................
2025-01-22 20:14:51,231:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:51,231:INFO:Creating metrics dataframe
2025-01-22 20:14:51,239:INFO:Initializing Light Gradient Boosting Machine
2025-01-22 20:14:51,239:INFO:Total runtime is 0.2709159652392069 minutes
2025-01-22 20:14:51,241:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:51,241:INFO:Initializing create_model()
2025-01-22 20:14:51,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:51,242:INFO:Checking exceptions
2025-01-22 20:14:51,242:INFO:Importing libraries
2025-01-22 20:14:51,242:INFO:Copying training dataset
2025-01-22 20:14:51,245:INFO:Defining folds
2025-01-22 20:14:51,245:INFO:Declaring metric variables
2025-01-22 20:14:51,247:INFO:Importing untrained model
2025-01-22 20:14:51,249:INFO:Light Gradient Boosting Machine Imported successfully
2025-01-22 20:14:51,253:INFO:Starting cross validation
2025-01-22 20:14:51,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:54,349:INFO:Calculating mean and std
2025-01-22 20:14:54,350:INFO:Creating metrics dataframe
2025-01-22 20:14:54,351:INFO:Uploading results into container
2025-01-22 20:14:54,351:INFO:Uploading model into container now
2025-01-22 20:14:54,352:INFO:_master_model_container: 18
2025-01-22 20:14:54,352:INFO:_display_container: 2
2025-01-22 20:14:54,352:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-01-22 20:14:54,352:INFO:create_model() successfully completed......................................
2025-01-22 20:14:54,429:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:54,429:INFO:Creating metrics dataframe
2025-01-22 20:14:54,437:INFO:Initializing Dummy Regressor
2025-01-22 20:14:54,437:INFO:Total runtime is 0.32420983314514157 minutes
2025-01-22 20:14:54,439:INFO:SubProcess create_model() called ==================================
2025-01-22 20:14:54,439:INFO:Initializing create_model()
2025-01-22 20:14:54,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x160ffa6e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:54,439:INFO:Checking exceptions
2025-01-22 20:14:54,439:INFO:Importing libraries
2025-01-22 20:14:54,439:INFO:Copying training dataset
2025-01-22 20:14:54,443:INFO:Defining folds
2025-01-22 20:14:54,443:INFO:Declaring metric variables
2025-01-22 20:14:54,444:INFO:Importing untrained model
2025-01-22 20:14:54,446:INFO:Dummy Regressor Imported successfully
2025-01-22 20:14:54,450:INFO:Starting cross validation
2025-01-22 20:14:54,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:54,564:INFO:Calculating mean and std
2025-01-22 20:14:54,565:INFO:Creating metrics dataframe
2025-01-22 20:14:54,566:INFO:Uploading results into container
2025-01-22 20:14:54,567:INFO:Uploading model into container now
2025-01-22 20:14:54,567:INFO:_master_model_container: 19
2025-01-22 20:14:54,568:INFO:_display_container: 2
2025-01-22 20:14:54,568:INFO:DummyRegressor()
2025-01-22 20:14:54,568:INFO:create_model() successfully completed......................................
2025-01-22 20:14:54,642:INFO:SubProcess create_model() end ==================================
2025-01-22 20:14:54,642:INFO:Creating metrics dataframe
2025-01-22 20:14:54,652:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-01-22 20:14:54,657:INFO:Initializing create_model()
2025-01-22 20:14:54,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:54,657:INFO:Checking exceptions
2025-01-22 20:14:54,658:INFO:Importing libraries
2025-01-22 20:14:54,658:INFO:Copying training dataset
2025-01-22 20:14:54,661:INFO:Defining folds
2025-01-22 20:14:54,661:INFO:Declaring metric variables
2025-01-22 20:14:54,662:INFO:Importing untrained model
2025-01-22 20:14:54,662:INFO:Declaring custom model
2025-01-22 20:14:54,662:INFO:Huber Regressor Imported successfully
2025-01-22 20:14:54,663:INFO:Cross validation set to False
2025-01-22 20:14:54,663:INFO:Fitting Model
2025-01-22 20:14:54,720:INFO:HuberRegressor()
2025-01-22 20:14:54,720:INFO:create_model() successfully completed......................................
2025-01-22 20:14:54,813:INFO:_master_model_container: 19
2025-01-22 20:14:54,813:INFO:_display_container: 2
2025-01-22 20:14:54,814:INFO:HuberRegressor()
2025-01-22 20:14:54,814:INFO:compare_models() successfully completed......................................
2025-01-22 20:14:54,820:INFO:Initializing create_model()
2025-01-22 20:14:54,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:14:54,820:INFO:Checking exceptions
2025-01-22 20:14:54,833:INFO:Importing libraries
2025-01-22 20:14:54,833:INFO:Copying training dataset
2025-01-22 20:14:54,841:INFO:Defining folds
2025-01-22 20:14:54,841:INFO:Declaring metric variables
2025-01-22 20:14:54,844:INFO:Importing untrained model
2025-01-22 20:14:54,846:INFO:Huber Regressor Imported successfully
2025-01-22 20:14:54,850:INFO:Starting cross validation
2025-01-22 20:14:54,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:14:55,065:INFO:Calculating mean and std
2025-01-22 20:14:55,065:INFO:Creating metrics dataframe
2025-01-22 20:14:55,068:INFO:Finalizing model
2025-01-22 20:14:55,125:INFO:Uploading results into container
2025-01-22 20:14:55,126:INFO:Uploading model into container now
2025-01-22 20:14:55,132:INFO:_master_model_container: 20
2025-01-22 20:14:55,132:INFO:_display_container: 3
2025-01-22 20:14:55,132:INFO:HuberRegressor()
2025-01-22 20:14:55,132:INFO:create_model() successfully completed......................................
2025-01-22 20:15:22,277:INFO:Initializing tune_model()
2025-01-22 20:15:22,278:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>)
2025-01-22 20:15:22,278:INFO:Checking exceptions
2025-01-22 20:15:22,310:INFO:Copying training dataset
2025-01-22 20:15:22,316:INFO:Checking base model
2025-01-22 20:15:22,316:INFO:Base model : Huber Regressor
2025-01-22 20:15:22,322:INFO:Declaring metric variables
2025-01-22 20:15:22,325:INFO:Defining Hyperparameters
2025-01-22 20:15:22,459:INFO:Tuning with n_jobs=-1
2025-01-22 20:15:22,460:INFO:Initializing RandomizedSearchCV
2025-01-22 20:15:22,929:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-22 20:15:23,252:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-22 20:15:23,324:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-22 20:15:23,589:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-22 20:15:23,918:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-22 20:15:23,928:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-22 20:15:24,134:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-22 20:15:24,167:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-01-22 20:15:24,411:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 276, in fit
    fitted_estimator = self._memory_fit(
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/linear_model/_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-01-22 20:15:24,414:WARNING:/opt/miniconda3/envs/P1/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.65398795 0.65191034 0.65364146        nan 0.65365374 0.65365816
        nan 0.65365341 0.65371475 0.65222916]
  warnings.warn(

2025-01-22 20:15:24,414:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.4, 'actual_estimator__alpha': 0.5}
2025-01-22 20:15:24,415:INFO:Hyperparameter search completed
2025-01-22 20:15:24,415:INFO:SubProcess create_model() called ==================================
2025-01-22 20:15:24,416:INFO:Initializing create_model()
2025-01-22 20:15:24,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103f4e770>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'epsilon': 1.4, 'alpha': 0.5})
2025-01-22 20:15:24,416:INFO:Checking exceptions
2025-01-22 20:15:24,416:INFO:Importing libraries
2025-01-22 20:15:24,416:INFO:Copying training dataset
2025-01-22 20:15:24,421:INFO:Defining folds
2025-01-22 20:15:24,421:INFO:Declaring metric variables
2025-01-22 20:15:24,424:INFO:Importing untrained model
2025-01-22 20:15:24,424:INFO:Declaring custom model
2025-01-22 20:15:24,427:INFO:Huber Regressor Imported successfully
2025-01-22 20:15:24,432:INFO:Starting cross validation
2025-01-22 20:15:24,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:15:24,680:INFO:Calculating mean and std
2025-01-22 20:15:24,681:INFO:Creating metrics dataframe
2025-01-22 20:15:24,685:INFO:Finalizing model
2025-01-22 20:15:24,735:INFO:Uploading results into container
2025-01-22 20:15:24,735:INFO:Uploading model into container now
2025-01-22 20:15:24,736:INFO:_master_model_container: 21
2025-01-22 20:15:24,736:INFO:_display_container: 4
2025-01-22 20:15:24,736:INFO:HuberRegressor(alpha=0.5, epsilon=1.4)
2025-01-22 20:15:24,736:INFO:create_model() successfully completed......................................
2025-01-22 20:15:24,814:INFO:SubProcess create_model() end ==================================
2025-01-22 20:15:24,814:INFO:choose_better activated
2025-01-22 20:15:24,816:INFO:SubProcess create_model() called ==================================
2025-01-22 20:15:24,817:INFO:Initializing create_model()
2025-01-22 20:15:24,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:15:24,817:INFO:Checking exceptions
2025-01-22 20:15:24,818:INFO:Importing libraries
2025-01-22 20:15:24,818:INFO:Copying training dataset
2025-01-22 20:15:24,821:INFO:Defining folds
2025-01-22 20:15:24,821:INFO:Declaring metric variables
2025-01-22 20:15:24,821:INFO:Importing untrained model
2025-01-22 20:15:24,821:INFO:Declaring custom model
2025-01-22 20:15:24,822:INFO:Huber Regressor Imported successfully
2025-01-22 20:15:24,822:INFO:Starting cross validation
2025-01-22 20:15:24,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-01-22 20:15:24,992:INFO:Calculating mean and std
2025-01-22 20:15:24,992:INFO:Creating metrics dataframe
2025-01-22 20:15:24,993:INFO:Finalizing model
2025-01-22 20:15:25,052:INFO:Uploading results into container
2025-01-22 20:15:25,052:INFO:Uploading model into container now
2025-01-22 20:15:25,052:INFO:_master_model_container: 22
2025-01-22 20:15:25,052:INFO:_display_container: 5
2025-01-22 20:15:25,053:INFO:HuberRegressor()
2025-01-22 20:15:25,053:INFO:create_model() successfully completed......................................
2025-01-22 20:15:25,127:INFO:SubProcess create_model() end ==================================
2025-01-22 20:15:25,127:INFO:HuberRegressor() result for R2 is 0.654
2025-01-22 20:15:25,127:INFO:HuberRegressor(alpha=0.5, epsilon=1.4) result for R2 is 0.654
2025-01-22 20:15:25,128:INFO:HuberRegressor() is best model
2025-01-22 20:15:25,128:INFO:choose_better completed
2025-01-22 20:15:25,128:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-01-22 20:15:25,134:INFO:_master_model_container: 22
2025-01-22 20:15:25,134:INFO:_display_container: 4
2025-01-22 20:15:25,134:INFO:HuberRegressor()
2025-01-22 20:15:25,134:INFO:tune_model() successfully completed......................................
2025-01-22 20:16:18,317:INFO:Initializing finalize_model()
2025-01-22 20:16:18,319:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=HuberRegressor(), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-01-22 20:16:18,319:INFO:Finalizing HuberRegressor()
2025-01-22 20:16:18,324:INFO:Initializing create_model()
2025-01-22 20:16:18,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x15f28e050>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-01-22 20:16:18,324:INFO:Checking exceptions
2025-01-22 20:16:18,326:INFO:Importing libraries
2025-01-22 20:16:18,327:INFO:Copying training dataset
2025-01-22 20:16:18,327:INFO:Defining folds
2025-01-22 20:16:18,327:INFO:Declaring metric variables
2025-01-22 20:16:18,327:INFO:Importing untrained model
2025-01-22 20:16:18,327:INFO:Declaring custom model
2025-01-22 20:16:18,328:INFO:Huber Regressor Imported successfully
2025-01-22 20:16:18,330:INFO:Cross validation set to False
2025-01-22 20:16:18,330:INFO:Fitting Model
2025-01-22 20:16:18,449:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', HuberRegressor())])
2025-01-22 20:16:18,450:INFO:create_model() successfully completed......................................
2025-01-22 20:16:18,539:INFO:_master_model_container: 22
2025-01-22 20:16:18,539:INFO:_display_container: 4
2025-01-22 20:16:18,546:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', HuberRegressor())])
2025-01-22 20:16:18,546:INFO:finalize_model() successfully completed......................................
2025-01-22 20:17:08,734:INFO:Initializing save_model()
2025-01-22 20:17:08,734:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', HuberRegressor())]), model_name=Huber Regressor to predict spanish/latino population, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-01-22 20:17:08,735:INFO:Adding model into prep_pipe
2025-01-22 20:17:08,735:WARNING:Only Model saved as it was a pipeline.
2025-01-22 20:17:48,140:INFO:Initializing save_model()
2025-01-22 20:17:48,141:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', HuberRegressor())]), model_name=Huber Regressor to predict spanish or latino population, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/y3/s_hzlzl55b5c5cswpxkkwbnw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-01-22 20:17:48,141:INFO:Adding model into prep_pipe
2025-01-22 20:17:48,141:WARNING:Only Model saved as it was a pipeline.
2025-01-22 20:17:48,150:INFO:Huber Regressor to predict spanish or latino population.pkl saved in current working directory
2025-01-22 20:17:48,160:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['State FIPS Code',
                                             'County FIPS Code', 'FIPS',
                                             'Total Population',
                                             'Male Population',
                                             'Female Population',
                                             'Total Race Responses',
                                             'White Alone',
                                             'Black or African American Alone'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['County', 'State'],
                                    transformer=TargetEncoder(cols=['County',
                                                                    'State'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', HuberRegressor())])
2025-01-22 20:17:48,161:INFO:save_model() successfully completed......................................
